{"meta":{"title":"打工纪实","subtitle":"记录打工每一天","description":"浅水是喧哗的，深水是沉默的","author":"ooooooh灰灰","url":"https://greycode.top","root":"/"},"pages":[{"title":"404","date":"2019-07-19T16:41:10.000Z","updated":"2022-04-16T02:52:58.645Z","comments":true,"path":"404.html","permalink":"https://greycode.top/404.html","excerpt":"","text":""},{"title":"","date":"2022-04-16T02:52:58.653Z","updated":"2022-04-16T02:52:58.653Z","comments":true,"path":"clock.html","permalink":"https://greycode.top/clock.html","excerpt":"","text":"时钟 var chartDom = document.getElementById('main'); var myChart = echarts.init(chartDom); var option; option = { series: [{ name: 'hour', type: 'gauge', startAngle: 90, endAngle: -270, min: 0, max: 12, splitNumber: 12, axisLine: { lineStyle: { width: 15, color: [ [1, 'rgba(0,0,0,0.7)'] ], shadowColor: 'rgba(0, 0, 0, 0.5)', shadowBlur: 15 } }, splitLine: { lineStyle: { shadowColor: 'rgba(0, 0, 0, 0.3)', shadowBlur: 3, shadowOffsetX: 1, shadowOffsetY: 2 } }, axisLabel: { fontSize: 50, distance: 25, formatter: function (value) { if (value === 0) { return ''; } return value; } }, anchor: { show: true, icon: 'path://M532.8,70.8C532.8,70.8,532.8,70.8,532.8,70.8L532.8,70.8C532.7,70.8,532.8,70.8,532.8,70.8z M456.1,49.6c-2.2-6.2-8.1-10.6-15-10.6h-37.5v10.6h37.5l0,0c2.9,0,5.3,2.4,5.3,5.3c0,2.9-2.4,5.3-5.3,5.3v0h-22.5c-1.5,0.1-3,0.4-4.3,0.9c-4.5,1.6-8.1,5.2-9.7,9.8c-0.6,1.7-0.9,3.4-0.9,5.3v16h10.6v-16l0,0l0,0c0-2.7,2.1-5,4.7-5.3h10.3l10.4,21.2h11.8l-10.4-21.2h0c6.9,0,12.8-4.4,15-10.6c0.6-1.7,0.9-3.5,0.9-5.3C457,53,456.7,51.2,456.1,49.6z M388.9,92.1h11.3L381,39h-3.6h-11.3L346.8,92v0h11.3l3.9-10.7h7.3h7.7l3.9-10.6h-7.7h-7.3l7.7-21.2v0L388.9,92.1z M301,38.9h-10.6v53.1H301V70.8h28.4l3.7-10.6H301V38.9zM333.2,38.9v10.6v10.7v31.9h10.6V38.9H333.2z M249.5,81.4L249.5,81.4L249.5,81.4c-2.9,0-5.3-2.4-5.3-5.3h0V54.9h0l0,0c0-2.9,2.4-5.3,5.3-5.3l0,0l0,0h33.6l3.9-10.6h-37.5c-1.9,0-3.6,0.3-5.3,0.9c-4.5,1.6-8.1,5.2-9.7,9.7c-0.6,1.7-0.9,3.5-0.9,5.3l0,0v21.3c0,1.9,0.3,3.6,0.9,5.3c1.6,4.5,5.2,8.1,9.7,9.7c1.7,0.6,3.5,0.9,5.3,0.9h33.6l3.9-10.6H249.5z M176.8,38.9v10.6h49.6l3.9-10.6H176.8z M192.7,81.4L192.7,81.4L192.7,81.4c-2.9,0-5.3-2.4-5.3-5.3l0,0v-5.3h38.9l3.9-10.6h-53.4v10.6v5.3l0,0c0,1.9,0.3,3.6,0.9,5.3c1.6,4.5,5.2,8.1,9.7,9.7c1.7,0.6,3.4,0.9,5.3,0.9h23.4h10.2l3.9-10.6l0,0H192.7z M460.1,38.9v10.6h21.4v42.5h10.6V49.6h17.5l3.8-10.6H460.1z M541.6,68.2c-0.2,0.1-0.4,0.3-0.7,0.4C541.1,68.4,541.4,68.3,541.6,68.2L541.6,68.2z M554.3,60.2h-21.6v0l0,0c-2.9,0-5.3-2.4-5.3-5.3c0-2.9,2.4-5.3,5.3-5.3l0,0l0,0h33.6l3.8-10.6h-37.5l0,0c-6.9,0-12.8,4.4-15,10.6c-0.6,1.7-0.9,3.5-0.9,5.3c0,1.9,0.3,3.7,0.9,5.3c2.2,6.2,8.1,10.6,15,10.6h21.6l0,0c2.9,0,5.3,2.4,5.3,5.3c0,2.9-2.4,5.3-5.3,5.3l0,0h-37.5v10.6h37.5c6.9,0,12.8-4.4,15-10.6c0.6-1.7,0.9-3.5,0.9-5.3c0-1.9-0.3-3.7-0.9-5.3C567.2,64.6,561.3,60.2,554.3,60.2z', showAbove: false, offsetCenter: [0, '-35%'], size: 120, keepAspect: true, itemStyle: { color: '#707177' } }, pointer: { icon: 'path://M2.9,0.7L2.9,0.7c1.4,0,2.6,1.2,2.6,2.6v115c0,1.4-1.2,2.6-2.6,2.6l0,0c-1.4,0-2.6-1.2-2.6-2.6V3.3C0.3,1.9,1.4,0.7,2.9,0.7z', width: 12, length: '55%', offsetCenter: [0, '8%'], itemStyle: { color: '#C0911F', shadowColor: 'rgba(0, 0, 0, 0.3)', shadowBlur: 8, shadowOffsetX: 2, shadowOffsetY: 4 } }, detail: { show: false }, title: { offsetCenter: [0, '30%'] }, data: [{ value: 0 }] }, { name: 'minute', type: 'gauge', startAngle: 90, endAngle: -270, min: 0, max: 60, axisLine: { show: false }, splitLine: { show: false }, axisTick: { show: false }, axisLabel: { show: false }, pointer: { icon: 'path://M2.9,0.7L2.9,0.7c1.4,0,2.6,1.2,2.6,2.6v115c0,1.4-1.2,2.6-2.6,2.6l0,0c-1.4,0-2.6-1.2-2.6-2.6V3.3C0.3,1.9,1.4,0.7,2.9,0.7z', width: 8, length: '70%', offsetCenter: [0, '8%'], itemStyle: { color: '#C0911F', shadowColor: 'rgba(0, 0, 0, 0.3)', shadowBlur: 8, shadowOffsetX: 2, shadowOffsetY: 4 } }, anchor: { show: true, size: 20, showAbove: false, itemStyle: { borderWidth: 15, borderColor: '#C0911F', shadowColor: 'rgba(0, 0, 0, 0.3)', shadowBlur: 8, shadowOffsetX: 2, shadowOffsetY: 4 } }, detail: { show: false }, title: { offsetCenter: ['0%', '-40%'] }, data: [{ value: 0 }] }, { name: 'second', type: 'gauge', startAngle: 90, endAngle: -270, min: 0, max: 60, animationEasingUpdate: 'bounceOut', axisLine: { show: false }, splitLine: { show: false }, axisTick: { show: false }, axisLabel: { show: false }, pointer: { icon: 'path://M2.9,0.7L2.9,0.7c1.4,0,2.6,1.2,2.6,2.6v115c0,1.4-1.2,2.6-2.6,2.6l0,0c-1.4,0-2.6-1.2-2.6-2.6V3.3C0.3,1.9,1.4,0.7,2.9,0.7z', width: 4, length: '85%', offsetCenter: [0, '8%'], itemStyle: { color: '#C0911F', shadowColor: 'rgba(0, 0, 0, 0.3)', shadowBlur: 8, shadowOffsetX: 2, shadowOffsetY: 4 } }, anchor: { show: true, size: 15, showAbove: true, itemStyle: { color: '#C0911F', shadowColor: 'rgba(0, 0, 0, 0.3)', shadowBlur: 8, shadowOffsetX: 2, shadowOffsetY: 4 } }, detail: { show: false }, title: { offsetCenter: ['0%', '-40%'] }, data: [{ value: 0 }] }] }; var timeUpdatedStatus = { second: false, minute: false, hour: false }; function updateSeries(time, series, type) { var isCritical = (Math.floor(time) === 0) || (type === 'second' && time === 1); if (isCritical && timeUpdatedStatus[type] === true) { timeUpdatedStatus[type] = false; series.data[0].value = 0; series.clockwise = true; option.animationDurationUpdate = 0; myChart.setOption(option, true); } series.data[0].value = time; series.clockwise = true; if (time === 0) { timeUpdatedStatus[type] = true; series.clockwise = false; } } setInterval(function () { var date = new Date(); var second = date.getSeconds(); var minute = date.getMinutes() + second / 60; var hour = date.getHours() % 12 + minute / 60; updateSeries(second, option.series[2], 'second'); updateSeries(minute, option.series[1], 'minute'); updateSeries(hour, option.series[0], 'hour'); option.animationDurationUpdate = 300; myChart.setOption(option, true); date = null; }, 1000); option && myChart.setOption(option);"},{"title":"","date":"2022-04-16T02:52:58.653Z","updated":"2022-04-16T02:52:58.653Z","comments":true,"path":"ea667b0f708cd4ded0b79ebbdd99373a.html","permalink":"https://greycode.top/ea667b0f708cd4ded0b79ebbdd99373a.html","excerpt":"","text":"ea667b0f708cd4ded0b79ebbdd99373a"},{"title":"About","date":"2022-04-16T02:52:58.653Z","updated":"2022-04-16T02:52:58.653Z","comments":true,"path":"about/index.html","permalink":"https://greycode.top/about/index.html","excerpt":"","text":""},{"title":"书单","date":"2022-04-16T02:52:58.653Z","updated":"2022-04-16T02:52:58.653Z","comments":false,"path":"books/index.html","permalink":"https://greycode.top/books/index.html","excerpt":"","text":""},{"title":"分类","date":"2019-08-04T22:50:38.000Z","updated":"2022-04-16T02:52:58.653Z","comments":false,"path":"categories/index.html","permalink":"https://greycode.top/categories/index.html","excerpt":"","text":""},{"title":"friends","date":"2019-08-04T22:53:14.000Z","updated":"2022-04-16T02:52:58.653Z","comments":true,"path":"friends/index.html","permalink":"https://greycode.top/friends/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2022-04-16T02:52:58.657Z","updated":"2022-04-16T02:52:58.657Z","comments":true,"path":"links/index.html","permalink":"https://greycode.top/links/index.html","excerpt":"","text":""},{"title":"Project","date":"2022-04-16T02:52:58.657Z","updated":"2022-04-16T02:52:58.657Z","comments":true,"path":"project/index.html","permalink":"https://greycode.top/project/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2022-04-16T02:52:58.657Z","updated":"2022-04-16T02:52:58.657Z","comments":false,"path":"repository/index.html","permalink":"https://greycode.top/repository/index.html","excerpt":"","text":""},{"title":"Series","date":"2022-04-16T02:52:58.657Z","updated":"2022-04-16T02:52:58.657Z","comments":true,"path":"series/index.html","permalink":"https://greycode.top/series/index.html","excerpt":"","text":""},{"title":"Tags","date":"2022-04-16T02:52:58.657Z","updated":"2022-04-16T02:52:58.657Z","comments":true,"path":"tags/index.html","permalink":"https://greycode.top/tags/index.html","excerpt":"","text":""},{"title":"Wikis","date":"2022-04-16T02:52:58.657Z","updated":"2022-04-16T02:52:58.657Z","comments":true,"path":"wikis/index.html","permalink":"https://greycode.top/wikis/index.html","excerpt":"","text":""}],"posts":[{"title":"【译】为什么 Web 3.0 很重要，你应该知道","slug":"archive/7F482D9706354A288702DCCB66C81BF2","date":"2022-04-16T10:42:57.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"archive/7F482D9706354A288702DCCB66C81BF2/","link":"","permalink":"https://greycode.top/archive/7F482D9706354A288702DCCB66C81BF2/","excerpt":"","text":"原文链接：https://medium.com/@essentia1/why-the-web-3-0-matters-and-you-should-know-about-it-a5851d63c949 Web 3.0 及其将给行业带来的巨大变化引起了很多关注，但很少有人真正知道它为什么会产生以及它会带来什么。要理解这一点，有必要回到过去并检查它的前身，Web 1.0 和 2.0。 就像中世纪一样，Web 1.0 直到尘埃落定才被命名。众所周知，“万维网”只是一组静态网站，包含大量信息，没有互动内容。连接意味着通过摇摇晃晃的调制解调器拨号并阻止房子里的任何人使用电话。它是 AOL 聊天室和 MSN Messenger、AltaVista 和 Ask Jeeves 的网络。它慢得令人发指。流媒体视频和音乐？忘了它。下载一首歌曲至少需要一天时间。 然后是 2.0令人毛骨悚然的调制解调器和无聊的接口的内存在很大程度上已经消失了。更快的互联网速度为互动内容铺平了道路，网络不再是为了观察，而是为了参与。全球信息共享催生了“社交媒体”时代。Youtube、维基百科、Flickr 和 Facebook 为无声者发声，并为志同道合的社区提供了蓬勃发展的途径。 发布这篇博文将花费我 30 秒的时间，这与设计师、开发人员和管理员共同努力进行简单的网站编辑相比，这是一个不可估量的改进。我们可以称之为“读写发布”时代——信息的传播就像这三个词一样简单。那么问题来了，web 2.0 很棒，哪里出了问题？ 信息就是金钱联合国估计，从 2000 年到 2015 年，互联网用户从 7.38 亿增加到 32 亿。这是一个不可估量的数据，正如大型数字公司所意识到的那样，个人信息是一项非常有价值的资产。于是开始在集中式服务器中大量存储数据，亚马逊、Facebook 和 Twitter 是最大的托管方。人们为了这些服务的便利而牺牲了安全性；不管他们是否知道，他们的身份、浏览习惯、搜索和在线购物信息都被卖给出价最高的人。 3.0 革命到了这个阶段，Web 2.0 的倡导者已经在构想继任者了。他们设想，下一个网络将怀旧地转向网络 1.0 的愿景：更“人性化”和更多隐私。与其将权力（和数据）集中在动机可疑的庞然大物手中，不如归还给合法所有者。 一个更公平、更透明的网络的愿景可以追溯到 2006 年左右，但当时还没有工具和技术来实现它。比特币还有三年的时间，它带来了分布式账本或区块链的概念，用于点对点数字存储。去中心化是一个想法。区块链是手段。现在我们有了所谓的以人为本的互联网。 支持隐私、反垄断的网络虽然 Web 2.0 使许多权力结构民主化并创造了新的机会，但经济引擎在很大程度上是私有化和垄断的。Facebook、Uber 和 AirBnB 已经为它们主导的公共基础设施创建了专用网络。Web 3.0 与此相反，它是关于通过开放网络共享价值的多个利润中心。 很容易想象在不久的将来，基于加密的手机、VPN、去中心化存储和加密货币钱包将广泛普及。未来不需要暂停或监视我们信息的网络和蜂窝提供商。如果我们要避免梦游进入黑镜式的隐私反乌托邦，这些就是我们需要的工具。Web 3.0 提供了许多优势： 没有中心控制点：中间人被从等式中删除，像以太坊这样的区块链提供了一个无需信任的平台，其中的规则是牢不可破的，数据是完全加密的。Alphabet 和 Apple 将不再控制用户数据。任何政府或实体都没有能力扼杀网站和服务；没有一个人可以控制他人的身份。 数据所有权：最终用户将重新获得对数据的完全控制权并拥有加密的安全性。然后可以在逐案和许可的基础上共享信息。目前，亚马逊和 Facebook 等大公司拥有服务器工厂，存储饮食偏好、收入、兴趣、信用卡详细信息等信息。这不仅仅是为了改善他们的服务——营销人员和广告商每年为数据支付数十亿美元。 黑客和数据泄露的显着减少：由于数据将分散和分布，黑客将需要关闭整个网络，而三字母机构使用的国家支持的工具（如Vault7）将被淘汰。目前，互联网公司被迫交出用户数据或屈服于对整个数据库的审查。这些数据入侵不仅限于恐怖主义等重大安全威胁；2017 年，Coinbase 将美国国税局告上法庭，要求其查看超过 15,000 名客户的数据。 到 2019 年，数据泄露的成本预计将超过 2.1 万亿美元。 Coinbase 最终败诉的此案为政府实体接管数千名客户的财务铺平了道路，几乎没有正当理由证明这种入侵是正当的。不幸的是，这样的案例并不是孤立的。2013 年，安全电子邮件提供商 Lavabit 选择关闭而不是将其 SSL 密钥交给美国政府，以便监视爱德华·斯诺登。 互操作性：应用程序将易于定制且与设备无关，能够在智能手机、电视、汽车、微波炉和智能传感器上运行。目前，应用程序是特定于操作系统的，并且通常仅限于单个操作系统。例如，许多 Android 加密货币钱包在 iO 上不可用，这让使用多种设备的消费者感到沮丧。它增加了负责发布软件多次迭代和更新的开发人员的费用。 无许可区块链：任何人都可以创建地址并与网络交互。访问无许可链的能力怎么强调都不为过。用户不会因为地理、收入、性别、方向或许多其他社会学和人口学因素而被禁止。财富和其他数字资产可以在世界任何地方快速高效地跨境转移。 不间断服务：账户暂停和分布式拒绝服务显着减少。因为没有单点故障，服务中断将是最小的。数据将存储在分布式节点上以确保冗余，并且多个备份将防止服务器故障或被占用。 它将如何运作？就像任何新兴技术一样，仍在完善中。为了访问去中心化的网络，人们只需要一个种子。这将是一个单一的资产，可以与 dApp 和其他服务进行交互。个人仍将使用网络浏览器访问互联网，并且在视觉上它将是 Web 2.0 用户友好的。 从表面上看，从 2.0 到 3.0 的学习曲线会很平缓。但在幕后，将用户与数字服务联系起来的框架却截然不同。交易是手动签名和验证的，以防止平台在没有正当理由的情况下窃取个人信息。网络用户会选择加入，而不是尝试——而且经常失败——选择退出。 我们使用 Storj、Siacoin、Filecoin 或 IPFS 技术等服务来分发和存储文件，而不是 Google Drive 或 Dropbox。 我们有 Experty.io 等平台，而不是 Skype。 我们有状态，而不是 WhatsApp 和微信 取代 iOS 和 Android 等操作系统，Essentia.one 和 EOS 等框架提供了通往新网络的门户。 Akasha 或 Steemit 将扮演 Facebook 的角色，Brave 浏览器将充当 Chrome，而 Ethlance 可以接替 Upwork。 这些只是几个例子。随着 Web 3.0 的兴起，新平台将会出现，竞争水平不会受到垄断服务提供商的限制。三年后我们将使用的最好的 dApp 和去中心化服务可能只是开发人员眼中的微光。 概念是这样的：目前构成 Web 3.0 的去中心化应用程序、钱包、平台和其他数字资产是分散的。访问这些接口需要单独的种子、登录名和身份——很像现有的 Web 2.0。Essentia.one将通过一个种子将这些不同的平台链接在一起。因为这将作为可以与其所有者关联的加密密钥运行，所以 Essentia 将提供身份证明，但不会放弃任何不必要的个人身份。 正如 Web 2.0 并没有自动消灭 Web 1.0（仍然在互联网的某些部分周围积聚灰尘），向 3.0 的迁移需要时间并与现有的在线系统集成。车轮已经启动，火车已经离开车站。Web 3.0 是一场运动革命，我们已经过了不归路。","categories":[{"name":"web3.0","slug":"web3-0","permalink":"https://greycode.top/categories/web3-0/"}],"tags":[{"name":"web3.0","slug":"web3-0","permalink":"https://greycode.top/tags/web3-0/"}]},{"title":"Redis是怎样通讯的？","slug":"archive/8B135153FD9D41DE928DF42F84AD1ECA","date":"2022-03-29T13:41:40.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"archive/8B135153FD9D41DE928DF42F84AD1ECA/","link":"","permalink":"https://greycode.top/archive/8B135153FD9D41DE928DF42F84AD1ECA/","excerpt":"","text":"模型Redis 协议模型就是简单的请求-响应模型，和平常的 Http 协议有点类似。客户端发送 Redis 命令，然后服务端处理命令并返回结果给客户端。Redis 官方说这可能是最简单的网络协议模型了。 有两种情况下不 不适用这个模型，一个是批量流水线命令，一个是发布&#x2F;订阅功能。 协议描述Redis 协议一般简单的分为 5 类数据结构，简单字符串、错误信息、数值、大字符串、数组。每种数据类型在第一个字节用不同的符号来区分： **简单字符串(Simple Strings)**：开头第一个符号为 +，对应 HEX 值为：0x2b **错误信息(Errors)**：第一个字节符号为 -，对应 HEX 值为：0x2d **数值(Integers)**：第一个字节符号为 :，对应 HEX 值为：0x3a **大字符串(Bulk Strings)**：第一个字节符号为 $，对应 HEX 值为：0x24 **数组(Arrays)**：第一个字节符号为 *，对应 HEX 值为：0x2a 这 5 种数据类型可以组合起来使用，每种数据类型通过 CRLF 结尾，就是平常的 \\r\\n，对应的 HEX 值为：0x0d,0x0a。一般我们判断一种数据类型是否结束时，只要判断是否有 \\r 出现就可以了。Redis 客户端和服务端之间就是通过这些规则来进行通信的。 简单字符串一般简单字符串用于返回 Redis 服务端的系统响应，如果要响应用户存储的数据时，一般会用大字符串(Bulk Strings)的数据类型来返回。 比如说客户端发送 set 命令新增一个 Key 来存储字符串，此时客户端就会返回 +OK。这种方式返回的数据不能有空格和换行，因为空格和换行表示该类型的数据结尾。 redis:0&gt;set name 灰灰&quot;OK&quot;# Redis 服务端响应数据0000 2b 4f 4b 0d 0a +OK·· 错误信息当我们执行的命令发生错误时，Redis 服务端就会返回错误信息 redis:0&gt;incr name&quot;ERR value is not an integer or out of range&quot;# Redis 服务端响应数据0000 2d 45 52 52 20 76 61 6c 75 65 20 69 73 20 6e 6f -ERR val ue is no0010 74 20 61 6e 20 69 6e 74 65 67 65 72 20 6f 72 20 t an int eger or 0020 6f 75 74 20 6f 66 20 72 61 6e 67 65 0d 0a out of r ange·· 数值返回数值的其中一种情况就是执行 exists 命令来判断某个 Key 存不存在，返回 1 表示存在，返回 0 表示不存在 redis:0&gt;exists name&quot;1&quot;# Redis 服务端响应数据0000 3a 31 0d 0a :1··---------------------------------------------------------------redis:0&gt;exists hui&quot;0&quot;# Redis 服务端响应数据0000 3a 30 0d 0a :0.. 大字符串大字符串返回值有两部分组成，一部分是表示字符串长度的数据，一部分是字符串本身数据。它由 $ 符号开头，后面跟着的是表示字符串长度的数据，该数值直接用字符串的形式表示，也就说读取该字节数据的时候，要用读取字符串数据的方式来读取。读取完后再转换为数值数据，然后再根据这个数值来读取相对应长度的字节数据。这样数据中就可以包含空格和换行了，因为是根据开头的长度数值来读取相对应的字节数据的，而不是通过判断 \\r\\n 符号来读取。 比如客户端获取前面设置的 Key 为 name 的数据： redis:0&gt;get name&quot;灰灰&quot;# Redis 服务端响应数据0000 24 36 0d 0a e7 81 b0 e7 81 b0 0d 0a $6.......... 其中 e7 81 b0 e7 81 b0 就是 灰灰 字符的字节数据 数组当服务端返回数组数据时，它由 * 符号开头，后面紧跟着的是这个数值的长度，和大字符串的字节长度一样，该长度也是以字符串的形式返回。数组中的每个元素再通过相对应的数据类型来表示。 *2+value1+value2# or*3:22:52:99# 当然也可以表示嵌套数组*2*1:123*2:433:92 比如客户端设置一个 list 数据，然后获取它 redis:0&gt;lpush mylist value1 value22# 获取 listredis:0&gt;lrange mylist 0 1[&quot;value2&quot;,&quot;value1&quot;]0000 2a 32 0d 0a 24 36 0d 0a 76 61 6c 75 65 32 0d 0a *2..$6..value2..0010 24 36 0d 0a 76 61 6c 75 65 31 0d 0a $6..value1.. 发送命令当客户端发送命令给服务端时，客户端一般会把命令组装成上面的数组加大字符串的数据格式再发送给服务端。比如上面的我们发送一个简单的新增一个 Key 命令： redis:0&gt;set name 灰灰# 客户端发送给服务端端数据0000 2a 33 0d 0a 24 33 0d 0a 73 65 74 0d 0a 24 34 0d *3..$3..set..$4.0010 0a 6e 61 6d 65 0d 0a 24 36 0d 0a e7 81 b0 e7 81 .name..$6.......0020 b0 0d 0a ... Redis 数据结构Redis 一般常用的有 5 种数据类型，下面看看 5 种数据类型对应的客户端和服务端之间的数据是怎么交互的。 字符串 Stringredis:0&gt;set name greycode0000 2a 33 0d 0a 24 33 0d 0a 73 65 74 0d 0a 24 34 0d *3..$3..set..$4.0010 0a 6e 61 6d 65 0d 0a 24 38 0d 0a 67 72 65 79 63 .name..$8..greyc0020 6f 64 65 0d 0a ode..# 响应0000 2b 4f 4b 0d 0a +OK..-------------------------------------------------------------------------redis:0&gt;get name0000 2a 32 0d 0a 24 33 0d 0a 67 65 74 0d 0a 24 34 0d *2..$3..get..$4.0010 0a 6e 61 6d 65 0d 0a .name..# 响应0000 24 38 0d 0a 67 72 65 79 63 6f 64 65 0d 0a $8..greycode.. 哈希表 Hashredis:0&gt;hset myHash name huihui0000 2a 34 0d 0a 24 34 0d 0a 68 73 65 74 0d 0a 24 36 *4..$4..hset..$60010 0d 0a 6d 79 48 61 73 68 0d 0a 24 34 0d 0a 6e 61 ..myHash..$4..na0020 6d 65 0d 0a 24 36 0d 0a 68 75 69 68 75 69 0d 0a me..$6..huihui..# 响应0000 3a 31 0d 0a :1..-------------------------------------------------------------------------redis:0&gt;hget myHash name0000 2a 33 0d 0a 24 34 0d 0a 68 67 65 74 0d 0a 24 36 *3..$4..hget..$60010 0d 0a 6d 79 48 61 73 68 0d 0a 24 34 0d 0a 6e 61 ..myHash..$4..na0020 6d 65 0d 0a me..# 响应0000 24 36 0d 0a 68 75 69 68 75 69 0d 0a $6..huihui..-------------------------------------------------------------------------redis:0&gt;hgetall myHash0000 2a 32 0d 0a 24 37 0d 0a 68 67 65 74 61 6c 6c 0d *2..$7..hgetall.0010 0a 24 36 0d 0a 6d 79 48 61 73 68 0d 0a .$6..myHash..# 响应0000 2a 32 0d 0a 24 34 0d 0a 6e 61 6d 65 0d 0a 24 36 *2..$4..name..$60010 0d 0a 68 75 69 68 75 69 0d 0a ..huihui.. 列表 Listredis:0&gt;lpush lists huihui greycode0000 2a 34 0d 0a 24 35 0d 0a 6c 70 75 73 68 0d 0a 24 *4..$5..lpush..$0010 35 0d 0a 6c 69 73 74 73 0d 0a 24 36 0d 0a 68 75 5..lists..$6..hu0020 69 68 75 69 0d 0a 24 38 0d 0a 67 72 65 79 63 6f ihui..$8..greyco0030 64 65 0d 0a de..# 响应0000 3a 32 0d 0a :2..-------------------------------------------------------------------------redis:0&gt;lrange lists 0 10000 2a 34 0d 0a 24 36 0d 0a 6c 72 61 6e 67 65 0d 0a *4..$6..lrange..0010 24 35 0d 0a 6c 69 73 74 73 0d 0a 24 31 0d 0a 30 $5..lists..$1..00020 0d 0a 24 31 0d 0a 31 0d 0a ..$1..1..# 响应0000 2a 32 0d 0a 24 38 0d 0a 67 72 65 79 63 6f 64 65 *2..$8..greycode0010 0d 0a 24 36 0d 0a 68 75 69 68 75 69 0d 0a ..$6..huihui.. 集合 Setredis:0&gt;sadd myset hello hi0000 2a 34 0d 0a 24 34 0d 0a 73 61 64 64 0d 0a 24 35 *4..$4..sadd..$50010 0d 0a 6d 79 73 65 74 0d 0a 24 35 0d 0a 68 65 6c ..myset..$5..hel0020 6c 6f 0d 0a 24 32 0d 0a 68 69 0d 0a lo..$2..hi..# 响应0000 3a 32 0d 0a :2..-------------------------------------------------------------------------redis:0&gt;smembers myset0000 2a 32 0d 0a 24 38 0d 0a 73 6d 65 6d 62 65 72 73 *2..$8..smembers0010 0d 0a 24 35 0d 0a 6d 79 73 65 74 0d 0a ..$5..myset..#响应0000 2a 32 0d 0a 24 35 0d 0a 68 65 6c 6c 6f 0d 0a 24 *2..$5..hello..$0010 32 0d 0a 68 69 0d 0a 2..hi.. 有序集合 ZSetredis:0&gt;zadd myZset 1 hello 2 world0000 2a 36 0d 0a 24 34 0d 0a 7a 61 64 64 0d 0a 24 36 *6..$4..zadd..$60010 0d 0a 6d 79 5a 73 65 74 0d 0a 24 31 0d 0a 31 0d ..myZset..$1..1.0020 0a 24 35 0d 0a 68 65 6c 6c 6f 0d 0a 24 31 0d 0a .$5..hello..$1..0030 32 0d 0a 24 35 0d 0a 77 6f 72 6c 64 0d 0a 2..$5..world..# 响应0000 3a 32 0d 0a :2..-------------------------------------------------------------------------redis:0&gt;zrange myset 0 -10000 2a 34 0d 0a 24 36 0d 0a 7a 72 61 6e 67 65 0d 0a *4..$6..zrange..0010 24 36 0d 0a 6d 79 5a 73 65 74 0d 0a 24 31 0d 0a $6..myZset..$1..0020 30 0d 0a 24 32 0d 0a 2d 31 0d 0a 0..$2..-1..# 响应0000 2a 32 0d 0a 24 35 0d 0a 68 65 6c 6c 6f 0d 0a 24 *2..$5..hello..$0010 35 0d 0a 77 6f 72 6c 64 0d 0a 5..world.. PipelineRedis 执行 Pipeline 命令，可以一次用一个数据包发送多条命令，然后服务端在把所有命令的执行结果打包成一个数据包返回给客户端，这样在执行大量命令的时候可以减少系统开销。比如我们要执行 set num 998 和 incr num 这两条命令，那么我们就可以把这两条命令分别组装然后拼接在一起发送给服务端。 0000 2a 33 0d 0a 24 33 0d 0a 73 65 74 0d 0a 24 33 0d *3..$3..set..$3.0010 0a 6e 75 6d 0d 0a 24 33 0d 0a 39 39 38 0d 0a 2a .num..$3..998..*0020 32 0d 0a 24 34 0d 0a 69 6e 63 72 0d 0a 24 33 0d 2..$4..incr..$3.0030 0a 6e 75 6d 0d 0a .num.. 服务端接收到数据包后，处理每条命令，然后把结果打包返回。 0000 2b 4f 4b 0d 0a 3a 39 39 39 0d 0a +OK..:999.. 其中， set num 998 命令的结果为：OK incr num 的结果为：999 代码实现了解了以上交互协议的规则后，我们就可以自己手写一个 Redis 客户端来与 Redis 服务器通讯了。 完整代码地址：https://gist.github.com/greycodee/4a102aa9ae689aea1874b1fe06190192","categories":[{"name":"协议","slug":"协议","permalink":"https://greycode.top/categories/%E5%8D%8F%E8%AE%AE/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://greycode.top/tags/Redis/"},{"name":"协议","slug":"协议","permalink":"https://greycode.top/tags/%E5%8D%8F%E8%AE%AE/"}]},{"title":"MySQL是怎样通讯的？","slug":"archive/2852F14D7D13471798CE28C544741E89","date":"2022-03-27T23:51:51.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"archive/2852F14D7D13471798CE28C544741E89/","link":"","permalink":"https://greycode.top/archive/2852F14D7D13471798CE28C544741E89/","excerpt":"","text":"前言我们平常使用数据库的场景一般是程序里面代码直接连接使用，然后进行 CRUD 操作。或者使用有 GUI 界面的数据库软件来手动操作数据库， 这类软件有 DataGrip、Navicat等等…。平常很少关心它们的底层数据交互是怎么样的，相信你看了这篇文章一定能有大概的了解。本篇文章的代码使用 Go 语言来实现 MySQL 的协议。 协议简介MySQL 协议一般分为两个阶段，一个是连接阶段，一个是命令阶段。连接阶段主要是客户端和服务端进行相互认证的阶段，就像我们平常登陆某个网站的一个操作。命令阶段主要是客户端向服务端进行的一些指令的发送，然后服务端处理指令并返回结果的一个过程。在客户端和服务端发送的数据包中，前 3 个字节表示这个数据包的大小，所以这里就有一个问题，就是它有一个大小的限制，数据包大小不能超过16777215 ($2^{24}-1$) bytes，也就是 16M 大小（16进制表示：ff ff ff，刚刚 3 个字节）。这就会有三种情况出现，一种是数据包小于 16M，一种是等于，一种是大于。所以在 MySQL 协议中是这样处理的： 小于 16M：发送一个数据包就可以了 等于 16M：发送两个数据包，第二个包为空包 大于 16M：发送多个数据包，每个数据包大小最大为 16M，当最后一个数据包等于 16M 时，再多发送一个空数据包 每个数据包中的第 4 个字节表示这个数据包的序号ID，这个 ID 在不同阶段会递增，比如在连接阶段，这个 ID 会随着包的数量而递增，当连接阶段完成后进入命令阶段，这个 ID 又会从 0 开始递增，直到这个命令的生命周期结束。 初始握手包当客户端进行尝试使用 TCP 连接 MySQL 服务端时，服务端就会响应一个初始的握手包，这个握手包有 V9、V10 两个版本。不过现在一般用的都是 V10 版本，如果 MySQL 的版本在 3.21.0 之前，那么服务端响应的是 V9 版本的初始握手包。本篇文章就讲讲现在常用的 V10 版本的初始握手包。 我们可以使用以下代码来尝试连接我们本地的 MySQL 服务: package mainimport &quot;net&quot;func main() &#123; conn, err := net.Dial(&quot;tcp&quot;,&quot;127.0.0.1:3306&quot;) if err != nil &#123; return &#125; defer func(conn net.Conn) &#123; err := conn.Close() if err != nil &#123; &#125; &#125;(conn)&#125; 运作程序后，服务端就会响应一个初始握手包给我们，那么怎么清楚明了的查看这个数据包呢？此时我们可以用 Wireshark 这个软件来查看 MySQL 服务端返回的数据包可以看到前 4 个字节为 16 进制的数据: 4e 00 00 00 ，表示了这个数据包大小为 78 字节，序号 ID 为 0。具体的字段字节大小和描述如下表示： 字段名 字节数据长度(byte) 描述 Protocol 1 初始握手包协议版本，可以根据这个字节数据来判断握手包的协议版本，然后按不同版本来处理接下来的数据 Version 直到遇到字节数据为 0 的时候停止 MySQL 服务端版本描述字符串 Thread ID 4 连接 ID Slat（第一段） 8 用于处理后续客户端的密码加密 filler 1 填充一个字节，默认为 0 Service Capability（Low） 2 服务端能力标志，一共有 4 个字节，这里表示的是低 2 位字节的数据 Server Language 1 服务端字符编码 Server Status 2 服务端状态 Service Capability（Upper） 2 服务端能力标志，这里表示的是高 2 位字节的数据 Authentication Plugin Length 1 身份验证插件长度 Unused 10 预留的 10 个字节数据，默认全部为 0 Slat（第二段） 计算公式：MAX(13, 身份验证插件长度 - 8) 用于处理后续客户端的密码加密 Authentication Plugin 直到遇到字节数据为 0 的时候停止 身份验证插件 这个初始握手包里包含了很多的数据，在后续的整个连接阶段需要用到里面的大部分数据。 能力标志上面服务端响应端初始握手包中包含了一个能力标志，这个能力标志一共有 4 个字节来表示，我们知道 1 个字节有 8 个 bit，所以 4 个字节一共有 32 个 bit，其中除了最高的 7 个 bit，另外的每一个 bit 都代表着一个能力标志的状态（0 为不支持，1 为支持）,就像下面这样表示 # Capabilities 字节数据中的低 2 位Server Capabilities: 0xffff.... .... .... ...1 = Long Password: Set.... .... .... ..1. = Found Rows: Set.... .... .... .1.. = Long Column Flags: Set.... .... .... 1... = Connect With Database: Set.... .... ...1 .... = Don&#x27;t Allow database.table.column: Set.... .... ..1. .... = Can use compression protocol: Set.... .... .1.. .... = ODBC Client: Set.... .... 1... .... = Can Use LOAD DATA LOCAL: Set.... ...1 .... .... = Ignore Spaces before &#x27;(&#x27;: Set.... ..1. .... .... = Speaks 4.1 protocol (new flag): Set.... .1.. .... .... = Interactive Client: Set.... 1... .... .... = Switch to SSL after handshake: Set...1 .... .... .... = Ignore sigpipes: Set..1. .... .... .... = Knows about transactions: Set.1.. .... .... .... = Speaks 4.1 protocol (old flag): Set1... .... .... .... = Can do 4.1 authentication: Set# Capabilities 字节数据中的高 2 位Extended Server Capabilities: 0xc1ff.... .... .... ...1 = Multiple statements: Set.... .... .... ..1. = Multiple results: Set.... .... .... .1.. = PS Multiple results: Set.... .... .... 1... = Plugin Auth: Set.... .... ...1 .... = Connect attrs: Set.... .... ..1. .... = Plugin Auth LENENC Client Data: Set.... .... .1.. .... = Client can handle expired passwords: Set.... .... 1... .... = Session variable tracking: Set.... ...1 .... .... = Deprecate EOF: Set1100 000. .... .... = Unused: 0x60 除了服务端响应的初始握手包会返回这个能力标志，后续我们发送给服务端的 HandshakeResponse 数据包中也包含这个能力标志数据，那么我们该怎么发送这个能力标志数据呢？官方给出力各个能力的值，如下表： 序号 Capability Flags 值【16进制】 1 CLIENT_LONG_PASSWORD 0x1 2 CLIENT_FOUND_ROWS 0x2 3 CLIENT_LONG_FLAG 0x4 4 CLIENT_CONNECT_WITH_DB 0x8 5 CLIENT_NO_SCHEMA 0x10 6 CLIENT_COMPRESS 0x20 7 CLIENT_ODBC 0x40 8 CLIENT_LOCAL_FILES 0x80 9 CLIENT_IGNORE_SPACE 0x100 10 CLIENT_PROTOCOL_41 0x200 11 CLIENT_INTERACTIVE 0x400 12 CLIENT_SSL 0x800 13 CLIENT_IGNORE_SIGPIPE 0x1000 14 CLIENT_TRANSACTIONS 0x2000 15 CLIENT_RESERVED 0x4000 16 CLIENT_SECURE_CONNECTION 0x8000 17 CLIENT_MULTI_STATEMENTS 0x10000 18 CLIENT_MULTI_RESULTS 0x20000 19 CLIENT_PS_MULTI_RESULTS 0x40000 20 CLIENT_PLUGIN_AUTH 0x80000 21 CLIENT_CONNECT_ATTRS 0x100000 22 CLIENT_PLUGIN_AUTH_LENENC_CLIENT_DATA 0x200000 23 CLIENT_CAN_HANDLE_EXPIRED_PASSWORDS 0x400000 24 CLIENT_SESSION_TRACK 0x800000 25 CLIENT_DEPRECATE_EOF 0x1000000 当我们要发送客户端支持的能力标志时，只要把所有支持的能力标志的值相加，然后转换为 4 字节大小的数据。例如我们要发送个给服务端说明我们支持 CLIENT_PROTOCOL_41 这个能力，那么我们就可以把这个 16 进制的值转换为 4 个字节的数据来表示，转换后的数据为：[0 0 16 0]。HEX 表示法为：[00 00 10 00] 注意：上面转换的字节数据为小端数据，这方面端知识具体可以查询字节序的大小端 字符编码初始握手包还有一个字节表示了支持的字符编码，后续我们响应的 HandshakeResponse 数据包中也要发送客户端支持的字符编码，相对应的字符编码对应的 ID 如下表，当我们支持什么字符编码时，只要发送对应编码的 ID就可以了。 +--------------------+---------------------+-----+| CHARACTER_SET_NAME | COLLATION_NAME | ID |+--------------------+---------------------+-----+| big5 | big5_chinese_ci | 1 || dec8 | dec8_swedish_ci | 3 || cp850 | cp850_general_ci | 4 || hp8 | hp8_english_ci | 6 || koi8r | koi8r_general_ci | 7 || latin1 | latin1_swedish_ci | 8 || latin2 | latin2_general_ci | 9 || swe7 | swe7_swedish_ci | 10 || ascii | ascii_general_ci | 11 || ujis | ujis_japanese_ci | 12 || sjis | sjis_japanese_ci | 13 || hebrew | hebrew_general_ci | 16 || tis620 | tis620_thai_ci | 18 || euckr | euckr_korean_ci | 19 || koi8u | koi8u_general_ci | 22 || gb2312 | gb2312_chinese_ci | 24 || greek | greek_general_ci | 25 || cp1250 | cp1250_general_ci | 26 || gbk | gbk_chinese_ci | 28 || latin5 | latin5_turkish_ci | 30 || armscii8 | armscii8_general_ci | 32 || utf8 | utf8_general_ci | 33 || ucs2 | ucs2_general_ci | 35 || cp866 | cp866_general_ci | 36 || keybcs2 | keybcs2_general_ci | 37 || macce | macce_general_ci | 38 || macroman | macroman_general_ci | 39 || cp852 | cp852_general_ci | 40 || latin7 | latin7_general_ci | 41 || cp1251 | cp1251_general_ci | 51 || utf16 | utf16_general_ci | 54 || utf16le | utf16le_general_ci | 56 || cp1256 | cp1256_general_ci | 57 || cp1257 | cp1257_general_ci | 59 || utf32 | utf32_general_ci | 60 || binary | binary | 63 || geostd8 | geostd8_general_ci | 92 || cp932 | cp932_japanese_ci | 95 || eucjpms | eucjpms_japanese_ci | 97 || gb18030 | gb18030_chinese_ci | 248 || utf8mb4 | utf8mb4_0900_ai_ci | 255 |+--------------------+---------------------+-----+ 客户端握手响应包（HandshakeResponse）客户端和 MySQL 服务端进行数据交互时，有明文数据交互和SSL加密数据交互，这里贴一张 MySQL 官网给出的一张图，这张图大致的描述了客户端和服务端连接的流程本篇文章就讲下简单的明文连接，不管是明文连接和加密连接，客户端都必须返回 HandshakeResponse 这个数据包给服务端。这个数据包也有两个版本，一个是 HandshakeResponse41，另一个是 HandshakeResponse320。现在一般都是用 HandshakeResponse41 这个版本的数据包。那么服务端要怎么知道客户端发送的数据包到底是什么版本呢？这个就要用到上面的 CLIENT_PROTOCOL_41 这个能力标志了，服务端只要解析客户端发来的 HandshakeResponse 数据包中的 Capability Flags 数据中是否支持 CLIENT_PROTOCOL_41 这个能力，来判断客户端握手响应包的版本。当 CLIENT_PROTOCOL_41 这个能力为支持状态，说明版本是 HandshakeResponse41，否则就是 HandshakeResponse320。 HandshakeResponse41现在常用的就是 HandshakeResponse41 这个握手响应包，本篇文章就讲一讲这个握手响应包吧。这个包的描述如下： 4 capability flags, CLIENT_PROTOCOL_41 always set4 max-packet size1 character setstring[23] reserved (all [0])string[NUL] usernameif capabilities &amp; CLIENT_PLUGIN_AUTH_LENENC_CLIENT_DATA &#123; // 如果支持 CLIENT_PLUGIN_AUTH_LENENC_CLIENT_DATA 标志就返回这些数据 lenenc-int length of auth-response string[n] auth-response&#125; else if capabilities &amp; CLIENT_SECURE_CONNECTION &#123; // 如果支持 CLIENT_SECURE_CONNECTION 标志就返回这些数据 1 length of auth-response string[n] auth-response&#125; else &#123; // 否则就返回这个数据 string[NUL] auth-response&#125;if capabilities &amp; CLIENT_CONNECT_WITH_DB &#123; // 如果支持 CLIENT_CONNECT_WITH_DB 标志就返回这些数据 string[NUL] database&#125;if capabilities &amp; CLIENT_PLUGIN_AUTH &#123; // 如果支持 CLIENT_PLUGIN_AUTH 标志就返回这些数据 string[NUL] auth plugin name&#125;if capabilities &amp; CLIENT_CONNECT_ATTRS &#123; // 如果支持 CLIENT_CONNECT_ATTRS 标志就返回这些数据 lenenc-int length of all key-values lenenc-str key lenenc-str value if-more data in &#x27;length of all key-values&#x27;, more keys and value pairs &#125; capability_flags – 客户端的能力标志，占用 4 个字节 max_packet_size – 客户端要发送到服务器的命令包的最大大小，占用 4 个字节 character_set - 连接的默认字符集，占用 1 个字节 username – 客户端要登录的 SQL 帐户的名称 – 此字符串应使用character set字段指示的字符集进行编码。 auth-response –由 auth plugin name 字段指示的 Authentication Method 生成的加密的身份验证响应数据。 database – 用于连接的初始数据库 – 此字符串应使用 character set字段指示的字符集进行编码。 auth plugin name – 客户端用此加密方法加密密码然后赋值给 auth-response 返回给服务端密码加密方式客户端传输给服务端的 MySQL 账户的密码加密方式采用插件的形式，就是 auth plugin name 这个字段的数据，一般支持以下几种加密方式 名称 Auth Plugin Name 能力标志 旧密码认证 mysql_old_password 不能使用，无能力标志 安全密码认证 mysql_native_password CLIENT_SECURE_CONNECTION 明文认证 mysql_clear_password CLIENT_PLUGIN_AUTH Windows 原生身份验证 authentication_windows_client CLIENT_PLUGIN_AUTH SHA256 sha256_password CLIENT_PLUGIN_AUTH 现在一般常用的是安全密码认证，就是 Auth Plugin Name 为 mysql_native_password 的认证加密方式。这个方法的加密方式如下 SHA1( password ) XOR SHA1( &quot;20-bytes random data from server&quot; &lt;concat&gt; SHA1( SHA1( password ) ) ) 它先对明文密码进行一次 SHA1 的散列运算生成密码 1，然后再将服务端初始握手包中的 20 位 Slat 数据和对明文密码进行两次 SHA1 散列的结果进行连接，然后对连接的结果再进行一次散列运算生成密码 2，最后密码 1 和密码 2 进行异或运算，得到来最终发送给服务端的数据。 响应数据包当我们发送响应握手包 HandshakeResponse 后，服务端就会返回一个通用的响应包给我们，这个响应包可以是以下其中一个： OK_Packet ERR_Packet EOF_Packet 那么我们要怎么区分这三个包呢？区分的关键在于包的第一个字节的数据，如果第一个字节数据为 0x00，则代表这是一个 OK_Packet 。如果第一个字节数据为 0xff，则表示这是一个 ERR_Packet。如果第一个字节为 0xfe，则代表这是一个 EOF_Packet。从 MySQL 5.7.5 开始，OK_Packet 包也用于指示 EOF_Packet，并且不推荐使用 EOF_Packet 包。为了确保 MySQL 的旧版本（5.7.5 之前）和新版本（5.7.5 及更高版本）之间的向后兼容性，新客户端会向服务端该送 CLIENT_DEPRECATE_EOF 能力标志。如果没有传送这个能力标志，服务端返回端数据结果集中还是会以 EOF_Packet 包结尾，如果传送了这个能力标志的话，服务端返回端结果集中会以 OK_Packet 包结尾，并且第一个字节数据会是 0xfe。那么我们怎么区分新版 OK_Packet 包在什么时候代表 OK_Packet，在什么时候代表 EOF_Packet 呢？主要可以通过以下几点来判断： 一个是判断客户端刚才是否传送了 CLIENT_DEPRECATE_EOF 能力标志 OK_Packet: 第一个字节数据为 0x00，且数据包长度 &gt; 7 EOF_Packet: 第一个字节数据为 0xfe，且数据包长度 &lt; 9OK_Packet 格式int&lt;1&gt; header [00] or [fe] the OK packet headerint&lt;lenenc&gt; affected_rows 受影响行数int&lt;lenenc&gt; last_insert_id 最后插入 IDif capabilities &amp; CLIENT_PROTOCOL_41 &#123; int&lt;2&gt; status_flags 状态标志 int&lt;2&gt; warnings 警告数&#125; elseif capabilities &amp; CLIENT_TRANSACTIONS &#123; int&lt;2&gt; status_flags Status Flags&#125;if capabilities &amp; CLIENT_SESSION_TRACK &#123; string&lt;lenenc&gt; info 人类可读的状态信息 if status_flags &amp; SERVER_SESSION_STATE_CHANGED &#123; string&lt;lenenc&gt; session_state_changes 会话状态信息 &#125; &#125; else &#123; string&lt;EOF&gt; info 人类可读的状态信息&#125; ERR_Packet 格式int&lt;1&gt; header [ff] header of the ERR packetint&lt;2&gt; error_code 错误代码if capabilities &amp; CLIENT_PROTOCOL_41 &#123; string&lt;1&gt; sql_state_marker SQL 状态的标记 string&lt;5&gt; sql_state SQL 状态&#125;string&lt;EOF&gt; error_message 人类可读的错误信息 EOF_Packet 格式int&lt;1&gt; header [fe] EOF headerif capabilities &amp; CLIENT_PROTOCOL_41 &#123; int&lt;2&gt; warnings 警告数 int&lt;2&gt; status_flags 状态标志&#125; 数据包数据类型介绍在上面的数据包格式中，你是不是看到例如 int&lt;1&gt;、string、int 等等这些一头雾水？这个是 MySQL 官网文档中表示协议数据类型和长度的。主要数据类型如下表： 数据类型 字节长度 int&lt;1&gt; 1 字节 int&lt;2&gt; 2 字节 int&lt;3&gt; 3 字节 int&lt;4&gt; 4 字节 int&lt;6&gt; 6 字节 int&lt;8&gt; 8 字节 int&lt;lenenc&gt; 见下文详细介绍 string&lt;lenenc&gt; 见下文详细介绍 string&lt;fix&gt; 固定字节长度的字符串，其中 fix 代表一个指定的数值，例如 string&lt;5&gt;，其中 fix 就等于 5 string&lt;var&gt; 字符串的长度由另一个字段确定或在运行时计算 string&lt;EOF&gt; 如果字符串是数据包的最后一个组成部分，则它的长度可以从整个数据包长度减去当前位置来计算。 string&lt;NUL&gt; 以 [00] 字节结尾的字符串。 在上面的表格中，大部分的数据类型的长度基本上都可以直接得知，但是其中 int&lt;lenenc&gt;、string&lt;lenenc&gt; 这两个类型的长度需要通过稍微复杂一点的计算来得到最终的数据长度。 int&lt;lenenc&gt;当要解析这个长度的数据时，它一般开头的第一个字节有 4 中表现形式 第一个字节的值小于 0xfb：代表这个数据就是这一个字节长度，并且第一个字节的值就是对应字段的值 第一个字节的值等于 0xfc：代表这个字节往后的两个字节就是这个字段的数据，就是说这个字段一个占用 3 个字节长度，其中第 1 个字节表示该字段占用的字节长度数据，第 2 和第 3 个字节表示的是这个字段的数据 第一个字节的值等于 0xfd：和上面类似，只是字段数据字节一共占用 4 个字节，其中后 3 个字节表示这个字段的数据 第一个字节的值等于 0xfe：字段数据字节一共占用 9 个字节，其中后 8 个字节表示这个字段的数据 注意：在 MySQL 3.22 版本以前，0xfe 表示的这个字段只有 4 个字节长度。如果数据包的第一个字节是长度编码的整数并且其字节值为 0xfe，则必须检查数据包的长度以验证它是否有足够的空间容纳 8 字节整数。如果不是，它可能是一个 EOF_Packet 替代。 所以要得到这个字段对应的字节长度时，只要判断第一个字节的数据，然后就可以轻松获得这个字段的长度了 string&lt;lenenc&gt;这个数据类型分为两部分 length (int) – string 数据的占用字节长度 string (string) – [len&#x3D;$length] string 其中 length 这个数据通过上面 int&lt;lenenc&gt; 的方法获得，然后 string 的数据的字节长度就是 length 的值 发送命令当我们连接成功后，这时就可以向服务端发送命令了，命令如下表： HEX 值 NAME 00 COM_SLEEP 01 COM_QUIT 02 COM_INIT_DB 03 COM_QUERY 04 COM_FIELD_LIST 05 COM_CREATE_DB 06 COM_DROP_DB 07 COM_REFRESH 08 COM_SHUTDOWN 09 COM_STATISTICS 0a COM_PROCESS_INFO 0b COM_CONNECT 0c COM_PROCESS_KILL 0d COM_DEBUG 0e COM_PING 0f COM_TIME 10 COM_DELAYED_INSERT 11 COM_CHANGE_USER 12 COM_BINLOG_DUMP 13 COM_TABLE_DUMP 14 COM_CONNECT_OUT 15 COM_REGISTER_SLAVE 16 COM_STMT_PREPARE 17 COM_STMT_EXECUTE 18 COM_STMT_SEND_LONG_DATA 19 COM_STMT_CLOSE 1a COM_STMT_RESET 1b COM_SET_OPTION 1c COM_STMT_FETCH 1d COM_DAEMON 1e COM_BINLOG_DUMP_GTID 1f COM_RESET_CONNECTION 一般我们用的最多的就是 COM_QUERY 这个命令，像 CRUD 都可以通过这个命令来发送，例如我们发送一个查询当前数据库，就可以发送下面的字节数据给服务端 0f 00 00 00 03 73 68 6f 77 20 64 61 74 61 62 6173 65 73 其中前 4 个字节代表这个包的大小和序号 ID，后面的字节数据就是我们发送的命令。03 代表这个命令是 COM_QUERY。后面所有的字节数据都是 show databses 转换 byte 后的字节数据 结果集当你发送的 COM_QUERY 命令时，它返回三种数据包的其中一种。我们可以通过第一个字节来判断它： 当第一个字节数据等于 0x00：返回的是 OK_Packet 当第一个字节的数据等于 0xff：返回的是 ERR_Packet 当第一个字节的数据不是以上两个值时：返回一个结果集，并且第一个字节的值代表返回结果集中列（columns）的总数。 结果集分 3 个部分来读取： 第一个数据包表示返回结果集中列（columns）的总数。 然后通过第一个数据包获取的列总数来读取相关列的所有数据包，一列有一个数据包，比如说上面得到列总数为 3，那么接下来的 3 个数据包就是这 3 列的说明。 读完列的所有数据包后，紧接着就是没行数据的数据包了，一个数据包代表一行数据，每个数据包中有所有列的字段值。其中，如果值长度的值为 0xfe 时，则代表这行中这列的数据为 NULL。行数据直到读取到 OK_Packet&#x2F;EOF_Packet 包出现为止。COM_QUERY_Response 格式// 字节长度计算方法见上面的 int&lt;lenenc&gt; 介绍int&lt;lenenc&gt; 结果集中列（columns）的总数。 列数据包格式列数据包格式也分为两种格式，也是通过客户端上传的 CLIENT_PROTOCOL_41 能力标志来觉得的。如果客户端支持 CLIENT_PROTOCOL_41 这个能力标志，服务端返回 ColumnDefinition41 这个列数据包。如果客户端不支持 CLIENT_PROTOCOL_41 这个能力标志的话，服务端就返回 ColumnDefinition320 这个版本的列数据包。现在一般都使用 ColumnDefinition41 这个数据包，这个数据包描述如下：string&lt;lenenc&gt; catalog 目录 (固定为 &quot;def&quot;)string&lt;lenenc&gt; schema 数据库string&lt;lenenc&gt; table 虚拟表string&lt;lenenc&gt; org_table 源表string&lt;lenenc&gt; name 虚拟名称string&lt;lenenc&gt; org_name 源名称string&lt;lenenc&gt; length of fixed-length fields [0c]2 character set 字符集4 column length 字段的最大长度1 type 列类型2 flags 标志1 decimals 显示的小数位数2 filler [00] [00] 两个空占位符if command was COM_FIELD_LIST &#123; int&lt;lenenc&gt; length of default-values string[$len] default values&#125; 行数据包格式行数据包里面包含了所有列的字段数据，每个列的字段的数据可以通过 string&lt;lenenc&gt; 数据类型的计算的方式获得，其中要注意的是，如果字段长度描述字节的数据等于 0xfe 时，代表这行中这列的数据为 NULL。下图是行数据包的表现形式： 代码实现通过以上的介绍，现在我们可以用代码来实现不用第三方驱动的情况下手动连接 MySQL 服务器，然后发送一条查询 databses 的命令。 下面的是代码片段，完整代码连接：https://gist.github.com/greycodee/22f98464fece7792a83433a1fba58e2a 连接 MySQL 服务器type MySQLClient struct &#123; conn net.Conn addr string username string password string&#125;func (m *MySQLClient) init() &#123; // 连接阶段 handshake := m.startConn() m.sendHandshakeResponse41(handshake)&#125;/* 连接 MySQL 服务器*/func (m *MySQLClient) startConn() *HandshakeV10 &#123; m.conn, _ = net.Dial(&quot;tcp&quot;,m.addr) initResp := make([]byte,1024) readLen, _ := m.conn.Read(initResp) return ReadHandShakeV10(initResp[:readLen])&#125; 解析初始握手数据包/* 解析初始握手包 HandShakeV10*/func ReadHandShakeV10(data []byte) *HandshakeV10 &#123; index := 0 var h = &amp;HandshakeV10&#123;&#125; index+=4 h.ProtocolVersion= int32(data[index]) index++ var serverVersion []byte for data[index]!=0 &#123; serverVersion = append(serverVersion,data[index]) index++ &#125; h.ServerVersion = string(serverVersion) index++ connectByte := data[index:index+4] for i :=range connectByte&#123; h.ConnectionId+=int32(connectByte[i]) &#125; index+=4 var apdp1 []byte apdp1Byte := data[index:index+8] for i := range apdp1Byte &#123; apdp1 = append(apdp1, apdp1Byte[i]) &#125; h.AuthPluginDataPart_1 = string(apdp1) index+=9 // 能力低2位 c_flag_low_1 := strings.Split(fmt.Sprintf(&quot;%b\\n&quot;,data[index+1]),&quot;&quot;) c_flag_low_2 := strings.Split(fmt.Sprintf(&quot;%b\\n&quot;,data[index]),&quot;&quot;) index+=2 // 编码获取 h.CharacterSet = int32(data[index]) index++ // 服务器状态 index+=2 // 能力高2位 c_flag_up_1 := strings.Split(fmt.Sprintf(&quot;%b\\n&quot;,data[index+1]),&quot;&quot;) c_flag_up_2 := strings.Split(fmt.Sprintf(&quot;%b\\n&quot;,data[index]),&quot;&quot;) var capabilityFlags []string capabilityFlags = append(capabilityFlags,c_flag_up_1...) capabilityFlags = append(capabilityFlags,c_flag_up_2...) capabilityFlags = append(capabilityFlags,c_flag_low_1...) capabilityFlags = append(capabilityFlags,c_flag_low_2...) index+=2 if strings.EqualFold(&quot;1&quot;,capabilityFlags[19])&#123; h.AuthPluginDataLen= int32(data[index]) &#125; index++ index+=10 if strings.EqualFold(&quot;1&quot;,capabilityFlags[15])&#123; p2Len := 13 p2len1 := int(h.AuthPluginDataLen-8) if p2Len &lt; p2len1 &#123; p2Len = p2len1 &#125; h.AuthPluginDataPart_2 = string(data[index:index+p2Len]) index+=p2Len &#125; if strings.EqualFold(&quot;1&quot;,capabilityFlags[19]) &#123; var authPlugName []byte for data[index] != 0 &#123; authPlugName = append(authPlugName,data[index]) index++ &#125; h.AuthPluginName = string(authPlugName) &#125; return h&#125;type HandshakeV10 struct &#123; ProtocolVersion int32 `protobuf:&quot;varint,1,opt,name=protocol_version,json=protocolVersion,proto3&quot; json:&quot;protocol_version,omitempty&quot;` ServerVersion string `protobuf:&quot;bytes,2,opt,name=server_version,json=serverVersion,proto3&quot; json:&quot;server_version,omitempty&quot;` ConnectionId int32 `protobuf:&quot;varint,3,opt,name=connection_id,json=connectionId,proto3&quot; json:&quot;connection_id,omitempty&quot;` AuthPluginDataPart_1 string `protobuf:&quot;bytes,4,opt,name=auth_plugin_data_part_1,json=authPluginDataPart1,proto3&quot; json:&quot;auth_plugin_data_part_1,omitempty&quot;` CharacterSet int32 `protobuf:&quot;varint,6,opt,name=character_set,json=characterSet,proto3&quot; json:&quot;character_set,omitempty&quot;` StatusFlags int32 `protobuf:&quot;varint,7,opt,name=status_flags,json=statusFlags,proto3&quot; json:&quot;status_flags,omitempty&quot;` AuthPluginDataLen int32 `protobuf:&quot;varint,8,opt,name=auth_plugin_data_len,json=authPluginDataLen,proto3&quot; json:&quot;auth_plugin_data_len,omitempty&quot;` AuthPluginDataPart_2 string `protobuf:&quot;bytes,9,opt,name=auth_plugin_data_part_2,json=authPluginDataPart2,proto3&quot; json:&quot;auth_plugin_data_part_2,omitempty&quot;` AuthPluginName string `protobuf:&quot;bytes,10,opt,name=auth_plugin_name,json=authPluginName,proto3&quot; json:&quot;auth_plugin_name,omitempty&quot;`&#125; 发送初始响应数据包/* 发送初始响应数据包 HandshakeResponse41，包含登陆信息*/func (m *MySQLClient) sendHandshakeResponse41(serverResp *HandshakeV10) &#123; resp := make([]byte,0) resp = append(resp, Int32ToBytesOfLittle(19833351)...) resp = append(resp, Int32ToBytesOfLittle(16777215)...) resp = append(resp, 33) reserved := make([]byte,23) resp = append(resp, reserved...) resp = append(resp, []byte(m.username)...) resp = append(resp, 0) resp = append(resp, 20) resp = append(resp, CalcPassword([]byte(serverResp.AuthPluginDataPart_1+serverResp.AuthPluginDataPart_2)[:20],[]byte(m.password))...) resp = append(resp, []byte(&quot;mysql_native_password&quot;)...) resp = append(resp, 0) _, _ = m.conn.Write(Pack(resp,1)) flag := m.handleResponse() if flag == 0xff &#123; panic(&quot;连接失败&quot;) &#125; return&#125; 判断连接结果/* 解析通用响应数据包 OK_Packet、ERR_Packet、数据集*/func (m *MySQLClient) handleResponse() uint8 &#123; resp := make([]byte,1024) readLen, _ := m.conn.Read(resp) data := resp[:readLen] data = data[4:] switch data[0] &#123; case 0x00: fmt.Println(&quot;成功&quot;) return 0x00 case 0xff: fmt.Println(&quot;失败&quot;) return 0xff default: parseResultSet(data) return 0xfe &#125;&#125; 发送命令/* CommandQuery 发送 COM_QUERY 命令，并读取数据*/func (m *MySQLClient) CommandQuery(sql string) &#123; resp := make([]byte,0) resp = append(resp, 3) resp = append(resp, []byte(sql)...) _, _ = m.conn.Write(Pack(resp,0)) m.handleResponse()&#125; 解析结果集func parseResultSet(resp []byte) &#123; index := 0 fieldLen := resp[0] index+=1 headRows := make([]string,0) headIndex := 1 // 读取列数据 for headIndex &lt;= int(fieldLen)&#123; n,l := readColumn(resp,index) index+=l headRows = append(headRows, n) headIndex++ &#125; table, err := gotable.Create(headRows...) if err != nil &#123; fmt.Println(&quot;Create table failed: &quot;, err.Error()) return &#125; // 读取行内容 for &#123; // 判断是否是 EOF 数据包 if resp[index+4] == 0xfe&#123; packLen := 0 for _,v :=range resp[index:index+3]&#123; packLen+=int(v) &#125; if packLen&lt;9 &#123; break &#125; &#125; rows,ll := readRow(resp,index, int(fieldLen)) table.AddRow(rows) index+=ll &#125; // 打印 fmt.Println(table)&#125;func readColumn(data []byte, startIndex int) (name string,length int) &#123; packLen := data[startIndex:startIndex+3] for i :=range packLen&#123; length+=int(packLen[i]) &#125; length += 4 startIndex+=4 startIndex+=int(data[startIndex]+1) startIndex+=int(data[startIndex]+1) startIndex+=int(data[startIndex]+1) startIndex+=int(data[startIndex]+1) nameLen := int(data[startIndex]) name = string(data[startIndex+1:startIndex+nameLen+1]) return&#125;func readRow(data []byte, startIndex int, fieldNum int) (name []string,length int) &#123; packLen := data[startIndex:startIndex+3] for i :=range packLen&#123; length+=int(packLen[i]) &#125; length += 4 startIndex+=4 f:=0 for f &lt; fieldNum&#123; dataLen := 0 // 计算字节数据长度 if data[startIndex] &lt; 0xfb &#123; // NULL dataLen = int(data[startIndex]) &#125;else if data[startIndex] == 0xfc &#123; for _,v := range data[startIndex+1:startIndex+3]&#123; dataLen+=int(v) &#125; &#125;else if data[startIndex] == 0xfd &#123; for _,v :=range data[startIndex+1:startIndex+5]&#123; dataLen+=int(v) &#125; &#125;else if data[startIndex] == 0xfe &#123; for _,v :=range data[startIndex+1:startIndex+9]&#123; dataLen+=int(v) &#125; &#125; name = append(name, string(data[startIndex+1:startIndex+dataLen+1])) startIndex += dataLen+1 f++ &#125; return&#125; 控制台结果输出执行上面的代码后，控制台就会输出所有的数据库名字 +--------------------+| Database |+--------------------+| information_schema || greycode || mysql || performance_schema || sys |+--------------------+ 参考资料https://dev.mysql.com/doc/internals/en/client-server-protocol.html","categories":[{"name":"协议","slug":"协议","permalink":"https://greycode.top/categories/%E5%8D%8F%E8%AE%AE/"}],"tags":[{"name":"协议","slug":"协议","permalink":"https://greycode.top/tags/%E5%8D%8F%E8%AE%AE/"},{"name":"MySQL","slug":"MySQL","permalink":"https://greycode.top/tags/MySQL/"}]},{"title":"什么是P2P网络","slug":"archive/FA21243A47644D98B4380AE439D2A69F","date":"2022-02-22T15:08:04.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"archive/FA21243A47644D98B4380AE439D2A69F/","link":"","permalink":"https://greycode.top/archive/FA21243A47644D98B4380AE439D2A69F/","excerpt":"","text":"NAT 类型Full Cone NAT全锥形 NAT 是将来自相同内部 IP 地址和端口的所有请求映射到相同的外部 IP 地址和端口。此外，任何外部主机都可以通过向映射的外部地址发送数据包来向内部主机发送数据包。 Restricted Cone NAT受限锥形 NAT 是将来自相同内部 IP 地址和端口的所有请求映射到相同的外部 IP 地址和端口。与完整的锥形 NAT 不同，外部主机（IP 地址为 X）只有在内部主机先前已向 IP 地址 X 发送数据包时才能向内部主机发送数据包。 Port Restricted Cone NAT端口受限锥形 NAT 类似于受限锥形 NAT，但限制包括端口号。具体来说，只有当内部主机之前已经向 IP 地址 X 和端口 P 发送了数据包时，外部主机才能向内部主机发送源 IP 地址为 X 和源端口 P 的数据包 Symmetric NAT对称 NAT 是一种从相同内部 IP 地址和端口到特定目标 IP 地址和端口的所有请求都映射到相同外部 IP 地址和端口的一种。如果同一主机发送具有相同源地址和端口的数据包，但发送到不同的目的地，则使用不同的映射。此外，只有收到数据包的外部主机才能将 UDP 数据包发送回内部主机。 Hole Punching使用先前建立的关联来允许任意外部地址&#x2F;端口向内部地址&#x2F;端口发送数据称为打孔。使用普通（全锥）、受限和端口受限 NAT 可以进行打孔，这些 NAT 将相同的内部地址&#x2F;端口一致地映射到外部地址&#x2F;端口。 注意： 纯对称 NAT 无法进行打孔，因为它们的目标特定端口映射行为不一致。 STUN 和 TURN参考资料https://dh2i.com/wp-content/uploads/NAT_types.png","categories":[{"name":"网络","slug":"网络","permalink":"https://greycode.top/categories/%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"P2P","slug":"P2P","permalink":"https://greycode.top/tags/P2P/"},{"name":"网络","slug":"网络","permalink":"https://greycode.top/tags/%E7%BD%91%E7%BB%9C/"}]},{"title":"centos 多网卡配置优先级","slug":"linux/0A5A3927BAEA4155849C174E4C613913","date":"2021-09-01T15:47:14.000Z","updated":"2022-04-16T02:52:58.653Z","comments":true,"path":"linux/0A5A3927BAEA4155849C174E4C613913/","link":"","permalink":"https://greycode.top/linux/0A5A3927BAEA4155849C174E4C613913/","excerpt":"","text":"过程 查看网卡配置 [root@localhost ~]# ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever2: em1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP group default qlen 1000 link/ether 34:17:eb:f0:18:8f brd ff:ff:ff:ff:ff:ff inet 192.168.0.84/24 brd 192.168.0.255 scope global noprefixroute em1 valid_lft forever preferred_lft forever inet6 240e:390:c6a:c3a0:3617:ebff:fef0:188f/64 scope global noprefixroute dynamic valid_lft 259182sec preferred_lft 172782sec inet6 fe80::3617:ebff:fef0:188f/64 scope link noprefixroute valid_lft forever preferred_lft forever3: em2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP group default qlen 1000 link/ether 34:17:eb:f0:18:90 brd ff:ff:ff:ff:ff:ff inet 192.169.0.10/23 brd 192.169.1.255 scope global noprefixroute em2 valid_lft forever preferred_lft forever inet6 fe80::3617:ebff:fef0:1890/64 scope link noprefixroute valid_lft forever preferred_lft forever4: docker0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default link/ether 02:42:b1:66:84:26 brd ff:ff:ff:ff:ff:ff inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0 valid_lft forever preferred_lft forever inet6 fe80::42:b1ff:fe66:8426/64 scope link valid_lft forever preferred_lft forever12: veth4ffa8ca@if11: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master docker0 state UP group default link/ether ca:d7:f0:2f:42:f0 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet6 fe80::c8d7:f0ff:fe2f:42f0/64 scope link valid_lft forever preferred_lft forever14: veth9c158d5@if13: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master docker0 state UP group default link/ether 76:ab:49:a9:e4:a6 brd ff:ff:ff:ff:ff:ff link-netnsid 1 inet6 fe80::74ab:49ff:fea9:e4a6/64 scope link valid_lft forever preferred_lft forever 这里有 em1 和 em2 两张网卡 查看网卡路由 [root@localhost ~]# ip route showdefault via 192.168.0.1 dev em1 proto static metric 100default via 192.169.0.1 dev em2 proto static metric 101172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1192.168.0.0/24 dev em1 proto kernel scope link src 192.168.0.84 metric 100192.169.0.0/23 dev em2 proto kernel scope link src 192.169.0.10 metric 101 可以看到，em1 的 metric 大于 em2 ， metric 值越低，优先级越高。 Metric 为路由指定所需跃点数的整数值（范围是 1 ~ 9999），它用来在路由表里的多个路由中选择与转发包中的目标地址最为匹配的路由。所选的路由具有最少的跃点数。跃点数能够反映跃点的数量、路径的速度、路径可靠性、路径吞吐量以及管理属性。Metric 的值越小，优先级越高，如果两块网卡的Metric的值相同，就会出现抢占优先级继而网卡冲突，将会有一块网卡无法连接。 更改优先级 现在要设置 em2 的优先级比 em1 的高，只需要更改 em2 网卡配置的 metric 值比 em1 的低就可以了 修改 em2 网卡配置： 配置文件地址：vim /etc/sysconfig/network-scripts/ifcfg-em2 添加配置: IPV4_ROUTE_METRIC=90 TYPE=EthernetBOOTPROTO=staticDEFROUTE=yesPEERDNS=yesPEERROUTES=yesIPV4_FAILURE_FATAL=noIPV4_ROUTE_METRIC=90IPV6INIT=yesIPV6_AUTOCONF=yesIPV6_DEFROUTE=yesIPV6_PEERDNS=yesIPV6_PEERROUTES=yesIPV6_FAILURE_FATAL=noNAME=em2UUID=23420496-e9ed-466c-a8fc-e99b091f3a00DEVICE=em2ONBOOT=yesIPADDR=192.169.0.10NETMASK=255.255.254.0GATEWAY=192.169.0.1DNS1=114.114.114.114 重启网卡 # 刷新配置文件source /etc/sysconfig/network-scripts/ifcfg-em2# 关闭 em2 网卡ifdown em2# 开启 em2 网卡ifup em2","categories":[{"name":"Linux","slug":"Linux","permalink":"https://greycode.top/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://greycode.top/tags/Linux/"},{"name":"Centos","slug":"Centos","permalink":"https://greycode.top/tags/Centos/"}]},{"title":"用 Json-Schema 来验证你的请求参数","slug":"tool/775FF9A0CE4940EBBB45FED3FAD7AB5B","date":"2021-08-19T16:40:05.000Z","updated":"2022-04-16T02:52:58.653Z","comments":true,"path":"tool/775FF9A0CE4940EBBB45FED3FAD7AB5B/","link":"","permalink":"https://greycode.top/tool/775FF9A0CE4940EBBB45FED3FAD7AB5B/","excerpt":"","text":"简介Json-Schema 是一个用来验证、描述 Json 数据的一个标准，它可以用来验证你的请求数据是否和你定义的 Schema 是否一致。比如下面的 Json 数据中： &#123; &quot;name&quot;:&quot;greycode&quot;, &quot;desc&quot;:&quot;coder&quot;&#125; 如果不预先告诉你字段的含义，你知道 name 是什么意思吗？它到底是指人名还是一个物品的名字还是其他？desc 又是什么意思呢？ 这时候，就可以用 Json-Schema 来描述它了 &#123; &quot;$schema&quot;: &quot;http://json-schema.org/draft-07/schema&quot;, &quot;$id&quot;: &quot;http://example.com/example.json&quot;, &quot;type&quot;: &quot;object&quot;, &quot;title&quot;: &quot;这是一个Json数据&quot;, &quot;description&quot;: &quot;描述个人信息的数据&quot;, &quot;required&quot;: [ &quot;name&quot;, &quot;desc&quot; ], &quot;properties&quot;: &#123; &quot;name&quot;: &#123; &quot;type&quot;: &quot;string&quot;, &quot;description&quot;: &quot;人的姓名&quot;, &#125;, &quot;desc&quot;: &#123; &quot;type&quot;: &quot;string&quot;, &quot;description&quot;: &quot;个人简介&quot;, &#125; &#125;&#125; 上面我们用 Json-Schema 来描述了刚开始的 Json 数据，这样就可以清楚的知道 name 是人的姓名，desc 是个人简介，在也不用自己去猜了。 Json Schema 字段说明在上面的 Json-Schema 数据中，每个字段都有其的含义 $schema ：主要用于版本控制 $id ：定义字段在 schema 中的地址 title 和 description ：用于描述和说明 Schema 的作用 type ：定义字段的数据类型 required ：Json 数据中包含的字段 …… 由于 Json-Schema 有许多草案，每个草案的字段都有一点区别，具体可以看一下的草案资料： 草案 2019-09 迁移 草案 2020-12 草案-07 迁移 草案 2019-09 草案-06 迁移 草案-07 草案-04 迁移 草案-06 文档说明 所有草案版本文档 使用 Json-Schema 验证 Json 数据 Json-Schema 支持多种语言的验证器，一般都是第三方实现的，这里我们使用 Java 验证器来验证一个 Json 数据，Java 验证器这里选用了 everit-org&#x2F;json-schema 验证器来使用，不过它最高支持到草案7，像最新的草案2020-12它是不支持的。 Java 验证 Json 数据导入依赖： &lt;dependency&gt; &lt;groupId&gt;com.github.everit-org.json-schema&lt;/groupId&gt; &lt;artifactId&gt;org.everit.json.schema&lt;/artifactId&gt; &lt;version&gt;1.13.0&lt;/version&gt;&lt;/dependency&gt;...&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;jitpack.io&lt;/id&gt; &lt;url&gt;https://jitpack.io&lt;/url&gt; &lt;/repository&gt;&lt;/repositories&gt; 导入所需依赖，由于这个包没有上传到中央仓库，所以要设置仓库地址 代码实现： 导入依赖后就可以用代码来实现一个使用 Json-Schema 验证 Json 数据的功能了 try &#123; String jsonSchema = &quot;&#123;\\n&quot; + &quot; \\&quot;$schema\\&quot;: \\&quot;http://json-schema.org/draft-07/schema\\&quot;,\\n&quot; + &quot; \\&quot;$id\\&quot;: \\&quot;http://example.com/example.json\\&quot;,\\n&quot; + &quot; \\&quot;type\\&quot;: \\&quot;object\\&quot;,\\n&quot; + &quot; \\&quot;title\\&quot;: \\&quot;这是一个Json数据\\&quot;,\\n&quot; + &quot; \\&quot;description\\&quot;: \\&quot;描述个人信息的数据\\&quot;,\\n&quot; + &quot; \\&quot;required\\&quot;: [\\n&quot; + &quot; \\&quot;name\\&quot;,\\n&quot; + &quot; \\&quot;desc\\&quot;\\n&quot; + &quot; ],\\n&quot; + &quot; \\&quot;properties\\&quot;: &#123;\\n&quot; + &quot; \\&quot;name\\&quot;: &#123;\\n&quot; + &quot; \\&quot;type\\&quot;: \\&quot;string\\&quot;,\\n&quot; + &quot; \\&quot;description\\&quot;: \\&quot;人的姓名\\&quot;,\\n&quot; + &quot; &#125;,\\n&quot; + &quot; \\&quot;desc\\&quot;: &#123;\\n&quot; + &quot; \\&quot;type\\&quot;: \\&quot;string\\&quot;,\\n&quot; + &quot; \\&quot;description\\&quot;: \\&quot;个人简介\\&quot;,\\n&quot; + &quot; &#125;\\n&quot; + &quot; &#125;\\n&quot; + &quot;&#125;&quot;; JSONObject jsonObject = new JSONObject(new JSONTokener(jsonSchema)); Schema schema = SchemaLoader.load(jsonObject); schema.validate(new JSONObject(&quot;&#123;\\n&quot; + &quot; \\&quot;name\\&quot;:\\&quot;greycode\\&quot;,\\n&quot; + &quot; \\&quot;desc\\&quot;:\\&quot;coder\\&quot;\\n&quot; + &quot;&#125;&quot;));&#125;catch (Exception e)&#123; System.out.println(&quot;验证异常：&quot;+e.getMessage());&#125; 这里用了上面的 Json 数据和 Json-Schema，当验证通过时，不会有任何输出，同时也没有任何异常。 当我们把 desc 的数据改为如下数据时： &#123; &quot;name&quot;:&quot;greycode&quot;, &quot;desc&quot;:1&#125; 此时由于 desc 的数据类型变为了数字类型，所以我们就可以捕获到异常并输出：验证异常：#/desc: expected type: String, found: Integer 资料 所有的第三方 Json-Schema 验证器：https://json-schema.org/implementations.html#validators Jaon-Schema 生成器：https://json-schema.org/implementations.html#schema-generators 通过 Json-Schema 生成代码、数据等：https://json-schema.org/implementations.html#generators-from-schemas 在线 Json 转换 Json-Schema ：https://www.jsonschema.net/home https://json-schema.org/","categories":[{"name":"Tool","slug":"Tool","permalink":"https://greycode.top/categories/Tool/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/tags/Java/"},{"name":"Json-Schema","slug":"Json-Schema","permalink":"https://greycode.top/tags/Json-Schema/"},{"name":"参数验证","slug":"参数验证","permalink":"https://greycode.top/tags/%E5%8F%82%E6%95%B0%E9%AA%8C%E8%AF%81/"}]},{"title":"AviatorScript轻量级高性能脚本语言","slug":"java/CA3AB1D58EA74B76A5FD69F79DD5EC79","date":"2021-08-17T16:10:53.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"java/CA3AB1D58EA74B76A5FD69F79DD5EC79/","link":"","permalink":"https://greycode.top/java/CA3AB1D58EA74B76A5FD69F79DD5EC79/","excerpt":"","text":"简介在 5.0 版本以前，它的名字是叫 Aviator ，定位一直只是一个表达式引擎，不支持 if&#x2F;else 条件语句（仅有三元运算符支持 ?: ），没有内置的 for&#x2F;while 循环支持（虽然你可以用 seq 库类似函数式的方式来处理集合），也没有赋值（后来在 4.0 引入），没有作用域的概念（也在 4.0 引入 lambda 函数后部分实现）等等一般语言常见的能力。在 5.0 版本后，它变成了一门脚本语言，叫：AviatorScript 。 在 5.0 ，新加了如下新特性： 大括号 &#123; ... &#125; 括起来的词法作用域。 let 语句用于定义局部变量。 条件语句 if/elsif/else 。 循环语句 for 和 while ，以及相应的 break 和 continue 语句支持。 return 语句用于从脚本或者函数中返回值。 fn hello() &#123; println(&quot;hello&quot;); &#125; 新的 fn 语法用于定义命名函数。 ## 单行注释 注释支持 模块系统 new 语法用于创建对象 异常处理 命令行工具 aviator 使用AviatorScript 可以单纯的作为脚本语言使用，也可以和 Java 配合使用。 单纯的作为脚本语言使用作为脚本语言使用时，需要下载一个 aviator，然后用它去执行脚本文件。 下载： 执行下面命令下载，如果你电脑没有安装 wget 工具，你也可以直接打开 https://raw.githubusercontent.com/killme2008/aviator/master/bin/aviator，然后把里面的内容复制下来保存成一个可执行文件。**然后把它放在环境变量中，可以全局访问到它** $ wget https://raw.githubusercontent.com/killme2008/aviator/master/bin/aviator$ chmod u+x aviator 初始化： 下载完后，需要执行一下命令，它会自动在 ~/.aviatorscrip 下载所需要的依赖。 ╰─$ aviatorDownloading AviatorScript now... % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed100 148 100 148 0 0 249 0 --:--:-- --:--:-- --:--:-- 248100 159 100 159 0 0 158 0 0:00:01 0:00:01 --:--:-- 158100 583k 100 583k 0 0 51321 0 0:00:11 0:00:11 --:--:-- 35877Usage: java com.googlecode.aviator.Main [file] [args] : java com.googlecode.aviator.Main -e [script] : java com.googlecode.aviator.Main -v 执行脚本文件： 下载好相关的环境后，就可以编写一个脚本文件了，文件名一般以 .av 结尾，这个不是必须的，你想以其他结尾也可以 test.av： println(&quot;Hello World!&quot;); 然后执行该脚本文件： ╰─$ aviator test.avHello World!null 界面输出 Hello World!，最后一行的 null 表示是整个表达式的执行结果，就是返回值的意思，比如定义 return 时，这个 null 就会变成 return 的值，我们做如下更改： test.av： println(&quot;Hello World!&quot;);return &quot;success&quot;; 我们添加了一个 return 数据，然后执行这个脚本文件： ╰─$ aviator test.avHello World!success 执行结果就会变成我们定义的 return 数据。 具体的可参考文档 aviator 命令行 配合 Java 使用配合 Java 使用时，需要导入 Aviator 的依赖，可以在 [search.maven.org](https://search.maven.org/search?q=g:com.googlecode.aviator AND a:aviator&amp;core&#x3D;gav) 查看可用的版本。 &lt;dependency&gt; &lt;groupId&gt;com.googlecode.aviator&lt;/groupId&gt; &lt;artifactId&gt;aviator&lt;/artifactId&gt; &lt;version&gt;&#123;version&#125;&lt;/version&gt;&lt;/dependency&gt; 导入依赖后，我们先来演示执行一个 1+1 操作： int result = (int) AviatorEvaluator.execute(&quot;return 1+1;&quot;);System.out.println(result); 上面代码中，我们直接返回 1+1 的结果，然后输出，但是当我们执行的时候，就回报如下错误： Exception in thread &quot;main&quot; java.lang.ClassCastException: java.lang.Long cannot be cast to java.lang.Integer at top.mjava.demo.AviatorDemo.demo5(AviatorDemo.java:19) at top.mjava.demo.AviatorDemo.main(AviatorDemo.java:15) 这是因为在 Aviator 中任何整数都将被转换为 Long 类型，而 Long 类型是不能转换为 Integer 类型的，所以会报上面的错误。所以我们要将 int 改为 long 即可： long result = (long) AviatorEvaluator.execute(&quot;return 1+1;&quot;);System.out.println(result); 输出： 2 挂载 Java 方法在 Aviator 中，除了可以使用它提供的法来创建函数外，还可以挂载 Java 的自定义方法，然后在 Aviator 脚本中使用。 定义自定义的 Java 方法时，需要继承 AbstractFunction 抽象类，然后重写 call 和 getName 这两个方法： call : 方法具体逻辑代码 getName : 在 Aviator 中使用时的函数名 定义自定义函数： 这边自定义了一个加法运算的方法，传入两个参数然后计算它们的和 class AddFunction extends AbstractFunction&#123; @Override public AviatorObject call(Map&lt;String, Object&gt; env, AviatorObject arg1, AviatorObject arg2) &#123; long p1 = (long) arg1.getValue(env); long p2 = (long) arg2.getValue(env); long result = p1+p2; return AviatorLong.valueOf(result); &#125; @Override public String getName() &#123; return &quot;add&quot;; &#125;&#125; 使用自定义函数： 如果要在 Aviator 脚本中使用这个自定义的函数时，需要先注册这个 Java 类，然后在 Aviator 脚本中使用 getName() 返回的方法名作为函数名来调用： // 注册自定义函数AviatorEvaluator.addFunction(new AddFunction());// 使用自定义函数long result = (long) AviatorEvaluator.execute(&quot;return add(2,1);&quot;);System.out.println(result); 输出： 3 参考资料 https://www.yuque.com/boyan-avfmj/aviatorscript/cpow90 https://code.google.com/archive/p/aviator/wikis/User_Guide_zh.wiki https://github.com/killme2008/aviatorscript","categories":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/tags/Java/"},{"name":"表达式引擎","slug":"表达式引擎","permalink":"https://greycode.top/tags/%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%BC%95%E6%93%8E/"},{"name":"Aviator","slug":"Aviator","permalink":"https://greycode.top/tags/Aviator/"}]},{"title":"ZooKeeper单机伪集群搭建","slug":"archive/zookeeper/2B9475B258994C18BCC5FCFA4B6D81D2","date":"2021-08-11T15:59:52.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"archive/zookeeper/2B9475B258994C18BCC5FCFA4B6D81D2/","link":"","permalink":"https://greycode.top/archive/zookeeper/2B9475B258994C18BCC5FCFA4B6D81D2/","excerpt":"","text":"Error contacting service. It is probably not running.","categories":[{"name":"ZooKeeper","slug":"ZooKeeper","permalink":"https://greycode.top/categories/ZooKeeper/"}],"tags":[{"name":"集群","slug":"集群","permalink":"https://greycode.top/tags/%E9%9B%86%E7%BE%A4/"},{"name":"分布式","slug":"分布式","permalink":"https://greycode.top/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"ZooKeeper","slug":"ZooKeeper","permalink":"https://greycode.top/tags/ZooKeeper/"}]},{"title":"ZooKeeper客户端详解及可视化客户端","slug":"archive/zookeeper/8B8235DEF437432C99C81E97D68D0644","date":"2021-08-09T14:54:39.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"archive/zookeeper/8B8235DEF437432C99C81E97D68D0644/","link":"","permalink":"https://greycode.top/archive/zookeeper/8B8235DEF437432C99C81E97D68D0644/","excerpt":"","text":"下载我们可以去 ZooKeeper 官网 下载，这里我下载了 ZooKeeper 3.7.0 版本 下载解压后，进入 apache-zookeeper-3.7.0-bin/bin 目录，这里有客户端、服务端和一些工具。在 Windows 中可以执行.cmd 结尾的执行文件，在 Mac 或 Linux 中可以执行 .sh 结尾的可执行文件。名为 zkCli 的文件就是 ZooKeeper 的客户端了，我们可以用这个客户端来连接到 ZooKeeper 注册中心，来对节点进行查看或增删操作。 使用 我是在 Mac 环境下演示使用的 接下来就说下这个客户端怎么使用。 连接第一步就是要连接到 ZooKeeper 服务，当你执行 zkCli.sh 不带任何参数时，它默认是连接到本地的 localhost:2181 地址。如果你要连接到指定地址，可以使用 -server 配置： ./zkCli.sh -server localhost:2181# 还可以加上连接超时时间（单位：毫秒）./zkCli.sh -timeout 3000 -server localhost:2181 连接上后，终端就会变成这样： [zk: localhost:2181(CONNECTED) 0] 然后你可以输入 help 来查看执行的命令： ZooKeeper -server host:port -client-configuration properties-file cmd args addWatch [-m mode] path # optional mode is one of [PERSISTENT, PERSISTENT_RECURSIVE] - default is PERSISTENT_RECURSIVE addauth scheme auth close config [-c] [-w] [-s] connect host:port create [-s] [-e] [-c] [-t ttl] path [data] [acl] delete [-v version] path deleteall path [-b batch size] delquota [-n|-b|-N|-B] path get [-s] [-w] path getAcl [-s] path getAllChildrenNumber path getEphemerals path history listquota path ls [-s] [-w] [-R] path printwatches on|off quit reconfig [-s] [-v version] [[-file path] | [-members serverID=host:port1:port2;port3[,...]*]] | [-add serverId=host:port1:port2;port3[,...]]* [-remove serverId[,...]*] redo cmdno removewatches path [-c|-d|-a] [-l] set [-s] [-v version] path data setAcl [-s] [-v version] [-R] path acl setquota -n|-b|-N|-B val path stat [-w] path sync path version whoami 在客户端里面，也可以使用命令 connect 来切换连接的 ZooKeeper 的服务地址： [zk: localhost:2181(CONNECTED) 12] connect localhost:2181 创建节点永久节点可以使用 create 命令来创建一个永久节点： [zk: localhost:2181(CONNECTED) 18] create /nodeCreated /node 临时节点临时节点当客户端断开后，这个节点就会被删除 [zk: localhost:2181(CONNECTED) 19] create -e /tmp_nodeCreated /tmp_node 临时节点不能够有子节点，当要创建它的子节点时就会报错 Ephemerals cannot have children : [zk: localhost:2181(CONNECTED) 20] create -e /tmp_node/t1Ephemerals cannot have children: /tmp_node/t1 顺序节点ZooKeeper 可以为我们自定创建递增的顺序节点 [zk: localhost:2181(CONNECTED) 23] create -s /seq_nodeCreated /seq_node0000000017[zk: localhost:2181(CONNECTED) 24] create -s /seq_nodeCreated /seq_node0000000018[zk: localhost:2181(CONNECTED) 25] create -s /seq_nodeCreated /seq_node0000000019 容器节点容器节点当其子所有节点都被删除时，它自己也会被删除 # 创建容器节点[zk: localhost:2181(CONNECTED) 39] create -c /containerCreated /container# 创建容器节点的子节点[zk: localhost:2181(CONNECTED) 43] create /container/c1Created /container/c1[zk: localhost:2181(CONNECTED) 44] create /container/c2Created /container/c2# 删除容器节点的子节点[zk: localhost:2181(CONNECTED) 46] delete /container/c1[zk: localhost:2181(CONNECTED) 47] delete /container/c2# 过了一会后，容器节点被删除了[zk: localhost:2181(CONNECTED) 56] get /containerorg.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /container ttl 节点ZooKeeper 也可以为节点设置有效期，单位是毫秒。要创建这个节点时，需要 ZooKeeper 服务端在启动时设置 zookeeper.extendedTypesEnabled=true ，否则在创建时就会失败：KeeperErrorCode = Unimplemented 创建时设置的过期时间单位时毫秒： [zk: localhost:2181(CONNECTED) 57] create -t 3000 /ttl_nodeCreated /ttl_node 删除节点在 zkCli 中可以用 delete 命令来删除节点，在删除一个节点时，必须保证该节点下面没有子节点 [zk: localhost:2181(CONNECTED) 6] create /node1Created /node1[zk: localhost:2181(CONNECTED) 7] delete /node1# 如果有子节点的话，删除时会报错[zk: localhost:2181(CONNECTED) 10] create /node1Created /node1[zk: localhost:2181(CONNECTED) 11] create /node1/n1Created /node1/n1[zk: localhost:2181(CONNECTED) 12] delete /node1Node not empty: /node1 如果你想一次性删除节点包括其所有子节点时，可以使用 deleteall 命令来进行删除 [zk: localhost:2181(CONNECTED) 14] deleteall /node1 查看节点查看所有子节点我们可以用 ls 命令来查看某个节点的所有子节点，比如我们查看根目录下的所有节点时，就可以这样用： [zk: localhost:2181(CONNECTED) 20] ls /[quota, zookeeper] 查看 zookeeper 节点的子节点 [zk: localhost:2181(CONNECTED) 21] ls /zookeeper[config, quota] 查看节点的状态可以用 stat 来查看一个节点的状态，比如我们查看根节点的状态时： [zk: localhost:2181(CONNECTED) 22] stat /cZxid = 0x0ctime = Thu Jan 01 08:00:00 CST 1970mZxid = 0x0mtime = Thu Jan 01 08:00:00 CST 1970pZxid = 0xecversion = 4dataVersion = 0aclVersion = 0ephemeralOwner = 0x0dataLength = 0numChildren = 2 字段说明： 字段 描述 czxid 创建znode的zxid mzxid 最近一次修改znode的zxid(创建、删除、set直系子节点、set自身节点都会计数) pzxid 最近一次修改子节点的zxid(创建、删除直系子节点都会计数，set子节点不会计数) ctime 创建znode的时间，单位毫秒 mtime 最近一次修改znode的时间，单位毫秒 dataVersion 修改znode数据的次数 cversion 修改子节点的次数(创建、删除直系子节点都会计数，set子节点不会计数) aclVersion 该znode的ACL修改次数 ephemeralOwner 临时znode节点的session id，如果不是临时节点，值为0 dataLength znode携带的数据长度，单位字节 numChildren 直系子节点的数量(不会递归计算孙节点) 查看节点的数据可以使用 set 命令来设置节点的数据，当要获取这个设置的数据时，就可以使用 get 命令来获取节点的数据 [zk: localhost:2181(CONNECTED) 27] create /nodeCreated /node[zk: localhost:2181(CONNECTED) 28] set /node 我的数据[zk: localhost:2181(CONNECTED) 29] get /node我的数据 终端可视化客户端 下载地址：https://github.com/greycodee/zk-cli/releases Github：https://github.com/greycodee/zk-cli","categories":[{"name":"ZooKeeper","slug":"ZooKeeper","permalink":"https://greycode.top/categories/ZooKeeper/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://greycode.top/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"ZooKeeper","slug":"ZooKeeper","permalink":"https://greycode.top/tags/ZooKeeper/"}]},{"title":"小白学前端之TypeScript使用Vuex 4.0","slug":"vue/2CA7C67D02E74713A030F09651A5F164","date":"2021-07-29T16:45:15.000Z","updated":"2022-04-16T02:52:58.653Z","comments":true,"path":"vue/2CA7C67D02E74713A030F09651A5F164/","link":"","permalink":"https://greycode.top/vue/2CA7C67D02E74713A030F09651A5F164/","excerpt":"","text":"简介官方介绍：Vuex 是一个专为 Vue.js 应用程序开发的状态管理模式。它采用集中式存储管理应用的所有组件的状态，并以相应的规则保证状态以一种可预测的方式发生变化。 简单来说，Vuex 就像是前端的数据库或缓存，不管什么页面，只要 Vuex 里面有的数据，都可以去拿。 Vuex 分为 5 个部分： State：是数据源，存放数据 Getters：可以取得 State 的数据，然后自定义组装返回新的数据 Mutations：可以改变 State 的数据，建议方法执行是同步的 Actions：可以异步执行 Mutations 里的方法 Modules：每个 Module 都有各自的 State、Getters、Mutations、Actions 这 5 个部分相辅相成。 TypeScript 使用在 vue 项目根目录执行命令来进行 vuex 模块的安装 npm install vuex@next --save 安装好后我们新建文件 /src/store/store.ts ,然后在里面定义 InjectionKey 和 Store import &#123; InjectionKey &#125; from &#x27;vue&#x27;import &#123; createStore, useStore as baseUseStore, Store &#125; from &#x27;vuex&#x27;// 定义 State 数据类型的接口interface IState&#123;&#125;// 类型传递export const key: InjectionKey&lt;Store&lt;IState&gt;&gt; = Symbol()export const store = createStore&lt;IState&gt; (&#123; &#125;)// 用于组合式API setup() 里，省的每次都传入 key export function useStore() &#123; return baseUseStore(key)&#125; 然后在 main.ts 文件里使用上面定义的 vuex import &#123; createApp &#125; from &#x27;vue&#x27;import App from &#x27;./App.vue&#x27;import &#123; store,key &#125; from &#x27;./store/store&#x27;createApp(App).use(store,key).mount(&#x27;#app&#x27;) StateState 是存储数据源的地方，所以我们可以在这里存储我们的数据，比如我这边定义一个 name 字段，需要在接口 IState 添加定义数据类型 interface IState&#123; name: string&#125; 然后在 createStore 里添加数据 export const store = createStore&lt;IState&gt; (&#123; state:&#123; name: &#x27;ooooooh灰灰&#x27; &#125;&#125;) 数据我们已经定义好了，接下来就是要在页面访问这个数据了，下面提供了两种方式来访问 vuex 里的数据 组合式 API 访问在组合式 API 中，我们可以直接导入刚才在 /src/store/store.ts 里定义的 useStore() 方法来访问 vuex 里的数据 import &#123; defineComponent &#125; from &#x27;vue&#x27;;import &#123; useStore &#125; from &#x27;./store/store&#x27;export default defineComponent(&#123; setup()&#123; let store = useStore() // 访问 state 里的 name 数据 console.log(store.state.name) &#125;&#125;); 运行代码的话就会在控制台打印 ooooooh灰灰 …toRefs() 访问所有字段如果要在页面访问的话，可以利用 ...toRefs() 来直接展开 store.state 里的所有字段，然后在页面直接访问 vuex 的 state 里的字段 // App.vue&lt;template&gt; &lt;div&gt; &#123;&#123; name &#125;&#125; &lt;/div&gt;&lt;/template&gt;&lt;script lang=&quot;ts&quot;&gt; import &#123; defineComponent, toRefs&#125; from &#x27;vue&#x27;; import &#123; useStore &#125; from &#x27;./store/store&#x27; export default defineComponent(&#123; setup()&#123; let store = useStore() return &#123; // 展开 state 所有的字段 ...toRefs(store.state) &#125; &#125; &#125;);&lt;/script&gt;&lt;style&gt;&lt;/style&gt; reactive 聚合单个字段如果你想单个数据导入的话，可以直接和页面数据一起放在 reactive import &#123; defineComponent, reactive, toRefs&#125; from &#x27;vue&#x27;; import &#123; useStore &#125; from &#x27;./store/store&#x27; export default defineComponent(&#123; setup()&#123; let store = useStore() // 把 vuex 的 state 的数据放进 reactive 里 let params = reactive(&#123; name: store.state.name &#125;) return &#123; ...toRefs(params), &#125; &#125; &#125;); computed 访问单个字段也可以使用 computed 模块来访问数据，要先导入 vue 里的 computed // App.vue&lt;template&gt; &lt;div&gt; &#123;&#123; name &#125;&#125; &lt;/div&gt;&lt;/template&gt;&lt;script lang=&quot;ts&quot;&gt; import &#123; defineComponent, computed&#125; from &#x27;vue&#x27;; import &#123; useStore &#125; from &#x27;./store/store&#x27; export default defineComponent(&#123; setup()&#123; let store = useStore() return &#123; name: computed(()=&gt;store.state.name) &#125; &#125; &#125;);&lt;/script&gt;&lt;style&gt;&lt;/style&gt; Gettersgetters 里的方法在 vuex/types/index.d.ts 中是这样定义的 export type Getter&lt;S, R&gt; = (state: S, getters: any, rootState: R, rootGetters: any) =&gt; any; 他有 4 个参数，分别是 state、getters、rootState、rootGetters 其中，state 可以取得同级中 state 里的数据，getters 可以取得同级中 getters 其他的方法返回的数据 而 rootState 和 rootGetters 是在当当前 Getters 处于 module 中时，可以取得根部的 state 和 gatters 里的数据 比如我们可以将 state 里的变量封装成一句话然后返回： export const store = createStore&lt;IState&gt; (&#123; state:&#123; name: &#x27;ooooooh灰灰&#x27;, &#125;, getters:&#123; newName(state):string&#123; // 通过 state 访问 name 字段 return &#x27;大家好！我是：&#x27;+state.name &#125; &#125;&#125;) 当我们要访问其他 getter 时，我们可以这样： export const store = createStore&lt;IState&gt; (&#123; state:&#123; name: &#x27;ooooooh灰灰&#x27;, age: 20 &#125;, getters:&#123; hello(state,getters):string&#123; // 通过 getters 访问其他 getter return &#x27;大家好！我是：&#x27;+state.name+&#x27;,&#x27;+getters.ageInfo &#125;, ageInfo(state):string&#123; return &#x27;年龄：&#x27;+state.age &#125; &#125;&#125;) 组合式 API 访问我们可以在组合式 API 里像访问 state 的里数据一样访问 gatters 里的方法： import &#123; defineComponent &#125; from &#x27;vue&#x27;;import &#123; useStore &#125; from &#x27;./store/store&#x27;export default defineComponent(&#123; setup()&#123; let store = useStore() // 访问 getters 里的 hello 方法 console.log(store.getters.hello) &#125;&#125;); 此外，getters 也可以使用 ...toRefs()、computed 这些方法来访问： &lt;template&gt; &lt;div&gt; &#123;&#123; hello &#125;&#125; &lt;/div&gt;&lt;/template&gt;&lt;script lang=&quot;ts&quot;&gt; import &#123; defineComponent, computed, toRefs &#125; from &#x27;vue&#x27;; import &#123; useStore &#125; from &#x27;./store/store&#x27; export default defineComponent(&#123; setup()&#123; let store = useStore() return &#123; // 通过 computed 访问 getters 里的 hello hello: computed(()=&gt;store.getters.hello), // 通过 ...toRefs() 访问 // ...toRefs(store.getters), &#125; &#125; &#125;);&lt;/script&gt;&lt;style&gt;&lt;/style&gt; Mutations如果你要改变 state 里的数据时，就要用到 Mutations 了，它可以提供改变 state 里数据的方法，它在 vuex/types/index.d.ts 中是这样定义的： export type Mutation&lt;S&gt; = (state: S, payload?: any) =&gt; any; 其中 state 可以拿到 state 里的数据，payload 是自定义传入的参数，后面有个问号，代表这是可选项 所以当我们要改变 state 的字段的值时，我们可以在 store.ts 中这样写代码 ： export const store = createStore&lt;IState&gt; (&#123; state:&#123; name: &#x27;ooooooh灰灰&#x27;, &#125;, mutations:&#123; changeName(state)&#123; // 改变 state 中 name 的值 state.name = &#x27;greycode&#x27; &#125; &#125;&#125;) 如果要自定义传入参数的话，就可以这样写： export const store = createStore&lt;IState&gt; (&#123; state:&#123; name: &#x27;ooooooh灰灰&#x27;, &#125;, mutations:&#123; changeName(state,newName:string)&#123; // 传入自定义字段并设置 state.name = newName &#125; &#125;&#125;) 组合式 API 访问在组合式 API 中，我们可以用 commit 来提交执行这个方法： import &#123; defineComponent &#125; from &#x27;vue&#x27;;import &#123; useStore &#125; from &#x27;./store/store&#x27;export default defineComponent(&#123; setup()&#123; let store = useStore() let change = () =&gt; &#123; // 提交执行 mutations 中 changeName 方法 // store.commit(&#x27;changeName&#x27;) // 提交执行 mutations 中 changeName 方法,并传入自定义参数 store.commit(&#x27;changeName&#x27;,&#x27;自定义的&#x27;) &#125; return &#123; change &#125; &#125;&#125;); …mapMutations我们可以直接在组合式 API 中使用 ...mapMutations 来获得 mutations 中的方法，然后直接在页面中调用这个方法 import &#123; defineComponent &#125; from &#x27;vue&#x27;;import &#123; mapMutations &#125; from &#x27;vuex&#x27;;import &#123; useStore &#125; from &#x27;./store/store&#x27;export default defineComponent(&#123; setup()&#123; let store = useStore() return &#123; // 使用 ...mapMutations 来获得 mutations 中的方法 ...mapMutations([&#x27;changeName&#x27;]) &#125; &#125;&#125;); 然后直接在页面中使用： &lt;template&gt; &lt;div&gt; &lt;button type=&quot;button&quot; @click=&quot;changeName&quot;&gt;按钮&lt;/button&gt; &lt;!-- 也可以传入函数自定义参数 --&gt; &lt;button type=&quot;button&quot; @click=&quot;changeName(’自定义名字‘)&quot;&gt;按钮&lt;/button&gt; &lt;/div&gt;&lt;/template&gt; Action当要异步改变 state 中的数据时，就要用到 Action 了，但是它不是直接改变 state 中的数据，而是通过异步执行 mutations 中的方法来间接改变 state 中的数据的 它在 vuex/types/index.d.ts 中是这样定义的： export type Action&lt;S, R&gt; = ActionHandler&lt;S, R&gt; | ActionObject&lt;S, R&gt;; 它支持两种类型的数据，一个是 ActionHandler&lt;S, R&gt; ，另一个是 ActionObject&lt;S, R&gt;。其中 ActionObject 一般用于 Module 中的命名空间，它们的定义如下： export type ActionHandler&lt;S, R&gt; = (this: Store&lt;R&gt;, injectee: ActionContext&lt;S, R&gt;, payload?: any) =&gt; any;export interface ActionObject&lt;S, R&gt; &#123; root?: boolean; handler: ActionHandler&lt;S, R&gt;;&#125; 这里只讲下 ActionHandler ，另外一个等到 Module 模块中再讲。 在 ActionHandler 中，它有 3 个参数，分别是 this、injectee、payload，其中 this 代表的是整个 Store 对象，injectee 是当前 Action 所在的上下文，payload 是可以自定义的传入参数 所以我们可以这样使用它： export const store = createStore&lt;IState&gt; (&#123; state:&#123; name: &#x27;ooooooh灰灰&#x27; &#125;, mutations:&#123; changeName(state)&#123; state.name = &#x27;异步改名&#x27; &#125; &#125;, actions:&#123; asyncChange(ctx)&#123; // 两秒后更改名字 setTimeout(() =&gt;&#123; ctx.commit(&#x27;changeName&#x27;) &#125;,2000) &#125; &#125;&#125;) 组合式 API 访问定义好 actions 后，我们可以在组合式 API 中用 dispatch 来分发 action： import &#123; defineComponent &#125; from &#x27;vue&#x27;;import &#123; useStore &#125; from &#x27;./store/store&#x27;export default defineComponent(&#123; setup()&#123; let store = useStore() let syncChange = () =&gt; &#123; // 执行 actions 中的 asyncChange 方法 store.dispatch(&#x27;asyncChange&#x27;) &#125; return &#123; syncChange &#125; &#125;&#125;); …mapActions也可以用 ...mapActions 来直接获得 actions 中的方法： import &#123; defineComponent &#125; from &#x27;vue&#x27;;import &#123; mapActions &#125; from &#x27;vuex&#x27;;import &#123; useStore &#125; from &#x27;./store/store&#x27;export default defineComponent(&#123; setup()&#123; let store = useStore() return &#123; ...mapActions([&#x27;asyncChange&#x27;]) &#125; &#125;&#125;); 页面使用的话和 mutation 差不多，直接访问 actions 中的方法名就可以了： &lt;template&gt; &lt;div&gt; &lt;button type=&quot;button&quot; @click=&quot;asyncChange&quot;&gt;按钮&lt;/button&gt; &lt;/div&gt;&lt;/template&gt; 最后除此之外还有一个 Module 模块，不过一般小项目用不到而且内容也比较多，下次再学吧。","categories":[{"name":"Vue","slug":"Vue","permalink":"https://greycode.top/categories/Vue/"}],"tags":[{"name":"Vuex","slug":"Vuex","permalink":"https://greycode.top/tags/Vuex/"},{"name":"Vue","slug":"Vue","permalink":"https://greycode.top/tags/Vue/"},{"name":"TypeScript","slug":"TypeScript","permalink":"https://greycode.top/tags/TypeScript/"}]},{"title":"利用腾讯位置API进行的阿里云DDNS工具","slug":"tool/9ACF61395A77470CA029D24AEC2CA42F","date":"2021-07-26T16:08:12.000Z","updated":"2022-04-16T02:52:58.653Z","comments":true,"path":"tool/9ACF61395A77470CA029D24AEC2CA42F/","link":"","permalink":"https://greycode.top/tool/9ACF61395A77470CA029D24AEC2CA42F/","excerpt":"","text":"介绍 本应用是基于阿里云SDK进行开发的，可以动态更新阿里云域名的DNS解析，运行环境是 Python 3 利用腾讯位置提供的 API 进行公网 IP 的获取，可以查看如何获取腾讯位置的 API 密钥 由于腾讯位置的 API 免费配额为每日 10000 次，请合理使用 快速开始程序从环境变量中获取配置，运行前先设置环境变量 环境变量 说明 ALI_ACCESS_KEY_ID 阿里云 ACCESS_KEY_ID（必填） ALI_ACCESS_KEY_SECRET 阿里云 ACCESS_KEY_SECRET（必填） ALI_REGION_ID 阿里云区域 ID（默认：cn-hangzhou） DNS_TYPE 解析类型（默认：A） DNS_DOMAIN 域名（必填） DNS_SUB_DOMAIN 二级域名（默认：@） TENCENT_LBS_KEY 腾讯位置应用 KEY TENCENT_LBS_SK 腾讯位置应用签名加密 SK 环境字段说明DNS_TYPE 支持的解析类型： 点击查看官方详细说明 A：将域名指向一个IPV4地址 CNAME：将域名指向另外一个域名 AAAA：将域名指向一个IPV6地址 DNS_SUB_DOMAIN 域名前缀，常见用法有： www：解析后的域名为www.aliyun.com。 @：直接解析主域名 aliyun.com。 *：泛解析，匹配其他所有域名 *.aliyun.com。 mail：将域名解析为mail.aliyun.com，通常用于解析邮箱服务器。 二级域名：如：abc.aliyun.com，填写abc。 手机网站：如：m.aliyun.com，填写m。 显性URL：不支持泛解析（泛解析：将所有子域名解析到同一地址） 运行当设置好环境变量后，使用以下命令安装依赖 pip install -r requeirments.txt 安装依赖后，直接运行 main.py python main.py 以 Docker 运行如果你本地没有 python 环境，可以直接使用 docker 来运行本程序 先拉取镜像： docker pull greycodee/aliyun-ddns 然后运行： docker run -d -e ALI_ACCESS_KEY_ID=&quot;阿里云AK&quot; \\ -e ALI_ACCESS_KEY_SECRET=&quot;阿里云AKS&quot; \\ -e DNS_DOMAIN=&quot;你的域名&quot; \\ -e DNS_SUB_DOMAIN=&quot;二级域名名称&quot; \\ -e TENCENT_LBS_KEY=&quot;腾讯位置应用KEY&quot; \\ -e TENCENT_LBS_SK=&quot;腾讯位置应用签名SK&quot; \\ greycodee/aliyun-ddns 如果你想看日志的话，可以使用 -v 命令把 docker 容器里的 /root/logs 日志目录挂载出来，这里面存放着程序的运行日志 Dockerfile在本目录中的 Dockerfile 文件中，更改文件里的环境变量参数为你的数据，具体参数字段含义见上文介绍。更改完参数后，可以在当前目录使用 docker build 构建命令来构建你自己来镜像 docker build -t 设置镜像标签 . 构建完成后就可以使用命令来运行你刚才构建的镜像了 docker run -d 设置的镜像标签","categories":[{"name":"Tool","slug":"Tool","permalink":"https://greycode.top/categories/Tool/"}],"tags":[{"name":"DDNS","slug":"DDNS","permalink":"https://greycode.top/tags/DDNS/"}]},{"title":"UML箭头在Java中的含义","slug":"gof/234C81B9931C44CB9B88E0E53210BB48","date":"2021-07-18T20:17:38.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"gof/234C81B9931C44CB9B88E0E53210BB48/","link":"","permalink":"https://greycode.top/gof/234C81B9931C44CB9B88E0E53210BB48/","excerpt":"","text":"泛化 在 Java 中表示继承关系，空心箭头指向父类 示例： class Parent &#123; &#125;class Son extends Parent &#123; &#125; 实现 表示实现接口，箭头指向接口类 示例： interface Iter &#123;&#125;class TerImpl implements Iter &#123;&#125; 依赖 表示依赖关系，某个类的方法必须依赖另一个类才可以执行，箭头指向被依赖的类 示例： class A &#123; public void testA()&#123; System.out.println(&quot;这是 A 类&quot;); &#125;&#125;class B &#123; public void testB(A a)&#123; a.testA(); &#125;&#125; 关联关系关联 表示关联关系，两个类的关系是平等的 可以双向关联，A 可以关联 B，B 也可以关联 A 箭头指向被关联的类 示例： class A &#123; public void testA()&#123; System.out.println(&quot;这是 A 类&quot;); &#125;&#125;class B &#123; private A a; public B(A a) &#123; this.a = a; &#125; public void testB()&#123; a.testA(); &#125;&#125; 聚合 表示聚合关系，聚合是关联的一种特例，在代码上两者没有什么区别。 单向关联，A 能关联 B，B 不能关联 A 尾部为空棱形，也可以是直线 示例： class A &#123;&#125;class B &#123; private List&lt;A&gt; a; &#125; 组合 表示组合关系，也是关联关系的一种 表示强关联关系，被关联的类的生命周期会随关联类的生命周期一起产生和消失 示例： class A &#123;&#125;class B &#123; private A a; public B() &#123; this.a = new A(); &#125;&#125; 总结聚合和组合的区别：聚合是个体离开了整体，依然可以存在. 组合是个体和整体不可以分开，个体不能离开整体单独存在。 依赖，关联 和聚合，组合的区别：依赖，关联 : 类之间的关系是在同一层次上. 聚合，组合: 类之间的关系表现为整体和部分。 参考资料 https://blog.csdn.net/zhuyu714997369/article/details/51983871 https://zhuanlan.zhihu.com/p/109655171 https://blog.csdn.net/qq_31655965/article/details/54645220","categories":[{"name":"UML","slug":"UML","permalink":"https://greycode.top/categories/UML/"}],"tags":[{"name":"UML","slug":"UML","permalink":"https://greycode.top/tags/UML/"}]},{"title":"记一次很久以前做的梦【加密】","slug":"archive/essay/8B40046C17644103BD2A256EB938884C","date":"2021-07-15T08:14:37.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"archive/essay/8B40046C17644103BD2A256EB938884C/","link":"","permalink":"https://greycode.top/archive/essay/8B40046C17644103BD2A256EB938884C/","excerpt":"","text":"时间：2019-12-19 07:23RGwc3OqLQr&#x2F;FK7bX9qFgbl1FD1WZLruNkeFBP4vHyDejXpJhzV309eABiP0e+YiX5wKAD0GaALo74u1B39tyIUFaMrQAVV5M60sGphzkL2hf0ad5&#x2F;0JAqGXgDy01ustT&#x2F;w+bAGA8As3jc+3CexZ8CfqJsrOp7vt0aE8zzqKV0IbSL3b5u4wpBfp4Rb7+4b7lES9sbZmD37mXP5bJ0X94Z6W38oSSUj6aiLpDI9kllGxSWavZK+hQk1eWuAThn833cjXVtaxq7Mruglvc+eo4ok2Fm56uCdnq2RiUi5nu9e0bkGXyv8ELwr3RcVjMQdHQB8CK&#x2F;OFuNXltCRWNKlH6G2fyrPO+D+Sg6zbolkLHl326Ja3co0fDuLm6MxbLLwubwjfci0&#x2F;ZXjGOCKodAfvEtrDmkd0l2HYaOTbH6nOu+3GwXr+3QwdoxhFrVPjpkvjWcs4VNieiqiynXeNBflPR66ZrscQtZRVX77DUXT3jZdQ5rV7a6ZyWDr9ZgET86YQlGFxcW62wsBnMBt9STCFCUhbhYdccrBOAMJuZXfccIDuBgqelngufQRinLHRJiv0ihN2QhNuJFKkkTxSgswrMjLWhMGgKs8fbfnK82myiWIgqRnF6geCydTX8UAS3dTR1f0XJKEJuUNzc87uzszP+EZIcZ+JnCLjLNnJXJG9XVlLKElLmiwXNi4zDnP6NHGa7ikvac7mHR2SsWGL3&#x2F;v4pZtSNiwoZW3pPaK6Id+eg+srKoB7GTQNKZIsDuJh8cMziJF7cr1KvH7LZRMpB4MpeyvLmgz8oo3soLiGFVhl5wMrcqbc8H4qtnC4mI9iT5Z1lPBtq13+bYyplOY+G0soMOvbtkei7nWxIz3fh17gqMZvlTikEGcMNHGTs+wwgtsbreqR54iWEVuOxfYD+eYArFujw+iJRCsUCYWepGeVGNpZwlsuKQ+EH0sIJ1c4srVN73BYyE9nHw34W9CHY1MkOhUmXflbaBxz7E+AWfiUiZEWpWwvXOfTtWRuJV0htuCPmA63XgHn6JAHadlf5OY4l1BNewOWXVDPYEChsONoPSmTFxjq&#x2F;Qop83AqoOtxoaPqfWLXM+s8AqMjfWDQkzDMuxUnMO9fxiEze7J+qMZw7y2W+37NgPQHZBcG3Q8Vd&#x2F;ArxjfMQaZO11cYsW+RQkhuXj6lvsbs31+j&#x2F;Od4mA0XPpJ2rKIVC&#x2F;ueVAP8BuTBAzMN8ndDHXkKctT17eCUXz7w+t9n4h4MZxQQPegz9d3ULLabcdCJ167fpJ+8&#x2F;iXQhcJXihJeNXefkPcVrkxF+Tfj&#x2F;r73rSbTgtK+LseIedY1u17&#x2F;8itWpPlPqlVDC6dzSECBofynwSHADsXl+CBFpkstT3JPiSRTnVmWcta4H9kHthp4yG8Hqc2O6fJnodDIjwa6uzS0N8o95wHz79dDtDHKSpGsjtjotT54qCeI9z3T9FMSwKrN2AJn&#x2F;1fQdRA56QjnGFLeE8EkYY5Ix6tsk9XFcqAeLC1UbWIoaEqUdILSo9e&#x2F;TAUizEf+01YBHrsec+o2lEGl8QjthfxhlEFDNgTD0Lt4Cb2ytqpMJZXxFrqqUYOOc2+Lq0&#x2F;xJPHCKHYf8vLZEfx7LzcLbwLk+BVnxm6JqQVXXWMM2BblrFCX2CAIuhd8m0lztKUrK5OVG0TyEeLrOpB6&#x2F;YfXm6MPIOttooJFzCBZAKpWt70Xwwfwxrr7r0qMZziWv8oTiFG4lSvGE0VvCwN9hZoLvFh6bMFpnz&#x2F;bv0L8HMSxBmOyanQm01HhX6KXcyNSbW9Ep2Qxkw+eC034r+HQzV2t+qFkbpNFMb0DatDetvdBZyvlTvlPNcxJCcxEqe&#x2F;gxb9DRzKNPyy8eM&#x2F;P4Wem+NW7GFZTfXZQ6uj712J&#x2F;vQddDF9ukf&#x2F;jXJkEShhLTs9+JFhR9zjnOljLfNhmB8UzIUBno1d+qqzlC+ZiHzkaRbMnATdOYqW0dBIf5f5wIq31M4GC5mkQzxBVQ8Zqxxu5LCLGRrm+2dro8O27&#x2F;B5D74h0s&#x2F;rUmbj8Qxxf32rNjj0+TAZIIFh&#x2F;3pQjdbwNiABQZUpLBtYWSiZSZ5ivKAgzK6H1uVAlrillqMWJDjLsU6yO1sGb6lMBgKiIuGD2MWHj6moa+JUygW+gWo9m7XVe0q6y6CveMERblK4nXsgurUqH4j91uqyu6c0kccGY8Oei6opdzG49&#x2F;53IJg8YQo6TnK+plLdg1ezfanf20QwHBV1IHNYFWiTUHVO88EJuvLSAPgDdiVCOzO0KjXxjqOiq7lDw+OFbYaYyUoE1nwywhgE1TbBJdR54em&#x2F;CC4lY+14GNDTTAaN9ATWLCSPJWQnsDR799HCBZcGumWHB303Zcti4&#x2F;hKKmUW1JH59XxL4dtLup7fER05tm7vtVJ5ZCd0r1+R7QOzPIszOqZ+B2OifcYLVAelM7OGtIZbOmIWQbU11K45P16Y6GVZicmSTPSKXrvAB6nhOD0&#x2F;we&#x2F;UbqpU6iNu5ZRTgcZcxyrgU2TzWaKgfcX5ynMjk0TAqvYKYHAXMhMIUE6tEMMithQ1WkasGcv0+r6Hu8jPrc9&#x2F;Gvlf4u+4fl9knAf7JCgONAi4ds&#x2F;p6rwGAGtZbvzcAvxF7p04RcX0MY6A53z0tsFIcE46Uu&#x2F;KuxhWVyufVwlrHfIek6k8hHTspNH8bztwUJLU6gBRP9SpRrZrZIhDPII19VXNFVWdujdwcu7dcNuuoXPofulrbbHSyYaSaxK&#x2F;RdHh7yjViodnoUp3WaTNDZtzRlICXyZm73kD7qqHyR6nyqnVFG43Zd+Xcic2HJzEhSMYG6Ddlyc6AzYSCJeoDCY9M6dpPFKplBpQRL8g4LjOLHwd7BMlXqqcvjAmJpfHSlByX5KEml7a3V4jVKoIhoq1B5EvoNELDwUah8nnJjh8CKJevnuNx2NRUr&#x2F;QNzIfHTRGKCYHua70wUQX7m+lcNMc&#x2F;EG3TLqr+qyXMFjXihPxRLL+Uc9LBDbCIMh1Zpirr&#x2F;0+6U4twTr&#x2F;ipWU5SmOxf0O+OFl2NjOH7u8MwkXT1yWTS09Nfu3tLHFA0EmqJxgceNea8uegh+KFo4Fnf4oTd1wwg6c3cE8RX7okJ5ZDMzWCifUEwzdturrhnaarzbZT&#x2F;aCIAn4Epu4&#x2F;G0wgJSZL5oos889CaEJcmGkkJ6XSTd87ArxLOu143GSoSxVj6dlMGYLfcnJIjX3NJ0kHJdSROY9f6Kd0Moh&#x2F;3fupqbLxtyP9bKQKPtpfw4pT2&#x2F;Kd2nmPeBhxMIqIap4b3zKL5PzBF&#x2F;t6faSIMANeUoU9+oD1LU5FVfkoz5Icd7aW73SNLnwFxvXXUkuR&#x2F;Dkcry3vJVOeKuxV6m6L6qqplQtCiyYzTc01Zllr4e34dYU0&#x2F;QOfId3TI4Ork17iAHGGu+JY8Kud55p2Ph3NZN9nLryFzyjAsgaRY5YJnrJ0&#x2F;vs+0yS3wLYvXWIy1rhJHytZRS7AzR+TjX+GRAFAajy5zkouA7owJbn1L8UFvzlbDTLFHzhxVMI+DsTddmNqU70wOP2Goh8c3HnOLf77Sn6l6qS+eL18+ZcTm8RhXN8+tT2&#x2F;id+GLg60kgFIQggJVgQV8qKOqfSnyE4v1szSmSnGxrlZHNSzBg18XppzmNxAbNHjPiauLVGw&#x2F;qPWvm4ZGvtYv23rLsA0cdLnjnmnlCg&#x2F;oh&#x2F;8juTf3GsX5VVS7sGIFZCJh&#x2F;RRzLmwvXq2LZgBhhdD607xq7AFhuazYpVXcP6axrAWl3ikqYYGzAtesSzc&#x2F;yK9hhhvPcO+UhhkfWrlLdubzSBP60ycIhCSMG+OhG2U5XZLaSpMZghnpf8tu2uFiH6xkiFHAunxseHecrBstXQZ4jzVL3aFv3TpyQG19dgKIlukZDpSFuLZLFW&#x2F;fe5So5mNfp&#x2F;zgezEXaZz&#x2F;TIkD&#x2F;HMpm18nov2oPuIOi2HFNwSZoExvORHzRCXcfci8&#x2F;+m8VH9aF31EwiapPfFmjBWTAtcUI6s+T5Xf55d245Mi0XYQtWkqxLhIXfN0uyJBekVBNCKS7A2J0qjR5weYpAz&#x2F;mnLX7xVfIGBanizxcag1GsOS70iPp4WuVTMrwVH9RvsCP+3n3wrMFkfrtQnjMx+GWJx3v3vl4fk1o5istwlrT3R3Z630OIgn6Wsdz43OWI4MIp8sJuKqQYntU7XkmSwxerSSOOr64+u9H3WKyUxzgQ8bEqH+i8xjRajjlrYQ8iZGr85c2JEE6HB7QcxbA6IpDz0WI7WdA2WBM&#x2F;c5lGWNE+gMg7abztKO9CPnQscEvCZGr85c2JEE6HB7QcxbA6IpDz0WI7WdA2WBM&#x2F;c5lGWNE+gMg7abztKO9CPnQscEvCZGr85c2JEE6HB7QcxbA6IpDz0WI7WdA2WBM&#x2F;c5lGWNE+gMg7abztKO9CPnQscEvCZGr85c2JEE6HB7QcxbA6IpDz0WI7WdA2WBM&#x2F;c5lGWNE+gMg7abztKO9CPnQscEvCZGr85c2JEE6HB7QcxbA6IpDz0WI7WdA2WBM&#x2F;c5lGWNE+gMg7abztKO9CPnQscEvCZGr85c2JEE6HB7QcxbA6IpDz0WI7WdA2WBM&#x2F;c5lGWNE+gMg7abztKO9CPnQscEvCZGr85c2JEE6HB7QcxbA6IpDz0WI7WdA2WBM&#x2F;c5lGWNE+gMg7abztKO9CPnQscEvCZGr85c2JEE6HB7QcxbA6IpDz0WI7WdA2WBM&#x2F;c5lGWNE+gMg7abztKO9CPnQscEvCZGr85c2JEE6HB7QcxbA6IpDz0WI7WdA2WBM&#x2F;c5lGWNE+gMg7abztKO9CPnQscEvP0OhWvdMO2k9oBXJJ5MV&#x2F;g&#x3D;","categories":[{"name":"Essay","slug":"Essay","permalink":"https://greycode.top/categories/Essay/"}],"tags":[{"name":"抒发情感","slug":"抒发情感","permalink":"https://greycode.top/tags/%E6%8A%92%E5%8F%91%E6%83%85%E6%84%9F/"}]},{"title":"Quarkus项目配置方式详解","slug":"archive/quarkus/3EC6E900CDCB4BCEBA3B0BE40C9AADBB","date":"2021-07-12T17:29:23.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"archive/quarkus/3EC6E900CDCB4BCEBA3B0BE40C9AADBB/","link":"","permalink":"https://greycode.top/archive/quarkus/3EC6E900CDCB4BCEBA3B0BE40C9AADBB/","excerpt":"","text":"配置加载流程Quarkus 可以从多个地方获取项目的配置，它读取配置优先级入下图，在下面的优先级中，一旦读取到某个配置，就不会再继续读取后面配置中的这个配置了。 0x1 System Properties系统属性可以在启动期间通过 -D 标志传递给应用程序。 比如要设置 http 服务的运行端口，各个运行方式传递系统参数的方式如下： Quarkus dev模式：mvn quarkus:dev -Dquarkus.http.port=8888 运行 jar 包：java -Dquarkus.http.port=8888 -jar quarkus-run.jar 运行 native-image：app-runner -Dquarkus.http.port=8888 0x2 Environment variables 环境变量的名字遵循 MicroProfile Config Environment Variables Mapping RulesSome operating systems allow only alphabetic characters or an underscore, _, in environment variables. Other characters such as ., /, etc may be disallowed. In order to set a value for a config property that has a name containing such disallowed characters from an environment variable, the following rules are used.The ConfigSource for the environment variables searches three environment variables for a given property name (e.g. com.ACME.size):1. Exact match (i.e. com.ACME.size)2. Replace each character that is neither alphanumeric nor _ with _ (i.e. com_ACME_size)3. Replace each character that is neither alphanumeric nor _ with _; then convert the name to upper case (i.e. COM_ACME_SIZE)The first environment variable that is found is returned by this ConfigSource. 环境变量的话各个系统设置的方式不一样，具体可以查一下自己系统设置环境变量的方式，一般 Unix 类的系统设置环境变量一般分为命令行设置和环境变量文件配置 命令行配置：export QUARKUS_HTTP_PORT:8888 配置文件配置：环境变量配置文件又分用户变量配置文件和系统变量配置文件，直接在对应的配置文件里加上这一样就可以了，但是一般不推荐这么用 0x3 .env 文件 注意：.env 文件中的环境变量无法像普通的环境变量通过 System.getenv(String) API 获得。 .env 文件的作用和环境变量类似，但是作用域更小，它只作用于当前项目，不像环境变量可以作用于所有项目。 它的设置方式是在 .env 文件里配置键值对的方式来设置变量，键名称和设置环境变量一样遵守 MicroProfile Config 规范 使用方式： 对于 dev 模式：可以放在项目的根目录下来使用，但是不要把它和代码一起打包 对于 jar 和 native-image 运行方式下：可以将 .env 文件放在和 jar 包或 native-image 同一目录下 0x4 Quarkus Application配置文件Quarkus 和 Spring Boot 项目一样，支持 application.properties 配置文件。同时在 jar 包和 native-image 的运行模式下还支持当前 jar 文件和native-image 文件同目录下 config 文件夹里的 application.properties 配置文件，并且 config 文件夹里的配置文件优先级高于项目 resources 文件夹里的配置文件 对于 dev 的运行模式下，项目也可以使用 config 文件里的配置文件，就是手动把 config 文件夹移到 target 文件夹里，但是在使用 mvn clean 命令时会把这个文件夹清理掉，到时候又要自己手动重新创建 config 文件夹和里面的配置文件，所以在 dev 模式下不推荐使用 config/application.properties 0x5 MicroProfile 配置文件它放在 src/main/resources/META-INF/microprofile-config.properties 里 它的工作原理和项目的 resources 文件夹下的 application.properties 完全相同，建议使用 resources 文件夹下的配置文件 使用 yml 配置文件以上配置中，除了系统属性、环境变量、.env 文件外，配置文件都可以支持 yml 格式的配置，不过需要额外添加依赖 添加依赖 pom.xml 文件添加依赖 &lt;dependency&gt; &lt;groupId&gt;io.quarkus&lt;/groupId&gt; &lt;artifactId&gt;quarkus-config-yaml&lt;/artifactId&gt;&lt;/dependency&gt; 或者可以直接用 maven 命令来添加拓展依赖 ./mvnw quarkus:add-extension -Dextensions=&quot;io.quarkus:quarkus-config-yaml&quot; 添加yml文件移除src/main/resources/application.properties 文件，添加 src/main/resources/application.yaml 文件 如果两个文件都存在，Quarkus 会优先使用来自 yml 的配置，然后再使用 properties 的配置，所以为了不搞混淆，建议删除 properties 文件。 配置文件扩展名支持 yml 和 yaml 参考资料 https://quarkus.io/guides/config-yaml https://quarkus.pro/guides/config.html https://quarkus.io/guides/config-reference","categories":[{"name":"Quarkus","slug":"Quarkus","permalink":"https://greycode.top/categories/Quarkus/"}],"tags":[{"name":"Quarkus","slug":"Quarkus","permalink":"https://greycode.top/tags/Quarkus/"}]},{"title":"Quarkus构建native-image遇到的问题及解决","slug":"archive/quarkus/5756337C1CEA4B599E678A3380DCFE00","date":"2021-07-09T17:44:33.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"archive/quarkus/5756337C1CEA4B599E678A3380DCFE00/","link":"","permalink":"https://greycode.top/archive/quarkus/5756337C1CEA4B599E678A3380DCFE00/","excerpt":"","text":"本机构建 native-image如果你本地安装了 Graal VM 的话，可以在项目目录下直接执行： mvn clean package -Pnative 构建的时间比较长，构建完成后就会在 ./target 目录下生成一个二进制执行文件，一般名字是 quarkus-demo-1.0-runner，直接执行这个二进制文件就可以运行项目了。 ➜ target: ./quarkus-demo-1.0-runner __ ____ __ _____ ___ __ ____ ______ --/ __ \\/ / / / _ | / _ \\/ //_/ / / / __/ -/ /_/ / /_/ / __ |/ , _/ ,&lt; / /_/ /\\ \\ --\\___\\_\\____/_/ |_/_/|_/_/|_|\\____/___/ 2021-07-09 16:54:10,812 INFO [io.quarkus] (main) quarkus-demo 1.0 native (powered by Quarkus 2.0.1.Final) started in 0.121s. Listening on: http://0.0.0.0:80802021-07-09 16:54:11,041 INFO [io.quarkus] (main) Profile prod activated. 2021-07-09 16:54:11,041 INFO [io.quarkus] (main) Installed features: [cdi, resteasy, smallrye-context-propagation]^C2021-07-09 16:55:12,904 INFO [io.quarkus] (Shutdown thread) quarkus-demo stopped in 0.008s 容器构建 native-image如果你本地没有安装 Graal VM 的话，Quarkus 官方还提供了一个构建的基础镜像：quay.io/quarkus/ubi-quarkus-native-image，我们可以直接执行以下命令进行构建： mvn clean package -Pnative -Dquarkus.native.container-build=true 容器构建遇到的问题1. 构建时内存不足在使用容器构建 native-image 的时候，可以会报如下错误： [ERROR] Failed to execute goal io.quarkus:quarkus-maven-plugin:2.0.1.Final:build (default) on project quarkus-demo: Failed to build quarkus application: io.quarkus.builder.BuildException: Build failure: Build failed due to errors[ERROR] [error]: Build step io.quarkus.deployment.pkg.steps.NativeImageBuildStep#build threw an exception: java.lang.RuntimeException: Failed to build native image[ERROR] at io.quarkus.deployment.pkg.steps.NativeImageBuildStep.build(NativeImageBuildStep.java:223)[ERROR] at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)[ERROR] at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)[ERROR] at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)[ERROR] at java.base/java.lang.reflect.Method.invoke(Method.java:566)[ERROR] at io.quarkus.deployment.ExtensionLoader$2.execute(ExtensionLoader.java:820)[ERROR] at io.quarkus.builder.BuildContext.run(BuildContext.java:277)[ERROR] at org.jboss.threads.ContextHandler$1.runWith(ContextHandler.java:18)[ERROR] at org.jboss.threads.EnhancedQueueExecutor$Task.run(EnhancedQueueExecutor.java:2442)[ERROR] at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.run(EnhancedQueueExecutor.java:1476)[ERROR] at java.base/java.lang.Thread.run(Thread.java:829)[ERROR] at org.jboss.threads.JBossThread.run(JBossThread.java:501)[ERROR] Caused by: java.lang.RuntimeException: Image generation failed. Exit code was 137 which indicates an out of memory error. Consider increasing the Xmx value for native image generation by setting the &quot;quarkus.native.native-image-xmx&quot; property[ERROR] at io.quarkus.deployment.pkg.steps.NativeImageBuildStep.imageGenerationFailed(NativeImageBuildStep.java:360)[ERROR] at io.quarkus.deployment.pkg.steps.NativeImageBuildStep.build(NativeImageBuildStep.java:200)[ERROR] ... 11 more[ERROR] -&gt; [Help 1][ERROR] [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.[ERROR] Re-run Maven using the -X switch to enable full debug logging.[ERROR] [ERROR] For more information about the errors and possible solutions, please read the following articles:[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException 错误提示时内存不足，可以尝试设置 quarkus.native.native-image-xmx 参数，但是设置了这个参数还是报这个错。在查阅资料后，在一个 stackoverflow 的回答中看到了这样一句话： Pay attention it has to be less than the memory you set in your docker daemon. 他说必须小于您在 docker 守护进程中设置的内存。 然后我查看 docker 的官方文档时发现，在 Mac 和 Windows 中默认的内存是 2GB。 所以只要调高这个值就可以了，推荐是 8GB，各系统设置方法： Mac：https://docs.docker.com/docker-for-mac/#resources Windows：https://docs.docker.com/docker-for-windows/#resources 2. 容器构建后的二进制文件无法运行容器构建 native-image 完成后生成的二进制文件不能执行，提示 zsh: exec format error: ./quarkus-demo-1.0-runner 这是因为我本机是 Mac 系统，但是 Quarkus 提供的构建镜像是 Linux 系统，但是 Graal VM 目前好像并不支持交叉编译，所以在 Linux 系统里构建的二进制文件只能在 Linux 系统里执行。 所以我们可以直接用容器来运行这个构建好的二进制文件。","categories":[{"name":"Quarkus","slug":"Quarkus","permalink":"https://greycode.top/categories/Quarkus/"}],"tags":[{"name":"Quarkus","slug":"Quarkus","permalink":"https://greycode.top/tags/Quarkus/"},{"name":"Graal VM","slug":"Graal-VM","permalink":"https://greycode.top/tags/Graal-VM/"}]},{"title":"使用Maven工具创建Quarkus项目","slug":"archive/quarkus/5870388109C640649633FA0BB2F5C9C1","date":"2021-07-09T15:22:39.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"archive/quarkus/5870388109C640649633FA0BB2F5C9C1/","link":"","permalink":"https://greycode.top/archive/quarkus/5870388109C640649633FA0BB2F5C9C1/","excerpt":"","text":"环境我这边使用的是 Maven 3.8.1 版本，可以使用 Quarkus 官方提供的 io.quarkus:quarkus-maven-plugin:2.0.1.Final 插件来快速穿件 Quarkus 项目。 创建项目使用以下 Maven 命令来创建一个新项目： mvn io.quarkus:quarkus-maven-plugin:2.0.1.Final:create \\ -DprojectGroupId=top.mjava \\ -DprojectArtifactId=quarkus-demo \\ -DprojectVersion=1.0 \\ -DclassName=&quot;top.mjava.demo.Application&quot; 在执行命令的当前目录下会为项目生成和 ArtifactId 同名的文件夹，如果已存在该同名文件夹，则项目会创建失败。 在 src/main/docker 目录下还生成了 native 和 jvm 模式的 Dockerfile，构建镜像和运行容器的指令写在这些 Dockerfile 中。 命令描述 属性 默认值 描述 projectGroupId org.acme.sample 项目的 GroupId projectArtifactId 没有默认值，但是必填 项目的 ArtifactId projectVersion 1.0.0-SNAPSHOT 项目版本 platformGroupId io.quarkus 目标平台的组 ID。鉴于所有现有平台都来自 io.quarkus，实际上不会明确使用这一平台。但它仍然是一个选择。 platformArtifactId quarkus-universe-bom 目标平台 BOM 的工件 ID。为了使用本地构建的 Quarkus，它应该是 quarkus-bom。 platformVersion 如果未指定，将解析最新的。 您希望项目使用的平台版本。它还可以接受版本范围，在这种情况下，将使用指定范围中的最新版本。 className 如果省略则不创建 生成的资源的完全限定名称 path /hello 资源路径，仅在设置了 className 时生效。 extensions [] 要添加到项目的扩展列表（逗号分隔） 管理扩展创建项目后就可以进入到项目文件夹，可以使用简短的命令来操作项目了，例如：mvn quarkus:[command] 查看所有扩展mvn quarkus:list-extensions 该命令可以查看当前项目所使用的的所有扩展。 ➜ quarkus-demo: mvn quarkus:list-extensions[INFO] Scanning for projects...[INFO] [INFO] -----------------------&lt; top.mjava:quarkus-demo &gt;-----------------------[INFO] Building quarkus-demo 1.0[INFO] --------------------------------[ jar ]---------------------------------[INFO] [INFO] --- quarkus-maven-plugin:2.0.1.Final:list-extensions (default-cli) @ quarkus-demo ---[INFO] Current Quarkus extensions available: [INFO] [INFO] Blaze-Persistence blaze-persistence-integration-quarkus [INFO] Camel ActiveMQ camel-quarkus-activemq [INFO] Camel Async HTTP Client (AHC) camel-quarkus-ahc [INFO] Camel Async HTTP Client (AHC) Websocket camel-quarkus-ahc-ws [INFO] Camel AMQP camel-quarkus-amqp ...... 添加扩展mvn quarkus:add-extensions -Dextension=vertx 该命令可以添加扩展，例如上面这条命令为项目添加了 vertx 扩展 ➜ quarkus-demo: mvn quarkus:add-extensions -Dextension=vertx[INFO] Scanning for projects...[INFO] [INFO] -----------------------&lt; top.mjava:quarkus-demo &gt;-----------------------[INFO] Building quarkus-demo 1.0[INFO] --------------------------------[ jar ]---------------------------------[INFO] [INFO] --- quarkus-maven-plugin:2.0.1.Final:add-extensions (default-cli) @ quarkus-demo ---[INFO] [SUCCESS] ✅ Extension io.quarkus:quarkus-vertx has been installed[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 2.370 s[INFO] Finished at: 2021-07-09T15:06:50+08:00[INFO] ------------------------------------------------------------------------ 删除扩展mvn quarkus:remove-extensions -Dextension=vertx 该命令可以删除不用的扩展，比如删除刚刚添加的 vertx 扩展 ➜ quarkus-demo: mvn quarkus:remove-extensions -Dextension=vertx[INFO] Scanning for projects...[INFO] [INFO] -----------------------&lt; top.mjava:quarkus-demo &gt;-----------------------[INFO] Building quarkus-demo 1.0[INFO] --------------------------------[ jar ]---------------------------------[INFO] [INFO] --- quarkus-maven-plugin:2.0.1.Final:remove-extensions (default-cli) @ quarkus-demo ---[INFO] [SUCCESS] ✅ Extension io.quarkus:quarkus-vertx has been uninstalled[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 2.112 s[INFO] Finished at: 2021-07-09T15:08:48+08:00[INFO] ------------------------------------------------------------------------ 项目构建运行项目mvn quarkus:dev 执行该命令时，项目会被运行，此时访问 http://localhost:8080/hello 就会得到 Hello RESTEasy 输出 quarkus-demo: mvn quarkus:dev [INFO] Scanning for projects...[INFO] [INFO] -----------------------&lt; top.mjava:quarkus-demo &gt;-----------------------[INFO] Building quarkus-demo 1.0[INFO] --------------------------------[ jar ]---------------------------------[INFO] [INFO] --- quarkus-maven-plugin:2.0.1.Final:dev (default-cli) @ quarkus-demo ---[INFO] Invoking io.quarkus:quarkus-maven-plugin:2.0.1.Final:generate-code @ quarkus-demo[INFO] Invoking org.apache.maven.plugins:maven-resources-plugin:2.6:resources @ quarkus-demo[INFO] Using &#x27;UTF-8&#x27; encoding to copy filtered resources.[INFO] Copying 2 resources[INFO] Invoking org.apache.maven.plugins:maven-compiler-plugin:3.8.1:compile @ quarkus-demo[INFO] Nothing to compile - all classes are up to date[INFO] Invoking org.apache.maven.plugins:maven-resources-plugin:2.6:testResources @ quarkus-demo[INFO] Using &#x27;UTF-8&#x27; encoding to copy filtered resources.[INFO] skip non existing resourceDirectory /Users/zheng/coding/study/quarkus-demo/src/test/resources[INFO] Invoking org.apache.maven.plugins:maven-compiler-plugin:3.8.1:testCompile @ quarkus-demo[INFO] Nothing to compile - all classes are up to dateListening for transport dt_socket at address: 5005__ ____ __ _____ ___ __ ____ ______ --/ __ \\/ / / / _ | / _ \\/ //_/ / / / __/ -/ /_/ / /_/ / __ |/ , _/ ,&lt; / /_/ /\\ \\ --\\___\\_\\____/_/ |_/_/|_/_/|_|\\____/___/ 2021-07-09 15:16:47,146 INFO [io.quarkus] (Quarkus Main Thread) quarkus-demo 1.0 on JVM (powered by Quarkus 2.0.1.Final) started in 3.412s. Listening on: http://localhost:80802021-07-09 15:16:47,194 INFO [io.quarkus] (Quarkus Main Thread) Profile dev activated. Live Coding activated.2021-07-09 15:16:47,199 INFO [io.quarkus] (Quarkus Main Thread) Installed features: [cdi, resteasy, smallrye-context-propagation] 构建项目mvn quarkus:build 该命令会构建项目，并会在 target/quarkus-app/ 目录下创建一个可运行的 jar 包 ➜ quarkus-demo mvn quarkus:build[INFO] Scanning for projects...[INFO] [INFO] -----------------------&lt; top.mjava:quarkus-demo &gt;-----------------------[INFO] Building quarkus-demo 1.0[INFO] --------------------------------[ jar ]---------------------------------[INFO] [INFO] --- quarkus-maven-plugin:2.0.1.Final:build (default-cli) @ quarkus-demo ---[INFO] [org.jboss.threads] JBoss Threads version 3.4.0.Final[INFO] [io.quarkus.deployment.QuarkusAugmentor] Quarkus augmentation completed in 1977ms[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 4.776 s[INFO] Finished at: 2021-07-09T15:13:54+08:00[INFO] ------------------------------------------------------------------------ 总结更多命令可以执行下面的命令查看，本文只介绍了几种常用的 mvn io.quarkus:quarkus-maven-plugin:2.0.1.Final:help// 或者在项目目录下可使用简短命令mvn quarkus:help 参考资料：https://quarkus.io/guides/maven-tooling","categories":[{"name":"Quarkus","slug":"Quarkus","permalink":"https://greycode.top/categories/Quarkus/"}],"tags":[{"name":"Quarkus","slug":"Quarkus","permalink":"https://greycode.top/tags/Quarkus/"},{"name":"Maven","slug":"Maven","permalink":"https://greycode.top/tags/Maven/"}]},{"title":"开发SaaS应用的12条准则【转】","slug":"archive/code/FFC3580D7E244B5282E3FDD7F3EB8E95","date":"2021-07-07T17:33:40.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"archive/code/FFC3580D7E244B5282E3FDD7F3EB8E95/","link":"","permalink":"https://greycode.top/archive/code/FFC3580D7E244B5282E3FDD7F3EB8E95/","excerpt":"","text":"开发SaaS应用的12条准则【转】 原文地址：https://12factor.net/ 简介如今，软件通常会作为一种服务来交付，它们被称为网络应用程序，或软件即服务（SaaS）。12-Factor 为构建如下的 SaaS 应用提供了方法论： 使用标准化流程自动配置，从而使新的开发者花费最少的学习成本加入这个项目。 和操作系统之间尽可能的划清界限，在各个系统中提供最大的可移植性。 适合部署在现代的云计算平台，从而在服务器和系统管理方面节省资源。 将开发环境和生产环境的差异降至最低，并使用持续交付实施敏捷开发。 可以在工具、架构和开发流程不发生明显变化的前提下实现扩展。 这套理论适用于任意语言和后端服务（数据库、消息队列、缓存等）开发的应用程序。 背景本文的贡献者参与过数以百计的应用程序的开发和部署，并通过 Heroku 平台间接见证了数十万应用程序的开发，运作以及扩展的过程。 本文综合了我们关于 SaaS 应用几乎所有的经验和智慧，是开发此类应用的理想实践标准，并特别关注于应用程序如何保持良性成长，开发者之间如何进行有效的代码协作，以及如何 避免软件污染 。 我们的初衷是分享在现代软件开发过程中发现的一些系统性问题，并加深对这些问题的认识。我们提供了讨论这些问题时所需的共享词汇，同时使用相关术语给出一套针对这些问题的广义解决方案。本文格式的灵感来自于 Martin Fowler 的书籍： Patterns of Enterprise Application Architecture ， Refactoring 。 读者应该是哪些人？任何 SaaS 应用的开发人员。部署和管理此类应用的运维工程师。 I. 基准代码 一份基准代码（Codebase），多份部署（deploy） 12-Factor应用(译者注：应该是说一个使用本文概念来设计的应用，下同)通常会使用版本控制系统加以管理，如Git, Mercurial, Subversion。一份用来跟踪代码所有修订版本的数据库被称作 代码库（code repository, code repo, repo）。 在类似 SVN 这样的集中式版本控制系统中，基准代码 就是指控制系统中的这一份代码库；而在 Git 那样的分布式版本控制系统中，基准代码 则是指最上游的那份代码库。 基准代码和应用之间总是保持一一对应的关系： 一旦有多个基准代码，就不能称为一个应用，而是一个分布式系统。分布式系统中的每一个组件都是一个应用，每一个应用可以分别使用 12-Factor 进行开发。 多个应用共享一份基准代码是有悖于 12-Factor 原则的。解决方案是将共享的代码拆分为独立的类库，然后使用 依赖管理 策略去加载它们。 尽管每个应用只对应一份基准代码，但可以同时存在多份部署。每份 部署 相当于运行了一个应用的实例。通常会有一个生产环境，一个或多个预发布环境。此外，每个开发人员都会在自己本地环境运行一个应用实例，这些都相当于一份部署。 所有部署的基准代码相同，但每份部署可以使用其不同的版本。比如，开发人员可能有一些提交还没有同步至预发布环境；预发布环境也有一些提交没有同步至生产环境。但它们都共享一份基准代码，我们就认为它们只是相同应用的不同部署而已。 II. 依赖 显式声明依赖关系（ dependency ） 大多数编程语言都会提供一个打包系统，用来为各个类库提供打包服务，就像 Perl 的 CPAN 或是 Ruby 的 Rubygems 。通过打包系统安装的类库可以是系统级的（称之为 “site packages”），或仅供某个应用程序使用，部署在相应的目录中（称之为 “vendoring” 或 “bunding”）。 12-Factor规则下的应用程序不会隐式依赖系统级的类库。 它一定通过 依赖清单 ，确切地声明所有依赖项。此外，在运行过程中通过 依赖隔离 工具来确保程序不会调用系统中存在但清单中未声明的依赖项。这一做法会统一应用到生产和开发环境。 例如， Ruby 的 Bundler 使用 Gemfile 作为依赖项声明清单，使用 bundle exec 来进行依赖隔离。Python 中则可分别使用两种工具 – Pip 用作依赖声明， Virtualenv 用作依赖隔离。甚至 C 语言也有类似工具， Autoconf 用作依赖声明，静态链接库用作依赖隔离。无论用什么工具，依赖声明和依赖隔离必须一起使用，否则无法满足 12-Factor 规范。 显式声明依赖的优点之一是为新进开发者简化了环境配置流程。新进开发者可以检出应用程序的基准代码，安装编程语言环境和它对应的依赖管理工具，只需通过一个 构建命令 来安装所有的依赖项，即可开始工作。例如，Ruby&#x2F;Bundler 下使用 bundle install，而 Clojure&#x2F;Leiningen 则是 lein deps。 12-Factor 应用同样不会隐式依赖某些系统工具，如 ImageMagick 或是curl。即使这些工具存在于几乎所有系统，但终究无法保证所有未来的系统都能支持应用顺利运行，或是能够和应用兼容。如果应用必须使用到某些系统工具，那么这些工具应该被包含在应用之中。 III. 配置 在环境中存储配置 通常，应用的 配置 在不同 部署 (预发布、生产环境、开发环境等等)间会有很大差异。这其中包括： 数据库，Memcached，以及其他 后端服务 的配置 第三方服务的证书，如 Amazon S3、Twitter 等 每份部署特有的配置，如域名等 有些应用在代码中使用常量保存配置，这与 12-Factor 所要求的代码和配置严格分离显然大相径庭。配置文件在各部署间存在大幅差异，代码却完全一致。 判断一个应用是否正确地将配置排除在代码之外，一个简单的方法是看该应用的基准代码是否可以立刻开源，而不用担心会暴露任何敏感的信息。 需要指出的是，这里定义的“配置”并不包括应用的内部配置，比如 Rails 的 config/routes.rb，或是使用 Spring 时 代码模块间的依赖注入关系 。这类配置在不同部署间不存在差异，所以应该写入代码。 另外一个解决方法是使用配置文件，但不把它们纳入版本控制系统，就像 Rails 的 config/database.yml 。这相对于在代码中使用常量已经是长足进步，但仍然有缺点：总是会不小心将配置文件签入了代码库；配置文件的可能会分散在不同的目录，并有着不同的格式，这让找出一个地方来统一管理所有配置变的不太现实。更糟的是，这些格式通常是语言或框架特定的。 12-Factor推荐将应用的配置存储于 环境变量 中（ env vars, env ）。环境变量可以非常方便地在不同的部署间做修改，却不动一行代码；与配置文件不同，不小心把它们签入代码库的概率微乎其微；与一些传统的解决配置问题的机制（比如 Java 的属性配置文件）相比，环境变量与语言和系统无关。 配置管理的另一个方面是分组。有时应用会将配置按照特定部署进行分组（或叫做“环境”），例如Rails中的 development,test, 和 production 环境。这种方法无法轻易扩展：更多部署意味着更多新的环境，例如 staging 或 qa 。 随着项目的不断深入，开发人员可能还会添加他们自己的环境，比如 joes-staging ，这将导致各种配置组合的激增，从而给管理部署增加了很多不确定因素。 12-Factor 应用中，环境变量的粒度要足够小，且相对独立。它们永远也不会组合成一个所谓的“环境”，而是独立存在于每个部署之中。当应用程序不断扩展，需要更多种类的部署时，这种配置管理方式能够做到平滑过渡。 IV. 后端服务 把后端服务(backing services)当作附加资源 后端服务是指程序运行所需要的通过网络调用的各种服务，如数据库（MySQL，CouchDB），消息&#x2F;队列系统（RabbitMQ，Beanstalkd），SMTP 邮件发送服务（Postfix），以及缓存系统（Memcached）。 类似数据库的后端服务，通常由部署应用程序的系统管理员一起管理。除了本地服务之外，应用程序有可能使用了第三方发布和管理的服务。示例包括 SMTP（例如 Postmark），数据收集服务（例如 New Relic 或 Loggly），数据存储服务（如 Amazon S3），以及使用 API 访问的服务（例如 Twitter, Google Maps, Last.fm）。 12-Factor 应用不会区别对待本地或第三方服务。 对应用程序而言，两种都是附加资源，通过一个 url 或是其他存储在 配置 中的服务定位&#x2F;服务证书来获取数据。12-Factor 应用的任意 部署 ，都应该可以在不进行任何代码改动的情况下，将本地 MySQL 数据库换成第三方服务（例如 Amazon RDS）。类似的，本地 SMTP 服务应该也可以和第三方 SMTP 服务（例如 Postmark ）互换。上述 2 个例子中，仅需修改配置中的资源地址。 每个不同的后端服务是一份 资源 。例如，一个 MySQL 数据库是一个资源，两个 MySQL 数据库（用来数据分区）就被当作是 2 个不同的资源。12-Factor 应用将这些数据库都视作 附加资源 ，这些资源和它们附属的部署保持松耦合。 部署可以按需加载或卸载资源。例如，如果应用的数据库服务由于硬件问题出现异常，管理员可以从最近的备份中恢复一个数据库，卸载当前的数据库，然后加载新的数据库 – 整个过程都不需要修改代码。 V. 构建，发布，运行 严格分离构建和运行 基准代码 转化为一份部署(非开发环境)需要以下三个阶段： 构建阶段 是指将代码仓库转化为可执行包的过程。构建时会使用指定版本的代码，获取和打包 依赖项，编译成二进制文件和资源文件。 发布阶段 会将构建的结果和当前部署所需 配置 相结合，并能够立刻在运行环境中投入使用。 运行阶段 （或者说“运行时”）是指针对选定的发布版本，在执行环境中启动一系列应用程序 进程。 12-factor 应用严格区分构建，发布，运行这三个步骤。 举例来说，直接修改处于运行状态的代码是非常不可取的做法，因为这些修改很难再同步回构建步骤。 部署工具通常都提供了发布管理工具，最引人注目的功能是退回至较旧的发布版本。比如， Capistrano 将所有发布版本都存储在一个叫 releases 的子目录中，当前的在线版本只需映射至对应的目录即可。该工具的 rollback 命令可以很容易地实现回退版本的功能。 每一个发布版本必须对应一个唯一的发布 ID，例如可以使用发布时的时间戳（2011-04-06-20:32:17），亦或是一个增长的数字（v100）。发布的版本就像一本只能追加的账本，一旦发布就不可修改，任何的变动都应该产生一个新的发布版本。 新的代码在部署之前，需要开发人员触发构建操作。但是，运行阶段不一定需要人为触发，而是可以自动进行。如服务器重启，或是进程管理器重启了一个崩溃的进程。因此，运行阶段应该保持尽可能少的模块，这样假设半夜发生系统故障而开发人员又捉襟见肘也不会引起太大问题。构建阶段是可以相对复杂一些的，因为错误信息能够立刻展示在开发人员面前，从而得到妥善处理。 VI. 进程 以一个或多个无状态进程运行应用 运行环境中，应用程序通常是以一个和多个 进程 运行的。 最简单的场景中，代码是一个独立的脚本，运行环境是开发人员自己的笔记本电脑，进程由一条命令行（例如python my_script.py）。另外一个极端情况是，复杂的应用可能会使用很多 进程类型 ，也就是零个或多个进程实例。 12-Factor 应用的进程必须无状态且 无共享 。 任何需要持久化的数据都要存储在 后端服务 内，比如数据库。 内存区域或磁盘空间可以作为进程在做某种事务型操作时的缓存，例如下载一个很大的文件，对其操作并将结果写入数据库的过程。12-Factor应用根本不用考虑这些缓存的内容是不是可以保留给之后的请求来使用，这是因为应用启动了多种类型的进程，将来的请求多半会由其他进程来服务。即使在只有一个进程的情形下，先前保存的数据（内存或文件系统中）也会因为重启（如代码部署、配置更改、或运行环境将进程调度至另一个物理区域执行）而丢失。 源文件打包工具（Jammit, django-compressor） 使用文件系统来缓存编译过的源文件。12-Factor 应用更倾向于在 构建步骤 做此动作——正如 Rails资源管道 ，而不是在运行阶段。 一些互联网系统依赖于 “粘性 session”， 这是指将用户 session 中的数据缓存至某进程的内存中，并将同一用户的后续请求路由到同一个进程。粘性 session 是 12-Factor 极力反对的。Session 中的数据应该保存在诸如 Memcached 或 Redis 这样的带有过期时间的缓存中。 VII. 端口绑定 通过端口绑定(Port binding)来提供服务 互联网应用有时会运行于服务器的容器之中。例如 PHP 经常作为 Apache HTTPD 的一个模块来运行，正如 Java 运行于 Tomcat 。 12-Factor 应用完全自我加载 而不依赖于任何网络服务器就可以创建一个面向网络的服务。互联网应用 通过端口绑定来提供服务 ，并监听发送至该端口的请求。 本地环境中，开发人员通过类似http://localhost:5000/的地址来访问服务。在线上环境中，请求统一发送至公共域名而后路由至绑定了端口的网络进程。 通常的实现思路是，将网络服务器类库通过 依赖声明 载入应用。例如，Python 的 Tornado, Ruby 的Thin , Java 以及其他基于 JVM 语言的 Jetty。完全由 用户端 ，确切的说应该是应用的代码，发起请求。和运行环境约定好绑定的端口即可处理这些请求。 HTTP 并不是唯一一个可以由端口绑定提供的服务。其实几乎所有服务器软件都可以通过进程绑定端口来等待请求。例如，使用 XMPP 的 ejabberd ， 以及使用 Redis 协议 的 Redis 。 还要指出的是，端口绑定这种方式也意味着一个应用可以成为另外一个应用的 后端服务 ，调用方将服务方提供的相应 URL 当作资源存入 配置 以备将来调用。 VIII. 并发 通过进程模型进行扩展 任何计算机程序，一旦启动，就会生成一个或多个进程。互联网应用采用多种进程运行方式。例如，PHP 进程作为 Apache 的子进程存在，随请求按需启动。Java 进程则采取了相反的方式，在程序启动之初 JVM 就提供了一个超级进程储备了大量的系统资源(CPU 和内存)，并通过多线程实现内部的并发管理。上述 2 个例子中，进程是开发人员可以操作的最小单位。 在 12-factor 应用中，进程是一等公民。12-Factor 应用的进程主要借鉴于 unix 守护进程模型 。开发人员可以运用这个模型去设计应用架构，将不同的工作分配给不同的 进程类型 。例如，HTTP 请求可以交给 web 进程来处理，而常驻的后台工作则交由 worker 进程负责。 这并不包括个别较为特殊的进程，例如通过虚拟机的线程处理并发的内部运算，或是使用诸如 EventMachine, Twisted, Node.js 的异步&#x2F;事件触发模型。但一台独立的虚拟机的扩展有瓶颈（垂直扩展），所以应用程序必须可以在多台物理机器间跨进程工作。 上述进程模型会在系统急需扩展时大放异彩。 12-Factor 应用的进程所具备的无共享，水平分区的特性 意味着添加并发会变得简单而稳妥。这些进程的类型以及每个类型中进程的数量就被称作 进程构成 。 12-Factor 应用的进程 不需要守护进程 或是写入 PID 文件。相反的，应该借助操作系统的进程管理器(例如 systemd ，分布式的进程管理云平台，或是类似 Foreman 的工具)，来管理 输出流 ，响应崩溃的进程，以及处理用户触发的重启和关闭超级进程的请求。 IX. 易处理 快速启动和优雅终止可最大化健壮性 *12-Factor 应用的 进程 是 易处理（disposable）的，意思是说它们可以瞬间开启或停止。* 这有利于快速、弹性的伸缩应用，迅速部署变化的 代码 或 配置 ，稳健的部署应用。 进程应当追求 最小启动时间 。 理想状态下，进程从敲下命令到真正启动并等待请求的时间应该只需很短的时间。更少的启动时间提供了更敏捷的 发布 以及扩展过程，此外还增加了健壮性，因为进程管理器可以在授权情形下容易的将进程搬到新的物理机器上。 进程 一旦接收 终止信号（SIGTERM） 就会优雅的终止 。就网络进程而言，优雅终止是指停止监听服务的端口，即拒绝所有新的请求，并继续执行当前已接收的请求，然后退出。此类型的进程所隐含的要求是HTTP请求大多都很短(不会超过几秒钟)，而在长时间轮询中，客户端在丢失连接后应该马上尝试重连。 对于 worker 进程来说，优雅终止是指将当前任务退回队列。例如，RabbitMQ 中，worker 可以发送一个[NACK](http://www.rabbitmq.com/amqp-0-9-1-quickref.html#basic.nack)信号。 Beanstalkd 中，任务终止并退回队列会在worker断开时自动触发。有锁机制的系统诸如 Delayed Job 则需要确定释放了系统资源。此类型的进程所隐含的要求是，任务都应该 可重复执行 ， 这主要由将结果包装进事务或是使重复操作 幂等 来实现。 进程还应当在面对突然死亡时保持健壮，例如底层硬件故障。虽然这种情况比起优雅终止来说少之又少，但终究有可能发生。一种推荐的方式是使用一个健壮的后端队列，例如 Beanstalkd ，它可以在客户端断开或超时后自动退回任务。无论如何，12-Factor 应用都应该可以设计能够应对意外的、不优雅的终结。Crash-only design 将这种概念转化为 合乎逻辑的理论。 X. 开发环境与线上环境等价 尽可能的保持开发，预发布，线上环境相同 从以往经验来看，开发环境（即开发人员的本地 部署）和线上环境（外部用户访问的真实部署）之间存在着很多差异。这些差异表现在以下三个方面： 时间差异： 开发人员正在编写的代码可能需要几天，几周，甚至几个月才会上线。 人员差异： 开发人员编写代码，运维人员部署代码。 工具差异： 开发人员或许使用 Nginx，SQLite，OS X，而线上环境使用 Apache，MySQL 以及 Linux。 12-Factor 应用想要做到 持续部署 就必须缩小本地与线上差异。 再回头看上面所描述的三个差异: 缩小时间差异：开发人员可以几小时，甚至几分钟就部署代码。 缩小人员差异：开发人员不只要编写代码，更应该密切参与部署过程以及代码在线上的表现。 缩小工具差异：尽量保证开发环境以及线上环境的一致性。 将上述总结变为一个表格如下： 传统应用 12-Factor 应用 每次部署间隔 数周 几小时 开发人员 vs 运维人员 不同的人 相同的人 开发环境 vs 线上环境 不同 尽量接近 后端服务 是保持开发与线上等价的重要部分，例如数据库，队列系统，以及缓存。许多语言都提供了简化获取后端服务的类库，例如不同类型服务的 适配器 。下列表格提供了一些例子。 类型 语言 类库 适配器 数据库 Ruby&#x2F;Rails ActiveRecord MySQL, PostgreSQL, SQLite 队列 Python&#x2F;Django Celery RabbitMQ, Beanstalkd, Redis 缓存 Ruby&#x2F;Rails ActiveSupport::Cache Memory, filesystem, Memcached 开发人员有时会觉得在本地环境中使用轻量的后端服务具有很强的吸引力，而那些更重量级的健壮的后端服务应该使用在生产环境。例如，本地使用 SQLite 线上使用 PostgreSQL；又如本地缓存在进程内存中而线上存入 Memcached。 12-Factor 应用的开发人员应该反对在不同环境间使用不同的后端服务 ，即使适配器已经可以几乎消除使用上的差异。这是因为，不同的后端服务意味着会突然出现的不兼容，从而导致测试、预发布都正常的代码在线上出现问题。这些错误会给持续部署带来阻力。从应用程序的生命周期来看，消除这种阻力需要花费很大的代价。 与此同时，轻量的本地服务也不像以前那样引人注目。借助于Homebrew，apt-get等现代的打包系统，诸如Memcached、PostgreSQL、RabbitMQ 等后端服务的安装与运行也并不复杂。此外，使用类似 Chef 和 Puppet 的声明式配置工具，结合像 Vagrant 这样轻量的虚拟环境就可以使得开发人员的本地环境与线上环境无限接近。与同步环境和持续部署所带来的益处相比，安装这些系统显然是值得的。 不同后端服务的适配器仍然是有用的，因为它们可以使移植后端服务变得简单。但应用的所有部署，这其中包括开发、预发布以及线上环境，都应该使用同一个后端服务的相同版本。 XI. 日志 把日志当作事件流 日志 使得应用程序运行的动作变得透明。在基于服务器的环境中，日志通常被写在硬盘的一个文件里，但这只是一种输出格式。 日志应该是 事件流 的汇总，将所有运行中进程和后端服务的输出流按照时间顺序收集起来。尽管在回溯问题时可能需要看很多行，日志最原始的格式确实是一个事件一行。日志没有确定开始和结束，但随着应用在运行会持续的增加。 12-factor应用本身从不考虑存储自己的输出流。 不应该试图去写或者管理日志文件。相反，每一个运行的进程都会直接的标准输出（stdout）事件流。开发环境中，开发人员可以通过这些数据流，实时在终端看到应用的活动。 在预发布或线上部署中，每个进程的输出流由运行环境截获，并将其他输出流整理在一起，然后一并发送给一个或多个最终的处理程序，用于查看或是长期存档。这些存档路径对于应用来说不可见也不可配置，而是完全交给程序的运行环境管理。类似 Logplex 和 Fluentd 的开源工具可以达到这个目的。 这些事件流可以输出至文件，或者在终端实时观察。最重要的，输出流可以发送到 Splunk 这样的日志索引及分析系统，或 Hadoop&#x2F;Hive 这样的通用数据存储系统。这些系统为查看应用的历史活动提供了强大而灵活的功能，包括： 找出过去一段时间特殊的事件。 图形化一个大规模的趋势，比如每分钟的请求量。 根据用户定义的条件实时触发警报，比如每分钟的报错超过某个警戒线。 XII. 管理进程 后台管理任务当作一次性进程运行 进程构成（process formation）是指用来处理应用的常规业务（比如处理 web 请求）的一组进程。与此不同，开发人员经常希望执行一些管理或维护应用的一次性任务，例如： 运行数据移植（Django 中的 manage.py migrate, Rails 中的 rake db:migrate）。 运行一个控制台（也被称为 REPL shell），来执行一些代码或是针对线上数据库做一些检查。大多数语言都通过解释器提供了一个 REPL 工具（python 或 perl） ，或是其他命令（Ruby 使用 irb, Rails 使用 rails console）。 运行一些提交到代码仓库的一次性脚本。 一次性管理进程应该和正常的 常驻进程 使用同样的环境。这些管理进程和任何其他的进程一样使用相同的 代码 和 配置 ，基于某个 发布版本 运行。后台管理代码应该随其他应用程序代码一起发布，从而避免同步问题。 所有进程类型应该使用同样的 依赖隔离 技术。例如，如果Ruby的web进程使用了命令 bundle exec thin start ，那么数据库移植应使用 bundle exec rake db:migrate 。同样的，如果一个 Python 程序使用了 Virtualenv，则需要在运行 Tornado Web 服务器和任何 manage.py 管理进程时引入 bin/python 。 12-factor 尤其青睐那些提供了 REPL shell 的语言，因为那会让运行一次性脚本变得简单。在本地部署中，开发人员直接在命令行使用 shell 命令调用一次性管理进程。在线上部署中，开发人员依旧可以使用ssh或是运行环境提供的其他机制来运行这样的进程。","categories":[],"tags":[{"name":"SaaS","slug":"SaaS","permalink":"https://greycode.top/tags/SaaS/"}]},{"title":"vertx的web开发学习笔记","slug":"vertx/10EF2E95447C468CB55BD7BD0675C090","date":"2021-07-05T15:31:02.000Z","updated":"2022-04-16T02:52:58.653Z","comments":true,"path":"vertx/10EF2E95447C468CB55BD7BD0675C090/","link":"","permalink":"https://greycode.top/vertx/10EF2E95447C468CB55BD7BD0675C090/","excerpt":"","text":"创建一个 Http 服务// 创建路由Router router = Router.router(vertx);// 创建 Http 服务vertx.createHttpServer() // 绑定路由 .requestHandler(router) // 监听端口 .listen(8888) // Http 服务启动成功后调用 .onSuccess(server -&gt; System.out.println(&quot;HTTP server started on port &quot; + server.actualPort()) ); Router 使用 直接使用上面的路由实例 创建请求路由 创建 Get 请求路由 router .get(&quot;/test&quot;) .respond( // 响应逻辑 ) // 或者router .route(HttpMethod.GET, &quot;/test&quot;) .respond( // 响应逻辑 ) 创建 Post 请求路由 router .post(&quot;/test&quot;) .respond( // 响应逻辑 )// 或者router .post(HttpMethod.POST, &quot;/test&quot;) .respond( // 响应逻辑 ) 获取参数 获取 URL 参数 请求地址示例：http://localhost:8080/get?param=greycode router.get(&quot;/get&quot;).handler(context-&gt; &#123; String param = context.request().getParam(&quot;param&quot;); System.out.println(param); &#125;);// 控制台打印greycode 获取 REST 风格的地址参数 请求地址示例：http://localhost:8080/get/greycode router.get(&quot;/get/:param&quot;).handler(context-&gt; &#123; String param = context.pathParam(&quot;param&quot;); System.out.println(param); &#125;);// 控制台打印greycode 获取 Body 数据 请求地址示例：http://localhost:8080/post 请求数据： &#123; &quot;name&quot;:&quot;greycode&quot;&#125; // 在获取数据前，一定要执行这行代码// 否则就会报：警告: BodyHandler in not enabled on this route: RoutingContext.getBodyAsJson() in always be NULL‘router.route().handler(BodyHandler.create());router.post(&quot;/post&quot;).handler(context-&gt;&#123; JsonObject body = context.getBodyAsJson(); System.out.println(body.toString()); &#125;);// 控制台打印&#123;&quot;name&quot;:&quot;greycode&quot;&#125; 异常处理router.get(&quot;/get&quot;).handler(context-&gt; &#123; throw new RuntimeException(&quot;模拟错误&quot;); &#125;).failureHandler(context-&gt; &#123; // 发生异常时执行的代码 &#125;);","categories":[{"name":"Vert.x","slug":"Vert-x","permalink":"https://greycode.top/categories/Vert-x/"}],"tags":[{"name":"Vert.x","slug":"Vert-x","permalink":"https://greycode.top/tags/Vert-x/"}]},{"title":"Java删除文件后电脑磁盘空间没有恢复","slug":"java/74CAAAFD610241A1B8ECDB5F3BB33EE4","date":"2021-07-03T17:12:41.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"java/74CAAAFD610241A1B8ECDB5F3BB33EE4/","link":"","permalink":"https://greycode.top/java/74CAAAFD610241A1B8ECDB5F3BB33EE4/","excerpt":"","text":"问题当用一下命令删除文件后，电脑磁盘内存没有恢复，还是原来的大小 File folder = new File(&quot;/tmp/file.mp4&quot;)file.delete(); 解决原来是 FileOutputStream 文件流忘了关了，导致一直占用这个资源。所以使用完后一定记得关文件流，使用下面的代码关闭文件流： FileOutputStream fileOutputStream = new FileOutputStream(new File());fileOutputStream.close(); Linux 里的文件被删除后，空间没有被释放是因为在 Linux 系统中，通过 rm 或者文件管理器删除文件将会从文件系统的目录结构上解除链接(unlink).然而如果文件是被打开的(有一个进程正在使用)，那么进程将仍然可以读取该文件，磁盘空间也一直被占用。 可以使用 lsof +L1 |grep delete 命令来查看状态为 deleted 的文件，状态为 deleted 为标记被删除，其实该文件并没有从磁盘中删除，类似windows下的回收站状态。 所以当进程结束后，磁盘空间就会被释放。 参考资料 http://www.cxyzjd.com/article/su4416160/78212934 https://www.jianshu.com/p/fcb80c878d04","categories":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/tags/Java/"},{"name":"Linux","slug":"Linux","permalink":"https://greycode.top/tags/Linux/"}]},{"title":"程序员的酒后真言","slug":"archive/essay/A98D5EC3509F483E80919CA2E09BDA1B","date":"2021-06-29T11:24:25.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"archive/essay/A98D5EC3509F483E80919CA2E09BDA1B/","link":"","permalink":"https://greycode.top/archive/essay/A98D5EC3509F483E80919CA2E09BDA1B/","excerpt":"","text":"转至：http://www.ruanyifeng.com/blog/2021/06/drunk-post-of-a-programmer.html 出至：https://old.reddit.com/r/ExperiencedDevs/comments/nmodyl/drunk_post_things_ive_learned_as_a_sr_engineer/ (1) 职业发展的最好方法是换公司。 (2）技术栈不重要。技术领域有大约 10-20 条核心原则，重要的是这些原则，技术栈只是落实它们的方法。你如果不熟悉某个技术栈，不需要过度担心。 (3）工作和人际关系是两回事。有一些公司，我交到了好朋友，但是工作得并不开心；另一些公司，我没有与任何同事建立友谊，但是工作得很开心。 (4）我总是对经理实话实说。怕什么？他开除我？我会在两周内找到一份新工作。 (5）如果一家公司的工程师超过 100 人，它的期权可能在未来十年内变得很有价值。对于工程师人数很少的公司，期权一般都是毫无价值。 (6）好的代码是初级工程师可以理解的代码。伟大的代码可以被第一年的 CS 专业的新生理解。 (7）作为一名工程师，最被低估的技能是记录。说真的，如果有人可以教我怎么写文档，我会付钱，也许是 1000 美元。 (8）网上的口水战，几乎都无关紧要，别去参与。 (9）如果我发现自己是公司里面最厉害的工程师，那就该离开了。 (10）我们应该雇佣更多的实习生，他们很棒。那些精力充沛的小家伙用他们的想法乱搞。如果他们公开质疑或批评某事，那就更好了。我喜欢实习生。 (11）技术栈很重要。如果你使用 Python 或 C++ 语言，就会忍不住想做一些非常不同的事情。因为某些工具确实擅长某些工作。 (12）如果你不确定自己想做什么东西，请使用 Java。这是一种糟糕的编程语言，但几乎无所不能。 (13）对于初学者来说，最赚钱的编程语言是 SQL，干翻所有其他语言。你只了解 SQL 而不会做其他事情，照样赚钱。人力资源专家的年薪？也许5万美元。懂 SQL 的人力资源专家？9万美元。 (14）测试很重要，但 TDD （测试驱动的开发）几乎变成了一个邪教。 (15） 政府单位很轻松，但并不像人们说的那样好。对于职业生涯早期到中期的工程师，12 万美元的年薪 + 各种福利 + 养老金听起来不错，但是你将被禁锢在深奥的专用工具里面，离开政府单位以后，这些知识就没用了。我非常尊重政府工作人员，但说真的，这些地方的工程师，年龄中位数在 50 岁以上是有原因的。 (16）再倒一杯酒。 (17）大多数头衔都无关紧要，随便什么公司都可以有首席工程师。 (18）手腕和背部的健康问题可不是开玩笑的，好的设备值得花钱。 (19）当一个软件工程师，最好的事情是什么？你可以结识很多想法相同的人，大家互相交流，不一定有相同的兴趣，但是对方会用跟你相同的方式思考问题，这很酷。 (20）有些技术太流行，我不得不用它。我心里就会很讨厌这种技术，但会把它推荐给客户，比如我恨 Jenkins，但把它推荐给新客户，我不觉得做错了。 (21）成为一名优秀的工程师意味着了解最佳实践，成为高级工程师意味着知道何时打破最佳实践。 (22）发生事故时，如果周围的人试图将责任归咎于外部错误或底层服务中断，那么是时候离开这家公司，继续前进了。 (23）我遇到的最好的领导，同意我的一部分观点，同时耐心跟我解释，为什么不同意我的另一部分观点。我正在努力成为像他们一样的人。 (24）算法和数据结构确实重要，但不应该无限夸大，尤其是面试的时候。我没见过药剂师面试时，还要测试有机化学的细节。这个行业的面试过程有时候很糟糕。 (25）做自己喜欢的事情并不重要，不要让我做讨厌的事情更重要。 (26）越接近产品，就越接近推动收入增长。无论工作的技术性如何，只要它接近产品，我都感到越有价值。 (27）即使我平时用 Windows 工作，Linux 也很重要。为什么？因为服务器是 Linux 系统，你最终在 Linux 系统上工作。 (28）人死了以后，你想让代码成为你的遗产吗？如果是那样，就花很多时间在代码上面吧，因为那是你的遗产。但是，如果你像我一样，更看重与家人、朋友和生活中其他人相处的时光，而不是写的代码，那就别对它太在意。 (29）我挣的钱还不错，对此心存感激，但还是需要省钱。 (30）糟糕，我没酒了。 (完）","categories":[{"name":"Essay","slug":"Essay","permalink":"https://greycode.top/categories/Essay/"}],"tags":[{"name":"闲谈","slug":"闲谈","permalink":"https://greycode.top/tags/%E9%97%B2%E8%B0%88/"}]},{"title":"免费全自动SEO优化","slug":"tool/21324399FBDC41CBA815D2069BB62168","date":"2021-06-20T22:27:32.000Z","updated":"2022-04-16T02:52:58.653Z","comments":true,"path":"tool/21324399FBDC41CBA815D2069BB62168/","link":"","permalink":"https://greycode.top/tool/21324399FBDC41CBA815D2069BB62168/","excerpt":"","text":"0x1 简介怎么让各大站长快速收录你自己网站的链接？那就是主动的推送你自己网站的 URL 到各大站长上去。前几天我写了一个一键提交的工具，可以一键提交你的链接到各大站长上去。你也可以单独使用工具来推送你的 URL、批量 URL 文件、SiteMap 站点地图。工具的github地址是：https://github.com/greycodee/seo-tools 今天我再教大家如何让网站自动提交最新的 URL 到各大站长上去，让各大站长第一时间收录你的链接。 0x2 准备在开始前，你需要准备如下东西： IFTTT 账号 Github 账号 你个人网站开通 RSS 订阅 具体原理就是通过 IFTTT 订阅你网站的 RSS，然后当有新的网址发布后，IFTTT 会触发事件回调 Github，Github 收到回调后 Github Action 会进行运转，然后在里面使用工具进行推送。","categories":[],"tags":[]},{"title":"百度、谷歌、必应三大站长API密钥申请流程","slug":"tool/C334612CBDCE41E79F7EA6A2F3F4C10C","date":"2021-06-17T21:40:11.000Z","updated":"2022-04-16T02:52:58.653Z","comments":true,"path":"tool/C334612CBDCE41E79F7EA6A2F3F4C10C/","link":"","permalink":"https://greycode.top/tool/C334612CBDCE41E79F7EA6A2F3F4C10C/","excerpt":"","text":"Google 索引 API 开通步骤 点击此链接，然后选择创建项目，点击继续。然后再点击转到“凭据”页面 到凭据页面先点击左侧的凭据选项，然后再点击管理服务账号 然后再点击创建服务账号 然后再填写相关信息，最后点击完成（第三步可不填） 点击图中的电子邮件，然后开始创建密钥，选择JSON格式，此时就会下载密钥文件到你电脑了 打开 Google Search Console，依次点击设置-&gt;用户和权限-&gt;拥有者账户右边三个点-&gt;管理资源所有者-&gt;添加所有者-&gt;填入上面密钥中的client_email 的值 现在可以用作为服务帐号进行身份验证的步骤来使用密钥了 Bing 索引 API 开通步骤 点击导航栏的齿轮图标 点击 API 访问，然后点击 API 密钥，就可以得到 API 密钥了 然后就可以按照必应文档来进行API的调用了 Baidu 索引 API 开通步骤百度就比较简单粗暴了，直接点击这个链接就可以直接得到 Token 了，这个页面下也有对应的 API 调用方法示例，这边就不再重复叙述了","categories":[{"name":"Tool","slug":"Tool","permalink":"https://greycode.top/categories/Tool/"}],"tags":[{"name":"SEO","slug":"SEO","permalink":"https://greycode.top/tags/SEO/"}]},{"title":"后端服务器时间不一致问题解决手册","slug":"linux/9AFC3EFAEC15479BB5FBC6F670594A94","date":"2021-06-15T10:32:50.000Z","updated":"2022-04-16T02:52:58.653Z","comments":true,"path":"linux/9AFC3EFAEC15479BB5FBC6F670594A94/","link":"","permalink":"https://greycode.top/linux/9AFC3EFAEC15479BB5FBC6F670594A94/","excerpt":"","text":"时区问题一般快 8 小时，慢 8 小时的问题都是时区问题，直接把时区改成 CST 时区 编辑系统环境变量文件 /etc/profile export TZ=&#x27;CST-8&#x27; Linux 系统时间不同步问题Linux 系统时间比正常时间快几分中或慢几分钟，但是时区是正确的 CST 时区，这是就要用到 ntpdate 这个命令了 安装 #centos,redhat系列yum install ntpdate#debian,ubuntu系列apt install ntpdate#archlinux系列pacman -S ntpdate 2、通过ntpdate命令从时钟服务器同步 我们这里选用中国ntp服务器cn.pool.ntp.org来作为时钟同步的来源。为能正常访问到cn.pool.ntp.org，你的Linux系统应该能访问外网才行。 执行命令如下： ntpdate cn.pool.ntp.org 3、配置crontab自动执行同步 如果每次手动执行，显然是很麻烦的。这里，我们使用crontab定时任务来定期执行ntpdate同步命令，例如我们每10分钟或一小时执行一次，可以通过以下方式实现。 首先在命令终端中输入crontab -e命令，然后输入如下命令保存即可。 crontab -e 开始编辑文件内容，输入定时执行命令： #每10分钟执行一次*/10 * * * * /usr/sbin/ntpdate cn.pool.ntp.org 或者 #每一个小时执行一次0 * * * * /usr/sbin/ntpdate cn.pool.ntp.org 参考资料 https://linux265.com/news/6009.html","categories":[{"name":"Linux","slug":"Linux","permalink":"https://greycode.top/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://greycode.top/tags/Linux/"},{"name":"Time","slug":"Time","permalink":"https://greycode.top/tags/Time/"}]},{"title":"用Darabonba一键生成7种语言的代码","slug":"tool/0D992236EC6B4E5EAD15886D992FF84B","date":"2021-06-05T18:08:19.000Z","updated":"2022-04-16T02:52:58.653Z","comments":true,"path":"tool/0D992236EC6B4E5EAD15886D992FF84B/","link":"","permalink":"https://greycode.top/tool/0D992236EC6B4E5EAD15886D992FF84B/","excerpt":"","text":"0x1 介绍最近在看阿里的SDK的时候，突然看到了一个好玩的东西，这玩意叫 Darabonba。是一种 OpenAPI 应用的领域特定语言。可以利用它为任意风格的接口生成多语言的 SDK、代码示例、测试用例、接口编排等。现在阿里云的多语言 SDK 就是用这个生成的。下面是官方的介绍流程图。 0x2 安装我们按照官方的步骤来安装它，因为是用 Nodejs 写的，所以可以用 npm 来安装它 sudo npm install -g @darabonba/cli 安装完成后可以在终端输入 dara ，如果输出版本号就是说明安装成功了 ➜ daraThe CLI for Darabonba 1.1.8 0x3 使用安装完成后就可以使用了，首先创建一个文件夹来存放这个项目 mkdir demo &amp;&amp; cd demo 然后用 dara 命令来进行初始化模块，然后依次输入包名等信息。 ➜ dara initpackage scope: demopackage name: demopackage version: 1.0.0main entry: ./demo.dara 初始化完成后，我们就可以在 demo.dara 文件里进行 Darabonba DSL 表达式的编写里 比如我们编写一个经典的输出 hello world！ 编写 Darabonba DSL 表达式在 demo.dara 文件里写入如下代码 import Console;init()&#123;&#125;function hello(): void &#123; Console.log(&quot;hello world!&quot;);&#125; 安装自定义模块因为上面我们用到了 Console 模块，所以我们在当前文件路径下执行如下命令，进行模块的安装 dara install# 执行后将显示下面这些信息fetching from remote repository1 libraries installed. (0 local, 1 remote) 执行完命令后，当前文件夹下就会出现一个 libraries 文件夹 配置 DarafileDarafile 是 Darabonba 的模块管理文件，类似 Java 中的 pom.xml 或者 Node.js 中的 package.json，这里我们要生成 Go 和 Java 的代码，所以只要做如下配置就可以了。具体的可以查看官方的详细介绍。 &#123; &quot;scope&quot;: &quot;demo&quot;, &quot;name&quot;: &quot;demo&quot;, &quot;version&quot;: &quot;1.0.0&quot;, &quot;main&quot;: &quot;./demo.dara&quot;, &quot;libraries&quot;: &#123; &quot;Console&quot;: &quot;darabonba:Console:*&quot; &#125;, &quot;java&quot;: &#123; &quot;package&quot;: &quot;top.mjava.demo&quot;, &quot;className&quot;:&quot;TestDemo&quot; &#125;&#125; 在 libraries 里配置我们刚才所使用的 Console 依赖模块，在 java 对象字段里配置了包名和类文件名。 生成代码官方暂时只支持 TypeScript、C#、Java、 Go、PHP、Python3、Python2、CPP 的代码生成，后续的话还会支持 Swift、Dart、Ruby、Lua、Kotlin。 我们这边只生成一下 Java 和 Go 代码，所以执行下面的命令就可以了 # 生成 Java 代码dara codegen java ./java-demo# 生成 Go 代码dara codegen go ./go-demo 执行完命令后，当前文件夹就会出现 java-demo 和 go-demo 两个文件夹了。然后就可以进入文件夹看到相应生成的代码了 Java： // This file is auto-generated, don&#x27;t edit it. Thanks.package top.mjava.demo;import com.aliyun.tea.*;import com.aliyun.teaconsole.*;public class TestDemo &#123; public TestDemo() throws Exception &#123; &#125; public void hello() throws Exception &#123; com.aliyun.teaconsole.Client.log(&quot;hello world!&quot;); &#125;&#125; Go: // This file is auto-generated, don&#x27;t edit it. Thanks.package clientimport ( console &quot;github.com/alibabacloud-go/tea-console/client&quot; &quot;github.com/alibabacloud-go/tea/tea&quot;)type Client struct &#123;&#125;func NewClient()(*Client, error) &#123; client := new(Client) err := client.Init() return client, err&#125;func (client *Client)Init()(_err error) &#123; return nil&#125; 0x3 自定义模块上面所用到的 Console 就是通过自定义模块打包上传到了 Darabonba 的模块仓库，然后我们可以直接通过 libraries 来使用它。 所以我们可以自定义自己的模块上传到 Darabonba 模块仓库，接下来我们自定义一个获取 UUID 的模块，让它支持 Java 和 Go 语言来生成使用。 从上面的流程图可以知道，模块是由各个语言自己编写代码，然后通过 Darabonba 聚合后上传到模块仓库，然后使用者从仓库安装模块，并且下载对应语言的依赖包。 我们这边要编写 Java 和 Go 语言获取 UUID 的代码，然后通过 Darabonba 打包上传到模块仓库。 配置模版编写模块我们也是用 Darabonba 先生成各个语言的模版代码，然后再编写相应的具体实现。 初始化 ➜ dara initpackage scope: greycodepackage name: UUIDpackage version: 1.0.0main entry: ./main.dara 我们先配置好 Darafile: &#123; &quot;scope&quot;: &quot;greycode&quot;, &quot;name&quot;: &quot;UUID&quot;, &quot;version&quot;: &quot;1.0.0&quot;, &quot;main&quot;: &quot;./main.dara&quot;, &quot;java&quot;: &#123; &quot;package&quot;: &quot;top.mjava.uuid&quot;, &quot;packageInfo&quot;: &#123; &quot;description&quot;: &quot;UUID generated for Darabonba moudle&quot;, &quot;url&quot;: &quot;https://github.com/greycodee/tea-uuid&quot;, &quot;developerId&quot;: &quot;greycode&quot;, &quot;developerName&quot;: &quot;greycode&quot;, &quot;developerEmail&quot;: &quot;zhengminghui99@gmail.com&quot; &#125; &#125;&#125; 然后在 main.dara 里编写一个静态方法： /*** @return uuid*/static function uuid(): string; 编写 Java 模块按上面的步骤配置好后就可以生成 Java 代码了，在当前目录下执行下面的命令 dara codegen java ./java 然后进入 java 文件夹，找到 Client.java，在 uuid() 方法里添加 UUID 生成的代码 // This file is auto-generated, don&#x27;t edit it. Thanks.package top.mjava.uuid;import com.aliyun.tea.*;public class Client &#123; public static String uuid() throws Exception &#123; // 添加这行代码 return UUID.randomUUID().toString(); &#125;&#125; 编写好代码后，还需要配置 pom.xml 文件，然后把 Java 代码打包发布到 maven 仓库上。 配置好 pom.xml 文件到下面这几个配置 &lt;groupId&gt;top.mjava&lt;/groupId&gt;&lt;artifactId&gt;tea-uuid&lt;/artifactId&gt;&lt;version&gt;1.0&lt;/version&gt;&lt;packaging&gt;jar&lt;/packaging&gt;&lt;name&gt;tea-uuid&lt;/name&gt; 还有把 pom.xml 里的仓库配置换成我们自己的，我这边也是用阿里云的 maven 参考。你们可以自己去阿里云 maven 注册自己的账号。 - &lt;distributionManagement&gt;- &lt;snapshotRepository&gt;- &lt;id&gt;sonatype-nexus-snapshots&lt;/id&gt;- &lt;url&gt;https://oss.sonatype.org/content/repositories/snapshots&lt;/url&gt;- &lt;/snapshotRepository&gt;- &lt;repository&gt;- &lt;id&gt;sonatype-nexus-staging&lt;/id&gt;- &lt;url&gt;https://oss.sonatype.org/service/local/staging/deploy/maven2/&lt;/url&gt;- &lt;/repository&gt;- &lt;/distributionManagement&gt;+ &lt;distributionManagement&gt;+ &lt;repository&gt;+ &lt;id&gt;rdc-releases_my&lt;/id&gt;+ &lt;url&gt;https://repo.rdc.aliyun.com/repository/102997-release-dTwmzu/&lt;/url&gt;+ &lt;/repository&gt;+ &lt;snapshotRepository&gt;+ &lt;id&gt;rdc-snapshots_my&lt;/id&gt;+ &lt;url&gt;https://repo.rdc.aliyun.com/repository/102997-snapshot-d0gx8B/&lt;/url&gt;+ &lt;/snapshotRepository&gt;+ &lt;/distributionManagement&gt; 配置好后就可以执行下面的命令将代码打包推送到远程 maven 仓库了 mvn clean source:jar javadoc:jar package deploy -Dmaven.test.skip=true -Dgpg.skip 看到下面的信息就说明部署成功了 [INFO] 阿里云Maven中央仓库为阿里云云效提供的公共代理仓库，云效也提供了免费、可靠的Maven私有仓库Packages，欢迎您体验使用。https://www.aliyun.com/product/yunxiao/packages?channel=pd_maven_download[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 5.538 s[INFO] Finished at: 2021-06-05T16:00:28+08:00[INFO] ------------------------------------------------------------------------ Maven 命令执行出现问题解决办法 如果执行 maven 命令进行部署时，出现下面的错误 [ERROR] Failed to execute goal org.apache.maven.plugins:maven-gpg-plugin:1.6:sign (sign-artifacts) on project tea-uuid: Unable to execute gpg command: Error while executing process. Cannot run program &quot;gpg&quot;: error=2, No such file or directory -&gt; [Help 1] 可以通过添加 -Dgpg.skip 解决 mvn clean source:jar javadoc:jar package deploy -Dmaven.test.skip=true -Dgpg.skip 如果出现下面的的错误 [ERROR] Failed to execute goal org.sonatype.plugins:nexus-staging-maven-plugin:1.6.3:deploy (injected-nexus-deploy) on project tea-uuid: Execution injected-nexus-deploy of goal org.sonatype.plugins:nexus-staging-maven-plugin:1.6.3:deploy failed: Server credentials with ID &quot;sonatype-nexus-staging&quot; not found! - 可以删除 pom.xml 文件里的 sonatype-nexus-staging 配置 - &lt;plugin&gt;- &lt;groupId&gt;org.sonatype.plugins&lt;/groupId&gt;- &lt;artifactId&gt;nexus-staging-maven-plugin&lt;/artifactId&gt;- &lt;version&gt;1.6.3&lt;/version&gt;- &lt;extensions&gt;true&lt;/extensions&gt;- &lt;configuration&gt;- &lt;serverId&gt;sonatype-nexus-staging&lt;/serverId&gt;- &lt;nexusUrl&gt;https://oss.sonatype.org/&lt;/nexusUrl&gt;- &lt;autoReleaseAfterClose&gt;true&lt;/autoReleaseAfterClose&gt;- &lt;/configuration&gt;- &lt;/plugin&gt; 编写 Go 模块老规矩，首先先生成 Go 的代码 dara codegen go ./go 然后编辑 client.go 文件，改为如下代码 // This file is auto-generated, don&#x27;t edit it. Thanks./*** @return uuid*/package clientimport ( &quot;github.com/google/uuid&quot;)func Uuid () (_result string) &#123; // V4 基于随机数 u4 := uuid.New() return u4.String()&#125; 然后 go.mod 文件里的 module 改为我们的上传 Go 代码的仓库地址 module github.com/greycodee/tea-uuid-go 然后推送到 GitHub 并打上一个 Tag 作为这个 Go 库的版本号，这边我设置版本号为 v1.0.0 git tag v1.0.0git push origin v1.0.0 上传 Darabonba 仓库编写好相应模块的代码并打包上传到对应的原创仓库后，就可以配置 Darafile 文件了 在 Darafile 添加 releases 信息 &#123; &quot;scope&quot;: &quot;greycode&quot;, &quot;name&quot;: &quot;UUID&quot;, &quot;version&quot;: &quot;1.0.0&quot;, &quot;main&quot;: &quot;./main.dara&quot;, &quot;releases&quot;: &#123; &quot;go&quot;: &quot;github.com/greycodee/tea-uuid-go/client:v1.0.0&quot;, &quot;java&quot;: &quot;top.mjava:tea-uuid:1.0&quot;, &#125;, &quot;java&quot;: &#123; &quot;package&quot;: &quot;top.mjava.uuid&quot;, &quot;packageInfo&quot;: &#123; &quot;description&quot;: &quot;UUID generated for Darabonba moudle&quot;, &quot;url&quot;: &quot;https://github.com/greycodee/tea-uuid&quot;, &quot;developerId&quot;: &quot;greycode&quot;, &quot;developerName&quot;: &quot;greycode&quot;, &quot;developerEmail&quot;: &quot;zhengminghui99@gmail.com&quot; &#125; &#125;&#125; 然后去 Darabonba 模块仓库里注册一个账号，然后点击个人中心-&gt;Scope-&gt;添加scope，添加一个 scope ，保持和 Darafile 文件里的 scope 一致。 注册完成后在项目目录下执行 dara login 命令，输入刚才注册的账号密码，进行登陆。 执行 dara pack 进行打包 再执行 dara publish 进行发布 发布完成后就可在 Darabonba 模块仓库里看到刚才发布的包了 Darabonba UUID 模块代码地址：https://github.com/greycodee/tea-uuid Go 模块代码地址： https://github.com/greycodee/tea-uuid-go 使用自定义的模块上传 Darabonba 模块仓库后，我们就可以向刚开始使用 Console 模块那样来使用 UUID 模块了 Darafile 添加 libraries &quot;libraries&quot;: &#123; &quot;UUID&quot;: &quot;greycode:UUID:*&quot;,&#125; 在 dara 代码里使用： import Console;import UUID;init()&#123;&#125;function hello(): void &#123; Console.log(UUID.uuid());&#125;","categories":[{"name":"Tool","slug":"Tool","permalink":"https://greycode.top/categories/Tool/"}],"tags":[{"name":"Darabonba","slug":"Darabonba","permalink":"https://greycode.top/tags/Darabonba/"}]},{"title":"什么是HTTP协议？","slug":"protocol/0143CD7666CD44389FE6F565E10EEE1A","date":"2021-06-04T11:44:00.000Z","updated":"2022-04-16T02:52:58.653Z","comments":true,"path":"protocol/0143CD7666CD44389FE6F565E10EEE1A/","link":"","permalink":"https://greycode.top/protocol/0143CD7666CD44389FE6F565E10EEE1A/","excerpt":"","text":"版本介绍HTTP 协议不用我多说了吧，大家都知道，现在我 web 开发一般都是使用 HTTP 协议来进行通信的。到目前为止，HTTP 进行了几次版本更新，HTTP 1.1 就是表示HTTP 的 1.1 版本。1.1 版本也是目前大部分网站所用的版本。 HTTP 0.9 发布时间：1991 年 简介：梦开始的地方，只接受GET一种请求方法，没有在通讯中指定版本号，且不支持请求头。由于该版本不支持POST方法，因此客户端无法向服务器传递太多信息。 HTTP 1.0 发布时间：1996 年 5 月 简介：这是第一个在通讯中指定版本号的HTTP协议版本。同时比 0.9 版本增加大量新特性。非持续连接，每次都要重新与服务器建立连接。 HTTP 1.1 发布时间：1997 年1月 简介：默认采用持续连接（Connection: keep-alive），能很好地配合代理服务器工作。还支持以管道方式在同时发送多个请求，以便降低线路负载，提高传输速度。同时这也是目前最流行的版本。 HTTP&#x2F;1.1相较于HTTP&#x2F;1.0协议的区别主要体现在： 缓存处理 带宽优化及网络连接的使用 错误通知的管理 消息在网络中的发送 互联网地址的维护 安全性及完整性 HTTP 2.0 发布时间：2015 年 5 月 简介：HTTP&#x2F;2 是 HTTP 协议自 1999 年 HTTP 1.1 的改进版 RFC 2616 发布后的首个更新，主要基于 SPDY 协议。它由互联网工程任务组（IETF）的Hypertext Transfer Protocol Bis（httpbis）工作小组进行开发。该组织于 2014 年 12 月将 HTTP&#x2F;2 标准提议递交至 IESG 进行讨论，于 2015 年 2 月 17 日被批准。 报文格式请求报文请求报文分为 4 个部分，分别是请求行、请求头、换行行、请求数据，每个部分的末尾都会带上回车符（CR，ASCII：0d）和换行符（LF，ASCII：0a） 其中请求行分为请求方法、请求的 URL 地址、HTTP 版本号，每个字段用空格（ASCII：20）来分隔 请求头部分可以有多行，每行用回车符和换行符区分 为了方便理解，我们可以用 Wireshark 来抓取一个 HTTP 请求来看看，并把它和上图进行关联 响应报文响应报文和请求报文基本差不多，唯一有区别就第一行状态行和请求报文的第一行请求行有区别。 状态行也分为三个部分，分别是 HTTP 版本、状态码、状态码描述，每个部分用空格进行分隔。 响应头和请求头一样，可以有多行 同样，用 Wireshark 抓取一个响应报文，来和上图进行一一对应。 持续连接和非持续连接上面说了，HTTP 1.1 的连接由原来的非持续连接变为了持续连接（Connection: keep-alive）。那么这两个有什么区别呢？ 非持续连接指的是当向服务器多次请求资源时，每次都需要单独的进行 TCP 的连接和断开。 持续连接指的是当向服务器请求资源时，可以共用一个 TCP 连接来进行资源的传输。 尽管 HTTP 1.1 默认使用持续连接，但是也可以配置为非持续连接，设置方法：Connection 字段设置为 close 为了好理解，为画了一张图，图中省略了 TCP 建立连接和断开连接的细致步骤。 请求方法 一般我们常用的只有 GET 和 POST 两个请求方法，但是如果遵循 REST 风格来进行 API 接口的设计，就可以用到下面的一些请求方法了。 OPTIONS：这个方法会请求服务器返回该资源所支持的所有HTTP请求方法。 GET：获取指定资源地址的数据，不推荐进行上传数据等操作。 HEAD：服务器在响应 HEAD 请求时不会回传 Body 资源的内容部分，这样，我们可以不传输全部内容的情况下，就可以获取服务器的响应头信息。 POST：POST 请求会 向指定资源提交数据，请求服务器进行处理，请求数据会被包含在请求体中。 PUT：可以将指定资源的最新数据传送给服务器取代指定的资源的内容。 DELETE：删除指定资源的数据。 TRACE：TRACE 请求服务器回显其收到的请求信息，该方法主要用于 HTTP 请求的测试或诊断。 …… 响应码1xxInformational（信息性状态码），表示接收的请求正在处理，具体可以查看 RFC 文档 2xxSuccess（成功状态码），请求正常处理完毕，具体可以查看 RFC 文档 3xxRedirection（重定向状态码），需要进行附加操作以完成请求，具体可以查看 RFC 文档 4xxClient Error（客户端错误状态码），服务器无法处理请求，具体可以查看 RFC 文档 5xxServer Error（服务器错误状态码），服务器处理请求出错，具体可以查看 RFC 文档","categories":[{"name":"Protocol","slug":"Protocol","permalink":"https://greycode.top/categories/Protocol/"}],"tags":[{"name":"HTTP协议","slug":"HTTP协议","permalink":"https://greycode.top/tags/HTTP%E5%8D%8F%E8%AE%AE/"}]},{"title":"使用Nacos实现网关动态路由","slug":"spring/EEF92888390B4E7C866FE7ADA6A0B42B","date":"2021-05-08T22:47:54.000Z","updated":"2022-04-16T02:52:58.653Z","comments":true,"path":"spring/EEF92888390B4E7C866FE7ADA6A0B42B/","link":"","permalink":"https://greycode.top/spring/EEF92888390B4E7C866FE7ADA6A0B42B/","excerpt":"","text":"背景网关作为一个主要的外部流量入口，其重启的次数当然是越少越好，所以不能有时候为了修改一个路由就重启整个网关服务，这样的话网关就不是一个高可用的网关。当然，有时候要新增或修改代码层面的自定义的过滤器时还是要重启网关的，所以我们能做的就是尽可能减少不必要的重启。这里就可以引入阿里巴巴开源的 Nacos 了。 什么是 Nacos？Naocs 是阿里巴巴开源的一款微服务组件，它提供注册中心和配置中心来供我们使用。并且 Nacos 同时支持 AP 模式和 CP 模式来供我们选择使用。具体可以查看官方文档来进一步了解。 安装 Nacos本地的话我这边建议直接用 Docker 来安装Nacos，省心省力。按照官方提供的方法，我们可以直接下载官方提供的 docker-compose 文件来启动 Nacos。 # 克隆项目git clone https://github.com/nacos-group/nacos-docker.git## 进入项目目录 然后启动cd nacos-dockerdocker-compose -f example/standalone-mysql-5.7.yaml up 我这边是启动了一个使用 MySQL 5.7 的单机 Nacos，如果你想使用其他的数据库或者启动集群的话可以参照一下官方文档 待启动完成后，就可以用浏览器打开 http://localhost:8848/nacos 进入 Nacos的管理台了。默认的登陆账号密码都是 nacos 网关使用 Nacos 我这边 Spring Cloud 使用的版本号是 2020.0.2 Nacos 创建配置在开始配置网关项目前，我们先在 Nacos 里创建一个配置，等下网关启动的时候就用这个配置。 server: port: 8989spring: cloud: gateway: routes: - id: route-demo uri: https://baidu.com predicates: - Path=/** 在上面配置中，我们定义了项目启动端口为 8989，然后创建了一个路由，这个路由接收所有请求，然后转发到百度。 依赖配置因为 Nacos 是阿里巴巴开源的，所以这里要用到 spring-cloud-alibaba-dependencies 这个依赖，在 Spring Cloud Gateway 项目里面添加如下依赖： &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;2021.1&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 配置文件导入依赖后，我们在 resources 文件夹下创建一个 bootstrap.yml 文件，然后在里面填入 Nacos 配置中心的相关的信息 spring: cloud: nacos: server-addr: localhost:8848 config: prefix: gateway file-extension: yml 上面配置中，server-addr 配置了本地 Nacos 的地址，prefix 配置了刚才配置文件的前缀，file-extension 配置了刚才 Nacos 上创建的文件扩展名。 在 Nacos Spring Cloud 中，dataId 的完整格式如下： $&#123;prefix&#125;-$&#123;spring.profiles.active&#125;.$&#123;file-extension&#125; prefix 默认为 spring.application.name 的值，也可以通过配置项 spring.cloud.nacos.config.prefix来配置。 spring.profiles.active 即为当前环境对应的 profile，详情可以参考 Spring Boot文档。 注意：当 spring.profiles.active 为空时，对应的连接符 - 也将不存在，dataId 的拼接格式变成 $&#123;prefix&#125;.$&#123;file-extension&#125; file-exetension 为配置内容的数据格式，可以通过配置项 spring.cloud.nacos.config.file-extension 来配置。目前只支持 properties 和 yaml 类型。 启动网关项目配置完成后，如果你和我用的 Spring Cloud 版本一样是 2020.0.2 版的话，你启动项目后会发现，欸？？怎么启动端口还是默认的 8080 呢？ 发生这种情况是因为项目没有读取 bootstrap.yml 文件，这是因为 Spring Cloud 从数字版开始，把 bootstrap 默认为关闭状态，此时如果要使用 bootstrap 的话就要导入以下依赖就可以了 &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-bootstrap&lt;/artifactId&gt;&lt;/dependency&gt; 导入依赖后再次启动网关，发现启动端口变成了我们刚在 Nacos 上配置的 8989 了，这时你打开浏览器访问 http://localhost:8989 就会跳转到百度首页了。 动态路由其实到这一步，动态路由的工作基本上已经完成了，现在你可以在 Nacos 找到刚才配置 gateway.yml，然后点击右边的编辑按钮，修改一下配置的路由。比如我这边把它改成知乎的地址。 配置完后点击下面的发布，此时你不用任何操作，不用重启网关项目，直接再次访问 http://localhost:8989 ，就会发现现在会跳转到知乎了。这样就实现了动态路由了。","categories":[{"name":"Spring","slug":"Spring","permalink":"https://greycode.top/categories/Spring/"}],"tags":[{"name":"Nacos","slug":"Nacos","permalink":"https://greycode.top/tags/Nacos/"},{"name":"Spring Cloud Gateway","slug":"Spring-Cloud-Gateway","permalink":"https://greycode.top/tags/Spring-Cloud-Gateway/"}]},{"title":"Dubbo项目双注册中心","slug":"spring/C2E28AA517AA45768B679D93F248B5DE","date":"2021-05-07T13:29:00.000Z","updated":"2022-04-16T02:52:58.653Z","comments":true,"path":"spring/C2E28AA517AA45768B679D93F248B5DE/","link":"","permalink":"https://greycode.top/spring/C2E28AA517AA45768B679D93F248B5DE/","excerpt":"","text":"🤔为什么要双注册中心？当前 Dubbo 版本注册粒度是以接口粒度来注册的，而 SpringBoot 是以服务为粒度来注册的。而且 Dubbo 有自己的注册中心（当然 Spring Cloud Alibaba Dubbo 的注册中心可以挂靠在 Spring 上）。所以当一个项目既要调用 Dubbo 服务，又要提供自己的 Web 接口给网关调用时，就要为该项目设置两个注册中心，一个 Dubbo，一个 SpringBoot的（当然可以注册到同一个注册中心上）。 🛠️创建一个 Dubbo 服务提供者我们先创建一个 Dubbo 服务提供者，然后把它注册到 Zoookeeper 上。我这边用到是 2.7.10 版本到 Dubbo，不同 Dubbo 版本到配置有所差异化。 pom 依赖： &lt;dependency&gt; &lt;groupId&gt;org.apache.dubbo&lt;/groupId&gt; &lt;artifactId&gt;dubbo-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.7.10&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.dubbo&lt;/groupId&gt; &lt;artifactId&gt;dubbo-dependencies-zookeeper&lt;/artifactId&gt; &lt;version&gt;2.7.10&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;/dependency&gt; 然后我们定义一个接口，返回一些文字，记得加上 @DubboService 注解，让 Dubbo 应用发现这个接口并注册到注册 Zookeeper 上。同时在启动类上面还要加上 @EnableDubbo 注解。当然你也可以用配置到方式来配置这些。 @DubboServicepublic class DemoServiceImpl implements DemoService &#123; @Override public String hello() &#123; return &quot;hello! This is Dubbo&#x27;s demo&quot;; &#125;&#125; 定义好接口后，我们在配置文件加上如下配置： server: port: 8787dubbo: application: id: dubbo-privode protocol: name: dubbo port: 28808 registry: address: zookeeper://localhost:2181 在上面配置中，我们定义来项目启动到端口为 8787 ，然后配置了 Dubbo 的协议名称和端口，同时也配置了注册地址为本地的 Zookeeper 的地址。 项目启动后，我们就可以看到 Zookeeper 的节点上多了一个 dubbo 节点，节点下面有我们注册上去的 Dubbo 接口 🛠️创建一个服务消费者消费者基本和服务提供者配置相同，只是要额外加上 web 依赖，应为我们要对外提供 HTTP 接口。 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt; 然后 yml 配置稍作修改，改下端口什么的 server: port: 8788dubbo: application: id: dubbo-consumer protocol: name: dubbo port: 28808 registry: address: zookeeper://localhost:2181 配置好后，我们创建一个对外的 HTTP 接口，并且调用上面服务提供者提供的服务，我们可以直接用注解 @DubboReference 来表示我们要调用 Dubbo 服务接口。 @RestControllerpublic class DubboConsumer &#123; @DubboReference DemoService demoService; @GetMapping(&quot;/consumer&quot;) public String dubboDemo()&#123; return demoService.hello(); &#125;&#125; 启动项目后，注册中心就会出现一个 consumers 节点，这个节点下面有我们注册上去是服务消费者。 这时候我们直接访问 [http://localhost:8788/consumer](http://localhost:8788/consumer) 地址，页面就会响应 hello! This is Dubbo&#39;s demo 字符串，这是我们在服务提供者中定义返回的数据，说明我们成功调用了服务提供者提供的 Dubbo 服务。 🔑为消费者再配置一个注册中心这时候如果我们网关要调用这个消费者提供的 HTTP 接口怎么办？ 你可能会想，可以直接把http://localhost:8788/consumer 这个地址配置到网关路由到 uri 字段上。但是我们一般项目不单单是只有一个，而且有时候地址也会变化，这时候网关就要用到服务名来调用对应到服务，网关一般以 lb://service-name 来调用对应到服务。 如果网关想要以服务名来调用这个消费者，那么我们就要以服务名到方式来把这个消费者注册到 Zookeeper 上。 由于 Spring Cloud 官方已经将 Zookeeper 整合进了 Spring Cloud 体系，所以我们可以直接用 Spring Cloud 下的包。需要添加如下依赖： &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zookeeper-discovery&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Hoxton.SR11&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 同时配置文件需要再添加如下配置，下面的配置中我们指定了要注册到 Zookeeper 到服务名 dubbo-consumer ,配置了注册中心到地址。 spring: application: name: dubbo-consumer cloud: zookeeper: connect-string: localhost:2181 同时启动类也要加上 @EnableDiscoveryClient 注解，不然是不会注册到 Zookeeper 上到。 启动项目后，我们就可以在 Zookeeper 的 services 节点下面看到我们的服务了 同样的我们可以看到注册上去到数据： &#123; &quot;name&quot;: &quot;dubbo-consumer&quot;, &quot;id&quot;: &quot;beff8ece-85a3-47ed-bd0b-34fc193eb3f1&quot;, &quot;address&quot;: &quot;169.254.238.114&quot;, &quot;port&quot;: 8788, &quot;sslPort&quot;: null, &quot;payload&quot;: &#123; &quot;@class&quot;: &quot;org.springframework.cloud.zookeeper.discovery.ZookeeperInstance&quot;, &quot;id&quot;: &quot;application-1&quot;, &quot;name&quot;: &quot;dubbo-consumer&quot;, &quot;metadata&quot;: &#123; &quot;instance_status&quot;: &quot;UP&quot; &#125; &#125;, &quot;registrationTimeUTC&quot;: 1620123669588, &quot;serviceType&quot;: &quot;DYNAMIC&quot;, &quot;uriSpec&quot;: &#123; &quot;parts&quot;: [ &#123; &quot;value&quot;: &quot;scheme&quot;, &quot;variable&quot;: true &#125;, &#123; &quot;value&quot;: &quot;://&quot;, &quot;variable&quot;: false &#125;, &#123; &quot;value&quot;: &quot;address&quot;, &quot;variable&quot;: true &#125;, &#123; &quot;value&quot;: &quot;:&quot;, &quot;variable&quot;: false &#125;, &#123; &quot;value&quot;: &quot;port&quot;, &quot;variable&quot;: true &#125; ] &#125;&#125; 🍰网关调用服务注册上去后，我们就可以修改下我们上节网关项目到路由配置，把它改成用服务名调用。我们可以修改 yml 配置，把 uri 改成服务调用的格式 spring: cloud: gateway: routes: - id: route-demo uri: lb://dubbo-consumer predicates: - Path=/** 或者如果我们是用 Java 代码方式配置的路由可以改成如下代码： @Beanpublic RouteLocator routesConfig(RouteLocatorBuilder builder)&#123; return builder.routes() .route(&quot;route-demo&quot;,r -&gt; r.path(&quot;/**&quot;).uri(&quot;lb://dubbo-consumer&quot;)) .build();&#125; 修改完成后，启动网关，然后访问网关地址 http://localhost:8080/consumer 就可以看到页面显示 hello! This is Dubbo&#39;s demo","categories":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://greycode.top/categories/Dubbo/"}],"tags":[{"name":"Dubbbo","slug":"Dubbbo","permalink":"https://greycode.top/tags/Dubbbo/"},{"name":"Spring","slug":"Spring","permalink":"https://greycode.top/tags/Spring/"}]},{"title":"快速搭建一个SpringGateway网关","slug":"spring/9944CC0FEBD34A3EBD04EAA1564F4C3A","date":"2021-05-07T13:05:58.000Z","updated":"2022-04-16T02:52:58.653Z","comments":true,"path":"spring/9944CC0FEBD34A3EBD04EAA1564F4C3A/","link":"","permalink":"https://greycode.top/spring/9944CC0FEBD34A3EBD04EAA1564F4C3A/","excerpt":"","text":"☝️搭建脚手架我们可以去 Spring initializer 网站或者用 IDEA 来快速创建出一个 Spring Cloud Gateway 项目。 这里我们选择的注册中心是 Zookeeper，你也可以自己选择其他的注册中心来注册你的项目，比如阿里巴巴的 Nacos 等。 配置完相关信息后，点击下面的 GENERATE 按钮就可以导出项目的 zip 压缩包，解压后用 IDE 打开。 打开后就是这个样子： ✌️配置路由Ymal 方式配置为了方便配置，我们把 application.properties 改成 application.yml 。 然后配置一个转发到百度到路由。 spring: cloud: gateway: routes: - id: route-demo uri: https://baidu.com predicates: - Path=/** 在配置中，我加来一个谓词 Path ，表示所有当请求都会匹配到这个路由下，然后转发到 uri 配置到网址里。所以当我们打开浏览器访问 [http://localhost:8080/](http://localhost:8080/) 是就会自动跳转到百度到首页。 Java 代码方式配置除了用配置文件配置路由外，我们还可以用代码的方式来配置路由。 下面来展示一下代码方式配置的路由： @Beanpublic RouteLocator routesConfig(RouteLocatorBuilder builder)&#123; return builder.routes() .route(&quot;route-demo&quot;,r -&gt; r.path(&quot;/**&quot;).uri(&quot;https://baidu.com&quot;)) .build();&#125; 这几行代码实现的是和上面配置一样的功能，当访问 [http://localhost:8080/](http://localhost:8080/) 时也会跳转到百度首页。 👌注册到 Zookeeper接下来演示一下如何把网关注册到 Zookeeper。 首先在我们本地搭建好 Zookeeper，我这边是直接用 Docker 启动了一个 Zookeeper。 然后在配置文件添加如下配置： spring: application: name: weidain-gateway cloud: zookeeper: connect-string: localhost:2181 上面到 weidain-gateway 是我们注册到 Zookeeper 上到服务名，地址 [localhost:2181](http://localhost:2181) 是我们本地 Zookeeper 注册中心到地址。 启动项目后，我们用 Zookeeper 可视化工具就可以看到注册中心多了一个 services 节点，节点下面有我们注册上去的 weidain-gateway 服务 下面就是我们网关服务注册到 Zookeeper 到数据： &#123; &quot;name&quot;: &quot;weidain-gateway&quot;, &quot;id&quot;: &quot;8c802a81-12e7-4f72-9034-aee00c0745bb&quot;, &quot;address&quot;: &quot;169.254.238.114&quot;, &quot;port&quot;: 8080, &quot;sslPort&quot;: null, &quot;payload&quot;: &#123; &quot;@class&quot;: &quot;org.springframework.cloud.zookeeper.discovery.ZookeeperInstance&quot;, &quot;id&quot;: &quot;application-1&quot;, &quot;name&quot;: &quot;weidain-gateway&quot;, &quot;metadata&quot;: &#123; &quot;instance_status&quot;: &quot;UP&quot; &#125; &#125;, &quot;registrationTimeUTC&quot;: 1620118042689, &quot;serviceType&quot;: &quot;DYNAMIC&quot;, &quot;uriSpec&quot;: &#123; &quot;parts&quot;: [ &#123; &quot;value&quot;: &quot;scheme&quot;, &quot;variable&quot;: true &#125;, &#123; &quot;value&quot;: &quot;://&quot;, &quot;variable&quot;: false &#125;, &#123; &quot;value&quot;: &quot;address&quot;, &quot;variable&quot;: true &#125;, &#123; &quot;value&quot;: &quot;:&quot;, &quot;variable&quot;: false &#125;, &#123; &quot;value&quot;: &quot;port&quot;, &quot;variable&quot;: true &#125; ] &#125;&#125;","categories":[{"name":"Spring","slug":"Spring","permalink":"https://greycode.top/categories/Spring/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://greycode.top/tags/SpringCloud/"},{"name":"Gateway","slug":"Gateway","permalink":"https://greycode.top/tags/Gateway/"}]},{"title":"telnet使用smtp协议发送qq邮件","slug":"protocol/4dd3868b-e23e-4446-b7ec-fd95e98612f4","date":"2021-03-23T10:36:44.000Z","updated":"2022-04-16T02:52:58.653Z","comments":true,"path":"protocol/4dd3868b-e23e-4446-b7ec-fd95e98612f4/","link":"","permalink":"https://greycode.top/protocol/4dd3868b-e23e-4446-b7ec-fd95e98612f4/","excerpt":"","text":"操作步骤 telnet命令调试QQ邮箱的smtp服务器 telnet smtp.qq.com 25# 响应Trying 183.3.225.42...Connected to smtp.qq.com.Escape character is &#x27;^]&#x27;.220 newxmesmtplogicsvrsza5.qq.com XMail Esmtp QQ Mail Server. 使用EHLO命令，指示ESMTP会话开始。服务器可以在它对 EHLO 的响应中表明自己支持 ESMTP 命令 EHLO smtp.qq.com# 响应250-newxmesmtplogicsvrsza5.qq.com250-PIPELINING250-SIZE 73400320250-STARTTLS250-AUTH LOGIN PLAIN250-AUTH=LOGIN250-MAILCOMPRESS250 8BITMIME 使用AUTH关键字进行身份验证，这里使用AUTH LOGIN，然后输入Base64编码的用户名和QQ邮箱授权码 AUTH LOGIN// base64编码的`Username:`$ 334 VXNlcm5hbWU6 // base64编码的`Password:`$ 334 UGFzc3dvcmQ6# 响应235 Authentication successful 使用MAIL命令，通过标识邮件的发件人来标识邮件传输开始；以 MAIL FROM 的形式使用。 MAIL FROM:&lt;211019847@qq.com&gt;# 响应250 OK. 使用RCPT命令标识邮件的收件人；以 RCPT TO 的形式使用。 RCPT TO:&lt;573419235@qq.com&gt;# 响应250 OK 使用DATA命令发送数据，以.符号代表结束 DATA# 响应354 End data with &lt;CR&gt;&lt;LF&gt;.&lt;CR&gt;&lt;LF&gt;. 输入内容 FROM: 211019847@qq.comTO: 573419235@qq.comSUBJECT: shell emailthis is body msg!. 使用QUIT命令退出 QUIT# 响应221 Bye.Connection closed by foreign host. 此时，573419235@qq.com邮箱就会收到一封标题为shell email,内容为 *this is body msg!*的邮件了。","categories":[{"name":"Protocol","slug":"Protocol","permalink":"https://greycode.top/categories/Protocol/"}],"tags":[{"name":"smtp","slug":"smtp","permalink":"https://greycode.top/tags/smtp/"},{"name":"telnet","slug":"telnet","permalink":"https://greycode.top/tags/telnet/"}]},{"title":"【go库】钉钉机器人","slug":"golang/47ca1795-f020-44a6-9847-02ef3955f6c9","date":"2021-03-19T14:18:58.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"golang/47ca1795-f020-44a6-9847-02ef3955f6c9/","link":"","permalink":"https://greycode.top/golang/47ca1795-f020-44a6-9847-02ef3955f6c9/","excerpt":"","text":"钉钉机器人 go库 github地址：https://github.com/greycodee/dingbot 钉钉官方文档 快速开始scriptgo get github.com/greycodee/dingbot 示例程序： package mainimport ( &quot;fmt&quot; &quot;github.com/greycodee/dingbot&quot; &quot;github.com/greycodee/dingbot/message&quot; &quot;time&quot;)func main() &#123; bot:= dingbot.DingBot&#123; Secret: &quot;你的加签秘钥&quot;, AccessToken: &quot;你的AccessToken【从钉钉机器人的url上获取】&quot;, &#125; msg := message.Message&#123; MsgType: message.TextStr, Text: message.Text_&#123; Content: &quot;go-钉钉机器人测试&quot;, &#125;, &#125; bot.Send(msg)&#125; 消息支持 text类型 link类型 markdown类型 整体跳转ActionCard类型 独立跳转ActionCard类型 FeedCard类型 使用发送Text消息func send() &#123; bot:= dingbot.DingBot&#123; Secret: &quot;你的加签秘钥&quot;, AccessToken: &quot;你的AccessToken【从钉钉机器人的url上获取】&quot;, &#125; msg := message.Message&#123; MsgType: message.TextStr, Text: message.Text_&#123; Content: &quot;go-钉钉机器人测试&quot;, At: message.At_&#123; AtMobiles: []string&#123;&quot;188xxxxxxxx&quot;&#125;, IsAtAll: false, &#125;, &#125;, &#125; bot.Send(msg)&#125; 发送link类型消息func send() &#123; bot:= dingbot.DingBot&#123; Secret: &quot;你的加签秘钥&quot;, AccessToken: &quot;你的AccessToken【从钉钉机器人的url上获取】&quot;, &#125; msg := message.Message&#123; MsgType: message.LinkStr, Link: message.Link_&#123; Text: &quot;link测试123123&quot;, Title: &quot;go钉钉机器人&quot;, PicUrl: &quot;&quot;, MessageUrl: &quot;https://developers.dingtalk.com/document/app/custom-robot-access/title-72m-8ag-pqw&quot;, &#125;, &#125; bot.Send(msg)&#125; 发送markdown类型消息func send() &#123; bot:= dingbot.DingBot&#123; Secret: &quot;你的加签秘钥&quot;, AccessToken: &quot;你的AccessToken【从钉钉机器人的url上获取】&quot;, &#125; msg := message.Message&#123; MsgType: message.MarkdownStr, Markdown: message.Markdown_&#123; Title: &quot;go钉钉&quot;, Text: &quot;## go钉钉测试 @188xxxxxxxx \\n&gt;文本123&quot;, At: message.At_&#123; AtMobiles: []string&#123;&quot;188xxxxxxxx&quot;&#125;, IsAtAll: false, &#125;, &#125;, &#125; bot.Send(msg)&#125; 发送整体跳转ActionCard类型消息func send() &#123; bot:= dingbot.DingBot&#123; Secret: &quot;你的加签秘钥&quot;, AccessToken: &quot;你的AccessToken【从钉钉机器人的url上获取】&quot;, &#125; msg := message.Message&#123; MsgType: message.ActionCardStr, ActionCard: message.ActionCard_&#123; Title: &quot;ActionCard整体跳转11&quot;, Text: &quot;ActionCardt整体跳转1223&quot;, SingleTitle: &quot;阅读全文&quot;, SingleURL: &quot;https://developers.dingtalk.com/document/app/custom-robot-access/title-72m-8ag-pqw&quot;, &#125;, &#125; bot.Send(msg)&#125; 发送独立跳转ActionCard类型消息func send() &#123; bot:= dingbot.DingBot&#123; Secret: &quot;你的加签秘钥&quot;, AccessToken: &quot;你的AccessToken【从钉钉机器人的url上获取】&quot;, &#125; msg := message.Message&#123; MsgType: message.ActionCardStr, ActionCard: message.ActionCard_&#123; Title: &quot;ActionCard跳转11&quot;, Text: &quot;ActionCardt跳转1223&quot;, BtnOrientation: &quot;1&quot;, HideAvatar: &quot;0&quot;, BtnS: []message.Btn_&#123; &#123; Title: &quot;按钮1&quot;, ActionURL: &quot;https://developers.dingtalk.com/&quot;, &#125;, &#123; Title: &quot;按钮2&quot;, ActionURL: &quot;https://developers.dingtalk.com/&quot;, &#125;, &#125;, &#125;, &#125; bot.Send(msg)&#125; 发送FeedCard类型消息func send() &#123; bot:= dingbot.DingBot&#123; Secret: &quot;你的加签秘钥&quot;, AccessToken: &quot;你的AccessToken【从钉钉机器人的url上获取】&quot;, &#125; msg := message.Message&#123; MsgType: message.FeedCardStr, FeedCard: message.FeedCard_&#123;[]message.Link_&#123; &#123; Title: &quot;标题1&quot;, PicUrl: &quot;&quot;, MessageUrl: &quot;https://developers.dingtalk.com/&quot;, &#125;, &#123; Title: &quot;标题2&quot;, PicUrl: &quot;&quot;, MessageUrl: &quot;https://developers.dingtalk.com/&quot;, &#125;, &#125;&#125;, &#125; bot.Send(msg)&#125;","categories":[{"name":"Go","slug":"Go","permalink":"https://greycode.top/categories/Go/"}],"tags":[{"name":"Go","slug":"Go","permalink":"https://greycode.top/tags/Go/"},{"name":"钉钉机器人","slug":"钉钉机器人","permalink":"https://greycode.top/tags/%E9%92%89%E9%92%89%E6%9C%BA%E5%99%A8%E4%BA%BA/"}]},{"title":"go自定义库上传github下载不了问题","slug":"golang/e1273901-26b1-4cfb-a55c-a9f5047855a5","date":"2021-03-19T11:39:50.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"golang/e1273901-26b1-4cfb-a55c-a9f5047855a5/","link":"","permalink":"https://greycode.top/golang/e1273901-26b1-4cfb-a55c-a9f5047855a5/","excerpt":"","text":"自定义库上传github标签规范当自己写的库要上传到github时,标签号要符合vX.Y.Z的格式，例如v1.0.0 如果定义其他的标签格式，则go会下载不到，例如v1.0,此时如果用go get命令下载的话，则下载不到此版本","categories":[{"name":"Go","slug":"Go","permalink":"https://greycode.top/categories/Go/"}],"tags":[{"name":"Go","slug":"Go","permalink":"https://greycode.top/tags/Go/"}]},{"title":"gitalk更换自定义代理","slug":"archive/33f09b03-a5a7-4d66-93d3-7063905f9b81","date":"2021-03-11T12:10:04.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"archive/33f09b03-a5a7-4d66-93d3-7063905f9b81/","link":"","permalink":"https://greycode.top/archive/33f09b03-a5a7-4d66-93d3-7063905f9b81/","excerpt":"","text":"首先注册一个https://dash.cloudflare.com/ 的账号 然后创建一个Workers。 然后将代码复制到输入框里： /*CORS Anywhere as a Cloudflare Worker!(c) 2019 by Zibri (www.zibri.org)email: zibri AT zibri DOT orghttps://github.com/Zibri/cloudflare-cors-anywhere*//*whitelist = [ &quot;^http.?://www.zibri.org$&quot;, &quot;zibri.org$&quot;, &quot;test\\\\..*&quot; ]; // regexp for whitelisted urls*/blacklist = [ ]; // regexp for blacklisted urlswhitelist = [ &quot;.*&quot; ]; // regexp for whitelisted originsfunction isListed(uri,listing) &#123; var ret=false; if (typeof uri == &quot;string&quot;) &#123; listing.forEach((m)=&gt;&#123; if (uri.match(m)!=null) ret=true; &#125;); &#125; else &#123; // decide what to do when Origin is null ret=true; // true accepts null origins false rejects them. &#125; return ret;&#125;addEventListener(&quot;fetch&quot;, async event=&gt;&#123; event.respondWith((async function() &#123; isOPTIONS = (event.request.method == &quot;OPTIONS&quot;); var origin_url = new URL(event.request.url); function fix(myHeaders) &#123; // myHeaders.set(&quot;Access-Control-Allow-Origin&quot;, &quot;*&quot;); myHeaders.set(&quot;Access-Control-Allow-Origin&quot;, event.request.headers.get(&quot;Origin&quot;)); if (isOPTIONS) &#123; myHeaders.set(&quot;Access-Control-Allow-Methods&quot;, event.request.headers.get(&quot;access-control-request-method&quot;)); acrh = event.request.headers.get(&quot;access-control-request-headers&quot;); //myHeaders.set(&quot;Access-Control-Allow-Credentials&quot;, &quot;true&quot;); if (acrh) &#123; myHeaders.set(&quot;Access-Control-Allow-Headers&quot;, acrh); &#125; myHeaders.delete(&quot;X-Content-Type-Options&quot;); &#125; return myHeaders; &#125; var fetch_url = unescape(unescape(origin_url.search.substr(1))); var orig = event.request.headers.get(&quot;Origin&quot;); var remIp = event.request.headers.get(&quot;CF-Connecting-IP&quot;); if ((!isListed(fetch_url, blacklist)) &amp;&amp; (isListed(orig, whitelist))) &#123; xheaders = event.request.headers.get(&quot;x-cors-headers&quot;); if (xheaders != null) &#123; try &#123; xheaders = JSON.parse(xheaders); &#125; catch (e) &#123;&#125; &#125; if (origin_url.search.startsWith(&quot;?&quot;)) &#123; recv_headers = &#123;&#125;; for (var pair of event.request.headers.entries()) &#123; if ((pair[0].match(&quot;^origin&quot;) == null) &amp;&amp; (pair[0].match(&quot;eferer&quot;) == null) &amp;&amp; (pair[0].match(&quot;^cf-&quot;) == null) &amp;&amp; (pair[0].match(&quot;^x-forw&quot;) == null) &amp;&amp; (pair[0].match(&quot;^x-cors-headers&quot;) == null) ) recv_headers[pair[0]] = pair[1]; &#125; if (xheaders != null) &#123; Object.entries(xheaders).forEach((c)=&gt;recv_headers[c[0]] = c[1]); &#125; newreq = new Request(event.request,&#123; &quot;headers&quot;: recv_headers &#125;); var response = await fetch(fetch_url,newreq); var myHeaders = new Headers(response.headers); cors_headers = []; allh = &#123;&#125;; for (var pair of response.headers.entries()) &#123; cors_headers.push(pair[0]); allh[pair[0]] = pair[1]; &#125; cors_headers.push(&quot;cors-received-headers&quot;); myHeaders = fix(myHeaders); myHeaders.set(&quot;Access-Control-Expose-Headers&quot;, cors_headers.join(&quot;,&quot;)); myHeaders.set(&quot;cors-received-headers&quot;, JSON.stringify(allh)); if (isOPTIONS) &#123; var body = null; &#125; else &#123; var body = await response.arrayBuffer(); &#125; var init = &#123; headers: myHeaders, status: (isOPTIONS ? 200 : response.status), statusText: (isOPTIONS ? &quot;OK&quot; : response.statusText) &#125;; return new Response(body,init); &#125; else &#123; var myHeaders = new Headers(); myHeaders = fix(myHeaders); if (typeof event.request.cf != &quot;undefined&quot;) &#123; if (typeof event.request.cf.country != &quot;undefined&quot;) &#123; country = event.request.cf.country; &#125; else country = false; if (typeof event.request.cf.colo != &quot;undefined&quot;) &#123; colo = event.request.cf.colo; &#125; else colo = false; &#125; else &#123; country = false; colo = false; &#125; return new Response( &quot;CLOUDFLARE-CORS-ANYWHERE\\n\\n&quot; + &quot;Source:\\nhttps://github.com/Zibri/cloudflare-cors-anywhere\\n\\n&quot; + &quot;Usage:\\n&quot; + origin_url.origin + &quot;/?uri\\n\\n&quot; + &quot;Donate:\\nhttps://paypal.me/Zibri/5\\n\\n&quot; + &quot;Limits: 100,000 requests/day\\n&quot; + &quot; 1,000 requests/10 minutes\\n\\n&quot; + (orig != null ? &quot;Origin: &quot; + orig + &quot;\\n&quot; : &quot;&quot;) + &quot;Ip: &quot; + remIp + &quot;\\n&quot; + (country ? &quot;Country: &quot; + country + &quot;\\n&quot; : &quot;&quot;) + (colo ? &quot;Datacenter: &quot; + colo + &quot;\\n&quot; : &quot;&quot;) + &quot;\\n&quot; + ((xheaders != null) ? &quot;\\nx-cors-headers: &quot; + JSON.stringify(xheaders) : &quot;&quot;), &#123;status: 200, headers: myHeaders&#125; ); &#125; &#125; else &#123; return new Response( &quot;Create your own cors proxy&lt;/br&gt;\\n&quot; + &quot;&lt;a href=&#x27;https://github.com/Zibri/cloudflare-cors-anywhere&#x27;&gt;https://github.com/Zibri/cloudflare-cors-anywhere&lt;/a&gt;&lt;/br&gt;\\n&quot; + &quot;\\nDonate&lt;/br&gt;\\n&quot; + &quot;&lt;a href=&#x27;https://paypal.me/Zibri/5&#x27;&gt;https://paypal.me/Zibri/5&lt;/a&gt;\\n&quot;, &#123; status: 403, statusText: &#x27;Forbidden&#x27;, headers: &#123; &quot;Content-Type&quot;: &quot;text/html&quot; &#125; &#125;); &#125; &#125; )());&#125;); 作者地址：https://github.com/Zibri/cloudflare-cors-anywhere 点击保存部署就可以了 然后吧gitalk的代理换到你自己上面的部署地址就可以了。类似： https://【上面部署的地址】.workers.dev/?https://github.com/login/oauth/access_token","categories":[],"tags":[{"name":"gitalk","slug":"gitalk","permalink":"https://greycode.top/tags/gitalk/"}]},{"title":"Java的NIO编程-Channel","slug":"java/nio/534d0985-a4a0-4239-ae81-d76378f64552","date":"2021-03-01T10:07:09.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"java/nio/534d0985-a4a0-4239-ae81-d76378f64552/","link":"","permalink":"https://greycode.top/java/nio/534d0985-a4a0-4239-ae81-d76378f64552/","excerpt":"","text":"0x1 主要类型在Java中有许多NIO Channel实现，本文只选最主要的四种Channel： FileChannel：文件通道，用于文件的数据读写 SocketChannel：套接字通道，用于Socket套接字TCP连接的数据读写。 ServerSocketChannel：服务器嵌套字通道（或服务器监听通道），允许我们监听TCP连接请求，为每个监听到的请求，创建一个SocketChannel套接字通道。 DatagramChannel：数据报通道，用于UDP协议的数据读写。 0x2 使用FileChannel读取通道数据首先在本地创建文件/home/zheng/channeltest，在里面编写内容：hello,world! public class ChannelTest &#123; public static void main(String[] args) throws IOException &#123; // 创建输入流 File file = new File(&quot;/home/zheng/channeltest&quot;); FileInputStream fis = new FileInputStream(file); // 获取通道 FileChannel fileChannel = fis.getChannel(); // 创建缓冲区 ByteBuffer byteBuffer = ByteBuffer.allocate(1024); int length = -1; // 读取通道数据到缓冲区 while ((length=fileChannel.read(byteBuffer))!=-1)&#123; System.out.println(&quot;缓冲区size：&quot;+length); &#125; fis.close(); fileChannel.close(); // 读取Buffer缓存数据 byteBuffer.flip(); StringBuilder str = new StringBuilder(); while (byteBuffer.position()!=byteBuffer.limit())&#123; char c = (char) byteBuffer.get(); str.append(c); &#125; System.out.println(str.toString()); &#125;&#125;//输出缓冲区size：13hello,world! 写入数据到通道public class ChannelTest &#123; public static void main(String[] args) throws IOException &#123; // 创建输入流 File file = new File(&quot;/home/zheng/channelOut&quot;); FileOutputStream fos = new FileOutputStream(file); // 获取通道 FileChannel fileChannel = fos.getChannel(); // 创建缓冲区 ByteBuffer byteBuffer = ByteBuffer.allocate(1024); byte c = &#x27;c&#x27;; byte o = &#x27;o&#x27;; byte d = &#x27;d&#x27;; byte e = &#x27;e&#x27;; byteBuffer.put(c); byteBuffer.put(o); byteBuffer.put(d); byteBuffer.put(e); int length = 0; // 缓冲区转换为读模式 byteBuffer.flip(); // 向通道写入数据 while ((length=fileChannel.write(byteBuffer))!=0)&#123; System.out.println(&quot;写入数据size：&quot;+length); &#125; //强制刷盘 fileChannel.force(true); fileChannel.close(); &#125;&#125;// 输出写入数据size：4 此时查看文件/home/zheng/channelOut，里面内容是:code SocketChannel和ServerSocketChannel 服务端 public class SocketServer &#123; public static void main(String[] args) throws IOException &#123; // 打开ServerSocketChannel ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); // 绑定端口 serverSocketChannel.socket().bind(new InetSocketAddress(8989)); // 设置为非阻塞式工作模式（io多路复用） serverSocketChannel.configureBlocking(false); while (true)&#123; // 等待客户端连接 SocketChannel channel = serverSocketChannel.accept(); if (channel!=null)&#123; System.out.println(&quot;==================&quot;); System.out.println(&quot;客户端地址：&quot;+channel.getRemoteAddress()); ByteBuffer byteBuffer = ByteBuffer.allocate(1024); // 读取通道的数据到缓冲区 channel.read(byteBuffer); // 读取Buffer缓存数据 byteBuffer.flip(); StringBuilder str = new StringBuilder(); while (byteBuffer.position()!=byteBuffer.limit())&#123; char c = (char) byteBuffer.get(); str.append(c); &#125; System.out.println(&quot;接收到消息：&quot;+str.toString()); &#125; &#125; &#125;&#125; 客户端 public class SocketClient &#123; public static void main(String[] args) throws IOException, InterruptedException &#123; // 打开SocketChannel SocketChannel channel = SocketChannel.open(); // 设置为非阻塞式工作模式（io多路复用） channel.configureBlocking(false); // 连接 channel.connect(new InetSocketAddress(&quot;127.0.0.1&quot;,8989)); while (!channel.finishConnect())&#123; System.out.println(&quot;连接中...&quot;); Thread.sleep(1000); &#125; ByteBuffer byteBuffer = ByteBuffer.allocate(1024); byteBuffer.put((byte)&#x27;s&#x27;); byteBuffer.flip(); // 从缓冲区写入数据到通道 channel.write(byteBuffer); channel.close(); &#125;&#125; 先运行服务端，然后在运行客户端，此时服务端控制台打印出： ==================客户端地址：/127.0.0.1:44728接收到消息：s DatagramChannel 发送端 public class DatagramClient &#123; public static void main(String[] args) throws IOException &#123; // 开启DatagramChannel DatagramChannel channel = DatagramChannel.open(); // 设置为非阻塞式工作模式（io多路复用） channel.configureBlocking(false); // 创建缓存区 ByteBuffer byteBuffer = ByteBuffer.allocate(1024); Scanner scanner = new Scanner(System.in); System.out.println(&quot;请输入要发送的消息：&quot;); while (scanner.hasNext())&#123; String s = scanner.next(); byteBuffer.put(s.getBytes()); byteBuffer.flip(); // 发送数据 channel.send(byteBuffer,new InetSocketAddress(&quot;127.0.0.1&quot;,8989)); byteBuffer.clear(); &#125; channel.close(); &#125;&#125; 接收端 public class DatagramServer &#123; public static void main(String[] args) throws IOException &#123; // 开启DatagramChannel DatagramChannel serverChannel = DatagramChannel.open(); // 设置为非阻塞式工作模式（io多路复用） serverChannel.configureBlocking(false); // 绑定监听地址 serverChannel.bind(new InetSocketAddress(&quot;127.0.0.1&quot;,8989)); // 创建缓存区 ByteBuffer byteBuffer = ByteBuffer.allocate(1024); while (true)&#123; // 接收消息并保存到缓存区 serverChannel.receive(byteBuffer); byteBuffer.flip(); if (byteBuffer.limit()!=0)&#123; // 读取Buffer缓存数据 StringBuilder str = new StringBuilder(); while (byteBuffer.position()!=byteBuffer.limit())&#123; char c = (char) byteBuffer.get(); str.append(c); &#125; System.out.println(&quot;接收到消息：&quot;+str.toString()); byteBuffer.clear(); &#125; byteBuffer.clear(); &#125; &#125;&#125; 源码地址：https://github.com/GreyCode9/nio-demo","categories":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/tags/Java/"},{"name":"Nio","slug":"Nio","permalink":"https://greycode.top/tags/Nio/"}]},{"title":"Java的NIO编程-Selector","slug":"java/nio/2571330c-67ef-4d4c-8717-6c96768009c7","date":"2021-03-01T10:07:07.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"java/nio/2571330c-67ef-4d4c-8717-6c96768009c7/","link":"","permalink":"https://greycode.top/java/nio/2571330c-67ef-4d4c-8717-6c96768009c7/","excerpt":"","text":"0x1 监控通道和选择器之间的关系，通过register（注册）的方式完成。调用通道的Channel.register（Selector sel, int ops）方法，可以将通道实例注册到一个选择器中。register方法有两个参数：第一个参数，指定通道注册到的选择器实例；第二个参数，指定选择器要监控的IO事件类型。 IO事件类型有： 可读：SelectionKey.OP_READ 可写：SelectionKey.OP_WRITE 连接：SelectionKey.OP_CONNECT 接收：SelectionKey.OP_ACCEPT 如果一下要监控多个事件的话可以用位或运算符来实现 int key = SelectionKey.OP_READ | SelectionKey.OP_WRITE; 0x2 SelectionKey选择键选择键的功能是很强大的。通过SelectionKey选择键，不仅仅可以获得通道的IO事件类型，比方说SelectionKey.OP_READ；还可以获得发生IO事件所在的通道；另外，也可以获得选出选择键的选择器实例。 常用方法 isAcceptable()：判断IO事件类型是否是SelectionKey.OP_ACCEPT isReadable()：判断IO事件是否是SelectionKey.OP_READ isConnectable():判断IO事件是否是SelectionKey.OP_CONNECT isWritable()：判断IO事件是否是SelectionKey.OP_WRITE 0x3 使用条件并不是所有的Channel都可以使用Selector，判断一个通道能否被选择器监控或选择，有一个前提：判断它是否继承了抽象类SelectableChannel（可选择通道）。如果继承了SelectableChannel，则可以被选择，否则不能。 简单地说，一条通道若能被选择，必须继承SelectableChannel类。 FileChannel就没有继承SelectableChannel类，所以不能使用Selector 0x4 使用流程使用选择器，主要有以下三步： 获取选择器实例； 将通道注册到选择器中； 轮询感兴趣的IO就绪事件（选择键集合）。 0x5 Demo源码地址： https://github.com/GreyCode9/nio-demo/tree/main/src/io/selector","categories":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/tags/Java/"},{"name":"Nio","slug":"Nio","permalink":"https://greycode.top/tags/Nio/"}]},{"title":"Java的NIO编程-Buffer","slug":"java/nio/8d2049e3-3eb1-46ed-a44b-57398964eb21","date":"2021-03-01T10:07:05.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"java/nio/8d2049e3-3eb1-46ed-a44b-57398964eb21/","link":"","permalink":"https://greycode.top/java/nio/8d2049e3-3eb1-46ed-a44b-57398964eb21/","excerpt":"","text":"0x1 子类Buffer是一个抽象类，所以一般使用他的子类来进行编程，常用的子类有： ByteBuffer IntBuffer LongBuffer CharBuffer DoubleBufffer FloatBuffer ShortBuffer MappedByteBuffer 0x2 属性Buffer中有四个重要的属性，分别是： capacity：Buffer类的capacity属性，表示内部容量的大小 position：Buffer类的position属性，表示当前的位置 limit：Buffer类的limit属性，表示读写的最大上限。 mark：暂存属性，暂时保存position的值，方便后面的重复使用position值。 0x3 方法Buffer中几个重要的方法有： allocate()：创建缓存区（BUffer创建缓存区不是用new，而是用这个方法来创建) put()：向缓冲器插入数据 filp()：翻转模式，将缓冲区改为读模式（缓冲区默认模式为写模式）。其实就改变了limit，position，mark属性的值。 get()：从缓冲区读取数据，从position位置开始读 rewind()：倒带（重复读取），就是将position的位置重置为0 mark()：mark()方法的作用就是将当前position的位置暂存起来，放在mark属性中。 reset()：将position重置为mark属性的位置。 clean()：清空缓存区，重置position，limit，mark属性为初始值","categories":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/tags/Java/"},{"name":"Nio","slug":"Nio","permalink":"https://greycode.top/tags/Nio/"}]},{"title":"Java的NIO编程-Reactor模式","slug":"java/nio/0702ff46-16cd-4520-9d33-0794cfda4b09","date":"2021-03-01T10:07:04.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"java/nio/0702ff46-16cd-4520-9d33-0794cfda4b09/","link":"","permalink":"https://greycode.top/java/nio/0702ff46-16cd-4520-9d33-0794cfda4b09/","excerpt":"","text":"0x1 Reactor模型0x1 单Reactor单线程","categories":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/tags/Java/"},{"name":"Nio","slug":"Nio","permalink":"https://greycode.top/tags/Nio/"}]},{"title":"Disruptor-消费模式简介(池化)","slug":"java/disruptor/c16646bf-1474-42a7-a5cd-84b99669062c","date":"2021-03-01T10:02:15.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"java/disruptor/c16646bf-1474-42a7-a5cd-84b99669062c/","link":"","permalink":"https://greycode.top/java/disruptor/c16646bf-1474-42a7-a5cd-84b99669062c/","excerpt":"","text":"并行模式(池化)每个消费端有两个线程实例 disruptor.handleEventsWithWorkerPool(new A1Handler(),new A1Handler());disruptor.handleEventsWithWorkerPool(new A2Handler(),new A2Handler()); 结果示例可以看到每次执行的线程是不一样的 ++++++++++++++++++++++++++++++++++++++++++++++++**************************DisruptorWorker-0**************************1605100167571+A1Handler:10**************************DisruptorWorker-21605100167572+A2Handler:30**************************++++++++++++++++++++++++++++++++++++++++++++++++**************************DisruptorWorker-11605100168572+A1Handler:11****************************************************DisruptorWorker-31605100168573+A2Handler:31************************** 串行模式（池化）每个消费端有两个线程实例 disruptor.handleEventsWithWorkerPool(new A1Handler(),new A1Handler()) .then(new A2Handler(),new A2Handler()); 结果示例++++++++++++++++++++++++++++++++++++++++++++++++**************************DisruptorWorker-01605100492248+A1Handler:10****************************************************DisruptorWorker-21605100492249+A2Handler:30**************************++++++++++++++++++++++++++++++++++++++++++++++++**************************DisruptorWorker-11605100493249+A1Handler:11****************************************************DisruptorWorker-31605100493249+A2Handler:31**************************","categories":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/tags/Java/"},{"name":"Disruptor","slug":"Disruptor","permalink":"https://greycode.top/tags/Disruptor/"}]},{"title":"Disruptor-缓存行填充","slug":"java/disruptor/18e3fbd6-ff4b-4a0a-b82f-a547dbef8d0c","date":"2021-03-01T10:02:08.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"java/disruptor/18e3fbd6-ff4b-4a0a-b82f-a547dbef8d0c/","link":"","permalink":"https://greycode.top/java/disruptor/18e3fbd6-ff4b-4a0a-b82f-a547dbef8d0c/","excerpt":"","text":"伪共享概念CPU架构常见的CPU架构如下图： 在某个CPU核心上运行一个线程时，他获取数据是先从L1缓存上面找，没有命中数据时，再从L2缓存上面找、还是没有命中时再从L3缓存上找，如果还没有的话就再从主内存里面找。找到后再一层一层的传递数据。 所以查找数据的顺序为： L1 》L2 》 L3 》主内存 刷新缓存的顺序为： 主内存 》L3 》L2 》L1 缓存存储结构 在计算机缓存中，存储数据是以缓存行为单位的，不同的系统缓存行的大小也不一样，现在常见的64位操作系统，他每行可以存储64字节数据。比如Java中Long类型的数据占8个字节，所以一行可以存8个Long数据类型的数据。 所以当加载缓存行中任意一个数据时，其他在当前缓存行里的数据也会一起加载 线程数据共享当线程共享一个变量时，每个线程的更改都会把最新数据刷新回主内存，如果处理器发现自己缓存行对应的内存地址呗修改，就会将当前处理器的缓存行设置无效状态，当处理器对这个数据进行修改操作的时候，会重新从系统内存中把数据库读到处理器缓存中（嗅探机制）。 伪共享上面说的是共享一个缓存行的一个数据，这样是完全没问题的。可是当不同线程要使用一个缓存行里的不同数据时，这样就会出现一种伪共享的情况: 尽管变量a没有被其他线程更改，可以由于他和变量d在同一缓存行里，所以每次都会受变量d的影响,缓存都会被设置为无效状态，所以每次使用时都会从主内存里重新拉取。这样速度就会大大的打折扣。 RingBuffer的解决方法在RingBuffer解决伪共享的方法就是缓存行填充 abstract class RingBufferPad&#123; protected long p1, p2, p3, p4, p5, p6, p7;&#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/tags/Java/"},{"name":"Disruptor","slug":"Disruptor","permalink":"https://greycode.top/tags/Disruptor/"}]},{"title":"Disruptor-等待策略","slug":"java/disruptor/ff51336d-70d4-449c-9214-fff2542bef1f","date":"2021-03-01T10:02:06.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"java/disruptor/ff51336d-70d4-449c-9214-fff2542bef1f/","link":"","permalink":"https://greycode.top/java/disruptor/ff51336d-70d4-449c-9214-fff2542bef1f/","excerpt":"","text":"BlockingWaitStrategyDisruptor默认策略 对EventProcessor使用等待条件的锁和条件变量的阻塞策略。 当吞吐量和低延迟不如CPU资源那么重要时，可以使用此策略。 LiteBlockingWaitStrategyBlockingWaitStrategy的变体，在无竞争的情况下尝试消除条件唤醒。 显示微基准测试的性能改进。 但是，由于我尚未完全证明锁省略码的正确性，因此应将这种等待策略视为实验性的。 BusySpinWaitStrategy繁忙旋转策略，该繁忙旋转策略对EventProcessor的障碍使用繁忙的旋转循环。 此策略将使用CPU资源来避免可能导致延迟抖动的系统调用。 最好当线程可以绑定到特定的CPU内核时使用。 TimeoutBlockingWaitStrategyLiteTimeoutBlockingWaitStrategyTimeoutBlockingWaitStrategy的变体，在无竞争的情况下尝试消除条件唤醒。 PhasedBackoffWaitStrategy在屏障上等待EventProcessor的分阶段等待策略。 当吞吐量和低延迟不如CPU资源那么重要时，可以使用此策略。旋转，然后屈服，然后使用配置的后备WaitStrategy等待。 SleepingWaitStrategy最初启动的休眠策略，然后使用Thread.yield（），最后在EventProcessor等待屏障时，休眠操作系统和JVM将允许的最小数量的nanos。 此策略是性能和CPU资源之间的良好折衷。安静时段后可能会出现延迟峰值。 这也将减少对生产线程的影响，因为它不需要发出信号通知任何条件变量来唤醒事件处理线程。 YieldingWaitStrategy在初始旋转后，使用Thread.yield（）的EventProcessor在屏障上等待。 如果其他线程需要CPU资源，则此策略将使用100％CPU，但比忙碌的自旋策略更容易放弃CPU。","categories":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/tags/Java/"},{"name":"Disruptor","slug":"Disruptor","permalink":"https://greycode.top/tags/Disruptor/"}]},{"title":"Disruptor-消费模式简介(单个实例)","slug":"java/disruptor/9a1bdb74-8ed3-4905-88bc-7b3b4e0a4af2","date":"2021-03-01T10:01:00.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"java/disruptor/9a1bdb74-8ed3-4905-88bc-7b3b4e0a4af2/","link":"","permalink":"https://greycode.top/java/disruptor/9a1bdb74-8ed3-4905-88bc-7b3b4e0a4af2/","excerpt":"","text":"并行模式并行模式下两个Handler同时执行，互不影响 disruptor.handleEventsWith(new A1Handler(),new B1Handler()); 结果示例++++++++++1605084168915+B1Handler:51605084168915+A1Handler:1++++++++++1605084169915+B1Handler:61605084169915+A1Handler:2 串行模式串行模式下，Handler执行必须是从前往后，按顺序执行。 disruptor.handleEventsWith(new A1Handler()).then(new B1Handler());// ordisruptor.handleEventsWith(new B1Handler()).then(new A1Handler()); 结果示例结果和handler放置的顺序有关，后面的handler要等前面的执行完才会执行 ++++++++++1605084411462+A1Handler:11605084411467+B1Handler:5++++++++++1605084412463+A1Handler:21605084412463+B1Handler:6// or++++++++++1605084638285+B1Handler:51605084638289+A1Handler:1++++++++++1605084639286+B1Handler:61605084639286+A1Handler:2 菱形模式菱形模式其实就是并行和串行的结合体，先并行执行，再串行执行 disruptor.handleEventsWith(new A1Handler(), new A2Handler()).then(new B1Handler()); 结果示例B1Handler要等A1Handler和A2Handler全部执行完，它才会执行。 ++++++++++1605085280283+A1Handler:11605085280283+A2Handler:31605085280287+B1Handler:5++++++++++1605085281283+A1Handler:21605085281283+A2Handler:41605085281283+B1Handler:6 链式模式链式模式也是并行和串行的结合，并行模式执行串行模式 disruptor.handleEventsWith(new A1Handler()).then(new A2Handler());disruptor.handleEventsWith(new B1Handler()).then(new B2Handler()); 结果示例++++++++++1605085843558+B1Handler:51605085843558+A1Handler:11605085843563+A2Handler:31605085843563+B2Handler:7++++++++++1605085844558+B1Handler:61605085844558+A1Handler:21605085844558+B2Handler:81605085844559+A2Handler:4 总结所有的模式都可以根据并行和串行来衍生出各种模式，玩法多种多样。","categories":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/tags/Java/"},{"name":"Disruptor","slug":"Disruptor","permalink":"https://greycode.top/tags/Disruptor/"}]},{"title":"Disruptor-实例化方法","slug":"java/disruptor/b3025291-ae52-4d26-a70c-66a79bda07d7","date":"2021-03-01T09:58:05.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"java/disruptor/b3025291-ae52-4d26-a70c-66a79bda07d7/","link":"","permalink":"https://greycode.top/java/disruptor/b3025291-ae52-4d26-a70c-66a79bda07d7/","excerpt":"","text":"创建一个事件实体public class LongEvent&#123; private Long id; public Long getId() &#123; return id; &#125; public void setId(Long id) &#123; this.id = id; &#125;&#125; 创建一个事件实体工厂public class LongEventFactory implements EventFactory&lt;LongEvent&gt; &#123; public LongEvent newInstance() &#123; return new LongEvent(); &#125;&#125; 创建两个事件处理类/*** EventHandler&lt;LongEvent&gt; 是没有池化的实现方式,每个消费者中只有一个示例* WorkHandler&lt;LongEvent&gt; 是池化的实现方式，每个消费者中可以以类似线程池的方式去执行这个事件* 实际根据业务场景 实现其中一个接口就可以*/public class A1Handler implements EventHandler&lt;LongEvent&gt; , WorkHandler&lt;LongEvent&gt; &#123; public void onEvent(LongEvent longEvent, long l, boolean b) throws Exception &#123; long id = longEvent.getId(); id+=1; System.out.println(&quot;**************************&quot;); System.out.println(Thread.currentThread().getName()); System.out.println(System.currentTimeMillis()+&quot;+A1Handler:&quot;+id); System.out.println(&quot;**************************&quot;); &#125; /** * 池化执行 * */ @Override public void onEvent(LongEvent longEvent) throws Exception &#123; long id = longEvent.getId(); id+=10; System.out.println(&quot;**************************&quot;); System.out.println(Thread.currentThread().getName()); System.out.println(System.currentTimeMillis()+&quot;+A1Handler:&quot;+id); System.out.println(&quot;**************************&quot;); &#125;&#125; public class A2Handler implements EventHandler&lt;LongEvent&gt; , WorkHandler&lt;LongEvent&gt; &#123; public void onEvent(LongEvent longEvent, long l, boolean b) throws Exception &#123; long id = longEvent.getId(); id+=3; System.out.println(&quot;**************************&quot;); System.out.println(Thread.currentThread().getName()); System.out.println(System.currentTimeMillis()+&quot;+A2Handler:&quot;+id); System.out.println(&quot;**************************&quot;); &#125; /** * 池化执行 * */ @Override public void onEvent(LongEvent longEvent) throws Exception &#123; long id = longEvent.getId(); id+=30; System.out.println(&quot;**************************&quot;); System.out.println(Thread.currentThread().getName()); System.out.println(System.currentTimeMillis()+&quot;+A2Handler:&quot;+id); System.out.println(&quot;**************************&quot;); &#125;&#125; 实例化Disruptor// 事件工厂LongEventFactory factory = new LongEventFactory();// 定义RingBuff大小 注意：数值一定是2的幂次方int bufferSize = 1024;// 创建ThreadFactoryThreadFactory threadFactory = new ThreadFactory() &#123; private int counter = 0; private String prefix = &quot;DisruptorWorker&quot;; @Override public Thread newThread(Runnable r) &#123; return new Thread(r, prefix + &quot;-&quot; + counter++); &#125;&#125;;/* 实例化Disruptor （官方有4个实例化方法） * factory 是事件工厂 * bufferSize 是上面定义的RingBuffer的大小 * ProducerType.MULTI 是生产者模式 有SINGL和MULTI两种 * new BlockingWaitStrategy() 是等待阻塞策略 */Disruptor&lt;LongEvent&gt; disruptor = new Disruptor&lt;LongEvent&gt;( factory, bufferSize, threadFactory, ProducerType.MULTI, new BlockingWaitStrategy()); 创建消费者单个模式disruptor会创建2和线程，一个线程用来执行A1Handler，一个线程用来执行A2Handler.每个线程互不影响。 disruptor.handleEventsWith(new A1Handler(),new A2Handler()); 池化模式disruptor会创建4个线程，其中两个线程组成线程池来执行A1Handler，另外两个线程也组成线程池用来执行A2Handler disruptor.handleEventsWithWorkerPool(new A1Handler(),new A1Handler())disruptor.handleEventsWithWorkerPool(new A2Handler(),new A2Handler()) 获取RingBufferRingBuffer&lt;LongEvent&gt; ringBuffer = disruptor.start(); 生产者发布消息这边直接使用Java8的发布方式来发布消息 // 创建ByteBuffer缓冲区 ByteBuffer bb = ByteBuffer.allocate(8);// 生产者发布5条消息for (long l = 0; l&lt;5; l++) &#123; // 写入消息到Bufer缓冲区 bb.putLong(0, l); // Java8 lambda发布方式 ringBuffer.publishEvent((event,sequece,buffer) -&gt; event.setId(buffer.getLong(0)),bb);&#125;System.out.println(&quot;发布完成&quot;); 完整的Main方法public class DisruptorMain &#123; public static void main(String[] args) &#123; // 实例化事件工厂 LongEventFactory factory = new LongEventFactory(); // 定义RingBuffer大小 int bufferSize = 1024; // 创建线程工厂 ThreadFactory threadFactory = new ThreadFactory() &#123; private int counter = 0; private String prefix = &quot;DisruptorWorker&quot;; @Override public Thread newThread(Runnable r) &#123; return new Thread(r, prefix + &quot;-&quot; + counter++); &#125; &#125;; // 实例化Disruptor Disruptor&lt;LongEvent&gt; disruptor = new Disruptor&lt;LongEvent&gt;( factory, bufferSize, threadFactory, ProducerType.MULTI, new BlockingWaitStrategy()); // 并行模式 两个Handler互不影响 disruptor.handleEventsWith(new A1Handler(),new A2Handler()); // 并行 每个消费端有两个线程实例 (池化模式)// disruptor.handleEventsWithWorkerPool(new A1Handler(),new A1Handler());// disruptor.handleEventsWithWorkerPool(new A2Handler(),new A2Handler()); // 获取RingBuffer RingBuffer&lt;LongEvent&gt; ringBuffer = disruptor.start(); // 创建ByteBuffer缓冲区 ByteBuffer bb = ByteBuffer.allocate(8); for (long l = 0; l&lt;5; l++) &#123; // 写入数据到缓冲区 bb.putLong(0, l); // Java8的发布方式 ringBuffer.publishEvent((event,sequece,buffer) -&gt; event.setId(buffer.getLong(0)),bb); &#125; System.out.println(&quot;发布完成&quot;); &#125;&#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/tags/Java/"},{"name":"Disruptor","slug":"Disruptor","permalink":"https://greycode.top/tags/Disruptor/"}]},{"title":"Disruptor-快速开始","slug":"java/disruptor/a552f7f0-4cbe-4628-8fcf-02f8b8730b56","date":"2021-03-01T09:58:03.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"java/disruptor/a552f7f0-4cbe-4628-8fcf-02f8b8730b56/","link":"","permalink":"https://greycode.top/java/disruptor/a552f7f0-4cbe-4628-8fcf-02f8b8730b56/","excerpt":"","text":"创建一个事件实体public class LongEvent&#123; private Long id; public Long getId() &#123; return id; &#125; public void setId(Long id) &#123; this.id = id; &#125;&#125; 创建一个事件实体工厂public class LongEventFactory implements EventFactory&lt;LongEvent&gt; &#123; public LongEvent newInstance() &#123; return new LongEvent(); &#125;&#125; 创建两个事件处理类/*** EventHandler&lt;LongEvent&gt; 是没有池化的实现方式,每个消费者中只有一个示例* WorkHandler&lt;LongEvent&gt; 是池化的实现方式，每个消费者中可以以类似线程池的方式去执行这个事件* 实际根据业务场景 实现其中一个接口就可以*/public class A1Handler implements EventHandler&lt;LongEvent&gt; , WorkHandler&lt;LongEvent&gt; &#123; public void onEvent(LongEvent longEvent, long l, boolean b) throws Exception &#123; long id = longEvent.getId(); id+=1; System.out.println(&quot;**************************&quot;); System.out.println(Thread.currentThread().getName()); System.out.println(System.currentTimeMillis()+&quot;+A1Handler:&quot;+id); System.out.println(&quot;**************************&quot;); &#125; /** * 池化执行 * */ @Override public void onEvent(LongEvent longEvent) throws Exception &#123; long id = longEvent.getId(); id+=10; System.out.println(&quot;**************************&quot;); System.out.println(Thread.currentThread().getName()); System.out.println(System.currentTimeMillis()+&quot;+A1Handler:&quot;+id); System.out.println(&quot;**************************&quot;); &#125;&#125; public class A2Handler implements EventHandler&lt;LongEvent&gt; , WorkHandler&lt;LongEvent&gt; &#123; public void onEvent(LongEvent longEvent, long l, boolean b) throws Exception &#123; long id = longEvent.getId(); id+=3; System.out.println(&quot;**************************&quot;); System.out.println(Thread.currentThread().getName()); System.out.println(System.currentTimeMillis()+&quot;+A2Handler:&quot;+id); System.out.println(&quot;**************************&quot;); &#125; /** * 池化执行 * */ @Override public void onEvent(LongEvent longEvent) throws Exception &#123; long id = longEvent.getId(); id+=30; System.out.println(&quot;**************************&quot;); System.out.println(Thread.currentThread().getName()); System.out.println(System.currentTimeMillis()+&quot;+A2Handler:&quot;+id); System.out.println(&quot;**************************&quot;); &#125;&#125; 实例化Disruptor// 事件工厂LongEventFactory factory = new LongEventFactory();// 定义RingBuff大小 注意：数值一定是2的幂次方int bufferSize = 1024;// 创建ThreadFactoryThreadFactory threadFactory = new ThreadFactory() &#123; private int counter = 0; private String prefix = &quot;DisruptorWorker&quot;; @Override public Thread newThread(Runnable r) &#123; return new Thread(r, prefix + &quot;-&quot; + counter++); &#125;&#125;;/* 实例化Disruptor （官方有4个实例化方法） * factory 是事件工厂 * bufferSize 是上面定义的RingBuffer的大小 * ProducerType.MULTI 是生产者模式 有SINGL和MULTI两种 * new BlockingWaitStrategy() 是等待阻塞策略 */Disruptor&lt;LongEvent&gt; disruptor = new Disruptor&lt;LongEvent&gt;( factory, bufferSize, threadFactory, ProducerType.MULTI, new BlockingWaitStrategy()); 创建消费者单个模式disruptor会创建2和线程，一个线程用来执行A1Handler，一个线程用来执行A2Handler.每个线程互不影响。 disruptor.handleEventsWith(new A1Handler(),new A2Handler()); 池化模式disruptor会创建4个线程，其中两个线程组成线程池来执行A1Handler，另外两个线程也组成线程池用来执行A2Handler disruptor.handleEventsWithWorkerPool(new A1Handler(),new A1Handler())disruptor.handleEventsWithWorkerPool(new A2Handler(),new A2Handler()) 获取RingBufferRingBuffer&lt;LongEvent&gt; ringBuffer = disruptor.start(); 生产者发布消息这边直接使用Java8的发布方式来发布消息 // 创建ByteBuffer缓冲区 ByteBuffer bb = ByteBuffer.allocate(8);// 生产者发布5条消息for (long l = 0; l&lt;5; l++) &#123; // 写入消息到Bufer缓冲区 bb.putLong(0, l); // Java8 lambda发布方式 ringBuffer.publishEvent((event,sequece,buffer) -&gt; event.setId(buffer.getLong(0)),bb);&#125;System.out.println(&quot;发布完成&quot;); 完整的Main方法public class DisruptorMain &#123; public static void main(String[] args) &#123; // 实例化事件工厂 LongEventFactory factory = new LongEventFactory(); // 定义RingBuffer大小 int bufferSize = 1024; // 创建线程工厂 ThreadFactory threadFactory = new ThreadFactory() &#123; private int counter = 0; private String prefix = &quot;DisruptorWorker&quot;; @Override public Thread newThread(Runnable r) &#123; return new Thread(r, prefix + &quot;-&quot; + counter++); &#125; &#125;; // 实例化Disruptor Disruptor&lt;LongEvent&gt; disruptor = new Disruptor&lt;LongEvent&gt;( factory, bufferSize, threadFactory, ProducerType.MULTI, new BlockingWaitStrategy()); // 并行模式 两个Handler互不影响 disruptor.handleEventsWith(new A1Handler(),new A2Handler()); // 并行 每个消费端有两个线程实例 (池化模式)// disruptor.handleEventsWithWorkerPool(new A1Handler(),new A1Handler());// disruptor.handleEventsWithWorkerPool(new A2Handler(),new A2Handler()); // 获取RingBuffer RingBuffer&lt;LongEvent&gt; ringBuffer = disruptor.start(); // 创建ByteBuffer缓冲区 ByteBuffer bb = ByteBuffer.allocate(8); for (long l = 0; l&lt;5; l++) &#123; // 写入数据到缓冲区 bb.putLong(0, l); // Java8的发布方式 ringBuffer.publishEvent((event,sequece,buffer) -&gt; event.setId(buffer.getLong(0)),bb); &#125; System.out.println(&quot;发布完成&quot;); &#125;&#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/tags/Java/"},{"name":"Disruptor","slug":"Disruptor","permalink":"https://greycode.top/tags/Disruptor/"}]},{"title":"Disruptor-生产者发布方式","slug":"java/disruptor/926f33f0-651d-471a-ad0c-b632fcce8c0f","date":"2021-03-01T09:57:58.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"java/disruptor/926f33f0-651d-471a-ad0c-b632fcce8c0f/","link":"","permalink":"https://greycode.top/java/disruptor/926f33f0-651d-471a-ad0c-b632fcce8c0f/","excerpt":"","text":"旧版本API发布方式import com.lmax.disruptor.RingBuffer;public class LongEventProducer&#123; private final RingBuffer&lt;LongEvent&gt; ringBuffer; public LongEventProducer(RingBuffer&lt;LongEvent&gt; ringBuffer)&#123; this.ringBuffer = ringBuffer; &#125; public void onData(ByteBuffer bb)&#123; long sequence = ringBuffer.next(); // Grab the next sequence try&#123; LongEvent event = ringBuffer.get(sequence); // Get the entry in the Disruptor // for the sequence event.set(bb.getLong(0)); // Fill with data &#125; finally&#123; ringBuffer.publish(sequence); &#125; &#125;&#125; 使用RingBuffer&lt;LongEvent&gt; ringBuffer = disruptor.start();LongEventProducer producer = new LongEventProducer(ringBuffer);ByteBuffer bb = ByteBuffer.allocate(8);for (long l = 0; l&lt;5; l++) &#123; bb.putLong(0, l); producer.onData(bb)&#125;System.out.println(&quot;发布完成&quot;); 使用Translators发布import com.lmax.disruptor.RingBuffer;import com.lmax.disruptor.EventTranslatorOneArg;public class LongEventProducerWithTranslator&#123; private final RingBuffer&lt;LongEvent&gt; ringBuffer; public LongEventProducerWithTranslator(RingBuffer&lt;LongEvent&gt; ringBuffer)&#123; this.ringBuffer = ringBuffer; &#125; private static final EventTranslatorOneArg&lt;LongEvent, ByteBuffer&gt; TRANSLATOR = new EventTranslatorOneArg&lt;LongEvent, ByteBuffer&gt;()&#123; public void translateTo(LongEvent event, long sequence, ByteBuffer bb)&#123; event.set(bb.getLong(0)); &#125; &#125;; public void onData(ByteBuffer bb)&#123; ringBuffer.publishEvent(TRANSLATOR, bb); &#125;&#125; 使用RingBuffer&lt;LongEvent&gt; ringBuffer = disruptor.start();- LongEventProducer producer = new LongEventProducer(ringBuffer);+ LongEventProducerWithTranslator producer = new LongEventProducerWithTranslator(ringBuffer);ByteBuffer bb = ByteBuffer.allocate(8);for (long l = 0; l&lt;5; l++) &#123; bb.putLong(0, l); producer.onData(bb)&#125;System.out.println(&quot;发布完成&quot;); 使用Java8的Lambda表达式发布RingBuffer&lt;LongEvent&gt; ringBuffer = disruptor.start();- LongEventProducerWithTranslator producer = new LongEventProducerWithTranslator(ringBuffer);ByteBuffer bb = ByteBuffer.allocate(8);for (long l = 0; true; l++)&#123; bb.putLong(0, l);- producer.onData(bb);+ ringBuffer.publishEvent((event, sequence, buffer) -&gt;event.set(buffer.getLong(0)),bb);&#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/tags/Java/"},{"name":"Disruptor","slug":"Disruptor","permalink":"https://greycode.top/tags/Disruptor/"}]},{"title":"Dubbo的Telnet调试三部曲","slug":"dubbo/dcf9d2d8-9c11-404a-874d-57834303dcac","date":"2021-02-05T14:04:54.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"dubbo/dcf9d2d8-9c11-404a-874d-57834303dcac/","link":"","permalink":"https://greycode.top/dubbo/dcf9d2d8-9c11-404a-874d-57834303dcac/","excerpt":"","text":"第一步找到Dubbo服务的IP地址，比如我的Dubbo服务地址是192.168.1.11 第二步使用命令连接Dubbo服务 telnet 192.168.1.11 20880 第三步直接调试方法 # 调试TestService类下的get方法invoke com.example.test.service.TestService.get(1132359) 资料https://dubbo.apache.org/zh/docs/v2.7/user/references/telnet/","categories":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://greycode.top/categories/Dubbo/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://greycode.top/tags/Dubbo/"}]},{"title":"Hexo使用UUID生成文章路径","slug":"linux/79b5fe12-9c60-4b93-be92-dffb00fa39c7","date":"2021-01-27T17:51:05.000Z","updated":"2022-04-16T02:52:58.653Z","comments":true,"path":"linux/79b5fe12-9c60-4b93-be92-dffb00fa39c7/","link":"","permalink":"https://greycode.top/linux/79b5fe12-9c60-4b93-be92-dffb00fa39c7/","excerpt":"教程 编写一个名为hexoN的脚本文件 #!/bin/bashuuid=$(sudo cat /proc/sys/kernel/random/uuid)echo $uuidhexo new $uuid 添加执行权限 chmod +x hexoN 在用户根目录的.zshrc(因为我用的是ohmyzsh，所以是这个文件，一般是.bashrc，也可直接加载系统文件/etc/profile中)追加一条 # 后面地址是存放这个脚本的文件夹路径 根据实际更改export PATH=$PATH:/home/zheng/software/shell 执行命令是刚才追加的内容生效 source .zshrc","text":"教程 编写一个名为hexoN的脚本文件 #!/bin/bashuuid=$(sudo cat /proc/sys/kernel/random/uuid)echo $uuidhexo new $uuid 添加执行权限 chmod +x hexoN 在用户根目录的.zshrc(因为我用的是ohmyzsh，所以是这个文件，一般是.bashrc，也可直接加载系统文件/etc/profile中)追加一条 # 后面地址是存放这个脚本的文件夹路径 根据实际更改export PATH=$PATH:/home/zheng/software/shell 执行命令是刚才追加的内容生效 source .zshrc 使用到Hexo博客的根目录执行","categories":[{"name":"Linux","slug":"Linux","permalink":"https://greycode.top/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://greycode.top/tags/Linux/"},{"name":"Shell","slug":"Shell","permalink":"https://greycode.top/tags/Shell/"}]},{"title":"使用GitHub Actions编译树莓派内核","slug":"linux/github-actions-build-pi-kernerl","date":"2021-01-26T15:56:07.000Z","updated":"2022-04-16T02:52:58.653Z","comments":true,"path":"linux/github-actions-build-pi-kernerl/","link":"","permalink":"https://greycode.top/linux/github-actions-build-pi-kernerl/","excerpt":"仓库地址仓库地址：https://github.com/GreyCode9/make-raspberrypi-kernel 创建秘钥 点击Github右上角头像 -&gt; Settings -&gt; Developer settings -&gt; Personal access tokens -&gt; Generate new token","text":"仓库地址仓库地址：https://github.com/GreyCode9/make-raspberrypi-kernel 创建秘钥 点击Github右上角头像 -&gt; Settings -&gt; Developer settings -&gt; Personal access tokens -&gt; Generate new token 或者直接点这个链接进入： https://github.com/settings/tokens 创建后保存这个秘钥(秘钥只显示一次) 创建仓库创建仓库**make-raspberrypi-kernel** 然后点击仓库的Settings -&gt; Secrets -&gt;New repository secret 然后填入刚才生成的秘钥 创建Actions接着点击Actions ,创建一个Actions，然后填入如下内容 name: Make RaspberryPi Kernelon: push: tags: - &#x27;v*&#x27; # 当推送的Tag为v开头的，就会触发构建env: USE_SSH_CONFIG: true # 是否使用ssh连接进行 true:使用 false:不使用jobs: build: runs-on: ubuntu-18.04 steps: - uses: actions/checkout@v2 - name: pull RaspberryPi Kernel linux run: | cd ../ git clone https://github.com/raspberrypi/linux.git - name: pull RaspberryPi Kernel Tool run: | cd ../ git clone https://github.com/raspberrypi/tools.git - name: Move .config if: env.USE_SSH_CONFIG == &#x27;false&#x27; run: | cp .config ../linux - name: Setup Debug Session # 用SSH连接Actions if: env.USE_SSH_CONFIG == &#x27;true&#x27; uses: csexton/debugger-action@master - name: Make run: | cd ../ export WORKPATH=$(pwd) export PATH=$PATH:$WORKPATH/tools/arm-bcm2708/gcc-linaro-arm-linux-gnueabihf-raspbian-x64/bin export PATH=$PATH:$WORKPATH/tools/arm-bcm2708/arm-bcm2708-linux-gnueabi/bin cd linux/ make ARCH=arm CROSS_COMPILE=arm-linux-gnueabihf- zImage modules dtbs -j8 - name: Create Release id: create_release uses: actions/create-release@master env: GITHUB_TOKEN: $&#123;&#123; secrets.TOKEN &#125;&#125; # 之前GitHub添加的Token with: tag_name: $&#123;&#123; github.ref &#125;&#125; # (tag)标签名称 release_name: Release $&#123;&#123; github.ref &#125;&#125; draft: false # 是否是草稿 prerelease: false # 是否是预发布 # 上传构建结果到 Release（把打包的tgz上传到Release） - name: build TAR PACKAGE run: | tar -czvf raspberrypi-kernel.tar.gz ../linux/arch/arm/boot - name: Upload Release Asset id: upload-release-asset uses: actions/upload-release-asset@master env: GITHUB_TOKEN: $&#123;&#123; secrets.TOKEN &#125;&#125; with: upload_url: $&#123;&#123; steps.create_release.outputs.upload_url &#125;&#125; # 上传地址，通过创建Release获取到的 asset_path: ./raspberrypi-kernel.tar.gz # 要上传文件 asset_name: raspberrypi-kernel.tar.gz # 上传后的文件名 asset_content_type: application/gzip 可以在本地配置好.config文件然后上传到仓库，然后把Actions的配置文件中的USE_SSH_CONFIG字段改成false。 也可以直接在Actions中进行配置.config文件，需要把USE_SSH_CONFIG字段改成true。 触发构建当上面完成后，就可以把代码pull到本地，然后根据自己的需求配置.config文件。执行命令 git tag -a v1.0 -m &#x27;build kernel&#x27;git push origin v1.0 推送完成后，就可以看到Actions正在构建了 构建完成后，就可以在Release下载构建好的内核文件了 资料索引 https://www.cnblogs.com/YAN-HUA/p/13530906.html http://doc.openluat.com/article/166/0 https://www.daimajiaoliu.com/daima/4793af6f2900402","categories":[{"name":"Linux","slug":"Linux","permalink":"https://greycode.top/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://greycode.top/tags/Linux/"},{"name":"Github Actions","slug":"Github-Actions","permalink":"https://greycode.top/tags/Github-Actions/"}]},{"title":"Git常用命令","slug":"recommend/git-commend-note","date":"2020-09-16T15:16:56.000Z","updated":"2022-04-16T02:52:58.653Z","comments":true,"path":"recommend/git-commend-note/","link":"","permalink":"https://greycode.top/recommend/git-commend-note/","excerpt":"","text":"Git简介Git 是用于 Linux内核开发的版本控制工具。与常用的版本控制工具 CVS, Subversion 等不同，它采用了分布式版本库的方式，不必服务器端软件支持（wingeddevil注：这得分是用什么样的服务端，使用http协议或者git协议等不太一样。并且在push和pull的时候和服务器端还是有交互的。），使源代码的发布和交流极其方便。 Git 的速度很快，这对于诸如 Linux kernel 这样的大项目来说自然很重要。 Git 最为出色的是它的合并跟踪（merge tracing）能力。 git对于很多人来说,真的是又爱又恨,用的好可以提示开发效率;用不好,解决各种冲突就要累的你半死 git结构 网上有 我就不画了 workspace 相当于就是我们的本地电脑上的文件 Index 缓存区 Repository 本地仓库 Remote 远程仓库(github&#x2F;gitlab&#x2F;gitee) git命令git官方提供的命令多达几百个,可是我们日常却用不到这么多 所以我就整理了一下日常使用的命令 现在关注微信公招:灰色Code 回复关键字:git 就可以获取思维导图高清图片及导图源地址","categories":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/categories/Java/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://greycode.top/tags/Git/"}]},{"title":"Fegin和RestTemplate添加全局请求头","slug":"spring/fegin-resttemplate-addheard","date":"2020-09-16T15:14:43.000Z","updated":"2022-04-16T02:52:58.653Z","comments":true,"path":"spring/fegin-resttemplate-addheard/","link":"","permalink":"https://greycode.top/spring/fegin-resttemplate-addheard/","excerpt":"","text":"Fegin添加全局请求头 实现RequestInterceptor接口 /*** 实现RequestInterceptor接口的apply方法*/@Configurationpublic class FeignRequestInterceptor implements RequestInterceptor &#123; @Override public void apply(RequestTemplate requestTemplate) &#123; ServletRequestAttributes attributes = (ServletRequestAttributes) RequestContextHolder .getRequestAttributes(); HttpServletRequest request = attributes.getRequest(); Enumeration&lt;String&gt; headerNames = request.getHeaderNames(); if (headerNames != null) &#123; while (headerNames.hasMoreElements()) &#123; String name = headerNames.nextElement(); String values = request.getHeader(name); requestTemplate.header(name, values); &#125; &#125; &#125;&#125; 在@FeginClient注释里configuration所填入的类文件中添加上面的拦截器 比如 // configuration指定的类为FeignConfig@FeignClient(name = &quot;$&#123;TinyConfigServiceName&#125;&quot;,path=&quot;/config&quot;,configuration = FeignConfig.class) 在FeignConfig类中添加拦截器 @Configurationpublic class FeignConfig &#123; @Bean public RequestInterceptor requestInterceptor()&#123; return new FeignRequestInterceptor(); &#125;&#125; RestTemplate添加全局请求头 编写拦截器,实现ClientHttpRequestInterceptor接口的intercept方法 public class MyInterceptor implements ClientHttpRequestInterceptor &#123; @Override public ClientHttpResponse intercept(HttpRequest httpRequest, byte[] bytes, ClientHttpRequestExecution clientHttpRequestExecution) throws IOException &#123; HttpHeaders httpHeaders=httpRequest.getHeaders(); ServletRequestAttributes attributes = (ServletRequestAttributes) RequestContextHolder .getRequestAttributes(); HttpServletRequest request = attributes.getRequest(); Enumeration&lt;String&gt; headerNames = request.getHeaderNames(); if (headerNames != null) &#123; while (headerNames.hasMoreElements()) &#123; String name = headerNames.nextElement(); String values = request.getHeader(name); httpHeaders.add(name, values); &#125; &#125; return clientHttpRequestExecution.execute(httpRequest,bytes); &#125;&#125; 在springboot的启动类里添加RestTemplate @SpringBootApplicationpublic class DemoApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(DemoApplication.class, args); &#125; //ioc添加RestTemplate @Bean public RestTemplate restTemplate()&#123; MyInterceptor myInterceptor=new MyInterceptor(); RestTemplate restTemplate=new RestTemplate(); restTemplate.setInterceptors(Collections.singletonList(myInterceptor)); return restTemplate; &#125;&#125;","categories":[{"name":"Spring","slug":"Spring","permalink":"https://greycode.top/categories/Spring/"}],"tags":[{"name":"Fegin","slug":"Fegin","permalink":"https://greycode.top/tags/Fegin/"},{"name":"Resttemplate","slug":"Resttemplate","permalink":"https://greycode.top/tags/Resttemplate/"}]},{"title":"浅谈MDC","slug":"java/mdc-test","date":"2020-09-16T15:10:47.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"java/mdc-test/","link":"","permalink":"https://greycode.top/java/mdc-test/","excerpt":"","text":"MDC是什么？MDC 全拼 Mapped Diagnostic Contexts，是SLF4J类日志系统中实现分布式多线程日志数据传递的重要工具；可利用MDC将一些运行时的上下文数据打印出来。目前只有log4j和logback提供原生的MDC支持； 简单使用MDC里面提供的都是静态方法，所以可以直接调用 // 设置一个keyMDC.put(&quot;name&quot;,&quot;灰色Code&quot;);// 获取一个key的值MDC.get(&quot;name&quot;); // 删除一个keyMDC.remove(&quot;name&quot;); // 清空MDC里的内容MDC.clear();// 获取上下文中的mapMap&lt;String,String&gt; map = MDC.getCopyOfContextMap();// 设置MDC的mapMDC.setContextMap(map); 源码解析MDC通过阅读MDC的源码可以发现，它其实是调用了MDCAdapter的接口来实现的 MDCAdapterMDCAdapter接口有三个实现类，而MDC是调用了LogbackMDCAdapter里的方法(在MDC里有一个静态代码块，实例化了这个对象) LogbackMDCAdapter而LogbackMDCAdapter主要是用ThreadLocal在线程上下文中维护一个HashMap来实现的 总结怎么样,实现原理是不是很简单，就这么短短几行代码，就实现了听起来很高大上的MDC。 所以简单来说，MDC就是利用ThreadLocal在线程中维护了一个HashMap，利用HashMap来存放数据","categories":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/categories/Java/"}],"tags":[{"name":"Logback","slug":"Logback","permalink":"https://greycode.top/tags/Logback/"},{"name":"MDC","slug":"MDC","permalink":"https://greycode.top/tags/MDC/"}]},{"title":"JDKproxy和Cglib初探","slug":"java/jdkproxy-cglib","date":"2020-09-16T15:09:47.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"java/jdkproxy-cglib/","link":"","permalink":"https://greycode.top/java/jdkproxy-cglib/","excerpt":"","text":"JDKproxy和Cglib初探简介在Java中，动态代理机制的出现，使得Java开发人员不用手工编写代理类，只要简单地制定一组接口及委托类对象，便能动态地获得代理类。动态代理在Java中有着广泛的应用，比如Spring AOP，Hibernate数据查询、测试框架的后端mock、RPC，Java注解对象获取等。 JDK原生动态代理(JDKProxy)JDKProxy只能对实现了接口的类生成代理，而不能针对普通类 。JDKProxy原生的反射API进行操作，在生成类上比较高效。 使用 interface TestInterface&#123; void test();&#125;class TestClass implements TestInterface&#123; @Override public void test()&#123; System.out.println(&quot;JDK动态代理&quot;); &#125;&#125;//主方法public class JDKProxy &#123; public static void main(String[] args) &#123; TestClass testClass=new TestClass(); ProxyHandle proxyHandle=new ProxyHandle(testClass); //使用接口 TestInterface testClass1= (TestInterface) Proxy.newProxyInstance( testClass.getClass().getClassLoader(), testClass.getClass().getInterfaces(),proxyHandle); testClass1.test(); System.out.println(&quot;代理类名称：&quot;+testClass1.getClass()); &#125;&#125;//代理class ProxyHandle implements InvocationHandler&#123; private Object originaObj; public ProxyHandle(Object o)&#123; this.originaObj=o; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println(&quot;前置&quot;); Object object=method.invoke(originaObj,args); System.out.println(&quot;后置&quot;); return object; &#125;&#125; 输出结果： 前置 JDK动态代理 后置 代理类名称：class com.example.demo.aop.$Proxy0 CglibCglib代理是针对所有类（包括实现接口的类和普通的类）实现代理，主要是对指定的类生成一个子类，覆盖其中的方法(所以该类或方法不能声明称final的) 。Cglib使用ASM框架直接对字节码进行操作，在类的执行过程中比较高效 使用 interface InterTest&#123; void t1();&#125;class InterClass implements InterTest&#123; @Override public void t1() &#123; System.out.println(&quot;我是接口测试方法&quot;); &#125;&#125;public class CglibTest &#123; public static void main(String[] args) &#123; /** * 普通类 * */ Enhancer enhancer=new Enhancer(); enhancer.setSuperclass(CG.class); enhancer.setCallback(new MethodInterceptor() &#123; @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; System.out.println(&quot;前置&quot;); Object object=methodProxy.invokeSuper(o,objects); System.out.println(&quot;后置&quot;); return object; &#125; &#125;); CG cglibTest= (CG) enhancer.create(); cglibTest.test(); System.out.println(&quot;代理类名称1：&quot;+cglibTest.getClass()); /* * 实现了接口的类 * */ Enhancer enhancer2=new Enhancer(); enhancer2.setSuperclass(InterClass.class); enhancer2.setCallback(new MethodInterceptor() &#123; @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; System.out.println(&quot;接口类前置&quot;); Object object=methodProxy.invokeSuper(o,objects); System.out.println(&quot;接口类后置&quot;); return object; &#125; &#125;); InterClass interClass= (InterClass) enhancer2.create(); interClass.t1(); System.out.println(&quot;代理类名称2：&quot;+interClass.getClass()); &#125;&#125;class CG&#123; public void test()&#123; System.out.println(&quot;代理类测试&quot;); &#125;&#125; 输出结果： 前置 代理类测试 后置 代理类名称1：class com.example.demo.aop.CG$$EnhancerByCGLIB$$5c6cbf31 接口类前置 我是接口测试方法 接口类后置 代理类名称2：class com.example.demo.aop.InterClass$$EnhancerByCGLIB$$80c75859","categories":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/tags/Java/"}]},{"title":"Java包装类缓存机制","slug":"java/java-base-data-pack","date":"2020-09-16T15:08:18.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"java/java-base-data-pack/","link":"","permalink":"https://greycode.top/java/java-base-data-pack/","excerpt":"","text":"面试题首先,来看一道常见的面试题,下面代码运行后会输出什么? 上面代码运行后,最终会输出false和true;为什么会这样呢? 按道理来说,在Java中==是比较两个对象的地址,上面代码中i3和i4是两个不同的对象,理应也应该返回是false,怎么返回是true呢?让我们慢慢往下看 Integer的缓存机制让我们来看看他的源代码. 当执行Integer i=128;这个语句时,Java会调用valueOf(int i)方法,然后自动装箱的方式,让其变成Integer i=new Integer(128),具体源码如下: public static Integer valueOf(int i) &#123; if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; //装箱 return new Integer(i);&#125; 从上面的源码中可以看到,在装箱之前会执行一个if语句,这个if语句就是判断传入的值是否在缓存内,如果在缓存内,就直接返回缓存内的值,如果不在缓存内,就装箱,在堆内创建一个新空间来存放. //Integer包装类缓存源码private static class IntegerCache &#123; static final int low = -128; static final int high; static final Integer cache[]; static &#123; // high value may be configured by property int h = 127; String integerCacheHighPropValue = sun.misc.VM.getSavedProperty(&quot;java.lang.Integer.IntegerCache.high&quot;); if (integerCacheHighPropValue != null) &#123; try &#123; int i = parseInt(integerCacheHighPropValue); i = Math.max(i, 127); // Maximum array size is Integer.MAX_VALUE h = Math.min(i, Integer.MAX_VALUE - (-low) -1); &#125; catch( NumberFormatException nfe) &#123; // If the property cannot be parsed into an int, ignore it. &#125; &#125; high = h; cache = new Integer[(high - low) + 1]; int j = low; for(int k = 0; k &lt; cache.length; k++) cache[k] = new Integer(j++); // range [-128, 127] must be interned (JLS7 5.1.7) assert IntegerCache.high &gt;= 127; &#125; private IntegerCache() &#123;&#125; &#125; 从源码中可以看到,Integer的缓存范围是-128~127,所以过程大致如下: 按照上面这个方法,只要在数据在缓存池范围内的,都会引用缓存在堆内的地址,所有上面的i3==i4会输出为true;而不在缓存范围内的,就会在堆中开放新的空间来存放对象,所以地址不同,用==比较返回也不同; 其他包装类缓存机制除了Integer之外,其他的包装类也使用了缓存技术; Long 缓存范围-128~127 public static Long valueOf(long l) &#123; final int offset = 128; if (l &gt;= -128 &amp;&amp; l &lt;= 127) &#123; // will cache return LongCache.cache[(int)l + offset]; &#125; return new Long(l);&#125;private static class LongCache &#123; private LongCache()&#123;&#125; static final Long cache[] = new Long[-(-128) + 127 + 1]; static &#123; for(int i = 0; i &lt; cache.length; i++) cache[i] = new Long(i - 128); &#125;&#125; Byte 缓存范围-128127 (byte范围:一个byte占8位,所以取值范围是**-2^72^7-1**) public static Byte valueOf(byte b) &#123; final int offset = 128; return ByteCache.cache[(int)b + offset];&#125;private static class ByteCache &#123; private ByteCache()&#123;&#125; static final Byte cache[] = new Byte[-(-128) + 127 + 1]; static &#123; for(int i = 0; i &lt; cache.length; i++) cache[i] = new Byte((byte)(i - 128)); &#125;&#125; Character 缓存范围0~127 (ascii码范围) public static Character valueOf(char c) &#123; if (c &lt;= 127) &#123; // must cache return CharacterCache.cache[(int)c]; &#125; return new Character(c);&#125;private static class CharacterCache &#123; private CharacterCache()&#123;&#125; static final Character cache[] = new Character[127 + 1]; static &#123; for (int i = 0; i &lt; cache.length; i++) cache[i] = new Character((char)i); &#125;&#125; Short 缓存范围-128~127 public static Short valueOf(short s) &#123; final int offset = 128; int sAsInt = s; if (sAsInt &gt;= -128 &amp;&amp; sAsInt &lt;= 127) &#123; // must cache return ShortCache.cache[sAsInt + offset]; &#125; return new Short(s);&#125;private static class ShortCache &#123; private ShortCache()&#123;&#125; static final Short cache[] = new Short[-(-128) + 127 + 1]; static &#123; for(int i = 0; i &lt; cache.length; i++) cache[i] = new Short((short)(i - 128)); &#125;&#125; Boolean 缓存范围 true false 它只设置了两个静态变量用来充当缓存 public static final Boolean TRUE = new Boolean(true);public static final Boolean FALSE = new Boolean(false);public static Boolean valueOf(boolean b) &#123; return (b ? TRUE : FALSE);&#125; 建议包装类对比数据是否相同的时候,建议采用重写的equals()方法.","categories":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/tags/Java/"}]},{"title":"JVM运行时栈帧","slug":"java/jvm/java-jvm-stack-1","date":"2020-09-16T15:06:15.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"java/jvm/java-jvm-stack-1/","link":"","permalink":"https://greycode.top/java/jvm/java-jvm-stack-1/","excerpt":"","text":"在JVM中，每个线程都包含n个栈帧，每一个栈帧都包括了局部变量表、操作数栈、动态连接、方法返回地址和一些额外的附加信息。 栈帧的生命周期随着方法的创建而创建，随着方法的结束而销毁，无论方法是正常完成还是异常完成（抛出了在方法内未被捕获的异常）都算方法的结束。 在某条线程执行过程中的某个时间点上，只有目前正在执行的那个方法的栈帧是活动的。这个栈帧称为当前栈帧，这个栈帧对应的方法称为当前方法，定义这个方法的类称为当前类。对局部变量表和操作数栈的各种操作，通常都指的是对当前栈帧的局部变量表和操作数栈所进行的操作。 **注意:**栈帧是线程本地私有的数据，不可能在一个栈帧 之中引用另外一个线程的栈帧 局部变量表局部变量表（Local Variables Table）是一组变量值的存储空间，用于存放方法参数和方法内部定义的局部变量。 存储方法局部变量表的容量以变量槽（Variable Slot）为最小单位，一般在虚拟机中，一个Slot占用32位存储空间(这不是固定的，虚拟机可以自行改变每个槽占用空间的大小,但一般都是32位)。 Java虚拟机通过索引定位的方式使用局部变量表，索引值的范围是从0开始至局部变量表最大的变量槽数量。如果访问的是32位数据类型的变量，索引N就代表了使用第N个变量槽，如果访问的是64位数据类型的变量，则说明会同时使用第N和N+1两个变量槽。 eg:在Java中，long在内存占64位，所以局部变量表用2个slot来存储 对于两个相邻的共同存放一个64位数据的两个变量槽，虚拟机不允许采用任何方式单独访问其中的某一个，《Java虚拟机规范》中明确要求了如果遇到进行这种操作的字节码序列，虚拟机就应该在类加载的校验阶段中抛出异常。 long和double的非原子性协定 在Java内存模型中，对于64位的数据类型（long和double），在模型中特别定义了一条宽松的规定：允许虚拟机将没有被volatile修饰的64位数据的读写操作划分为两次32位的操作来进行，即允许虚拟机实现自行选择是否要保证64位数据类型的load、store、read和write这四个操作的原子性，这就是所谓的“long和double的非原子性协定”（Non-Atomic Treatment of doubleand long Variables）。 虽然有这个协定，但是，由于局部变量表(Local Variable Table)是建立在线程堆栈中的，属于线程私有的数据，无论读写两个连续的变量槽是否为原子操作，都不会引起数据竞争和线程安全问题。 初始值问题我们已经知道类的字段变量有两次赋初始值的过程，一次在准备阶段，赋予系统初始值；另外一次在初始化阶段，赋予程序员定义的初始值。 但局部变量就不一样了，如果一个局部变量定义了但没有赋初始值，那它是完全不能使用的。所以不要认为Java中任何情况下都存在诸如整型变量默认为0、布尔型变量默认为false等这样的默认值规则。 eg：// 这个方法会报：// Error:(12, 28) java: variable y might not have been initializedpublic class JVMTest &#123; public static void main(String[] args) &#123; int y; int z=3; System.out.println(y+z); &#125;&#125;// 这个会正常输出 3； 因为int的初始值为0public class JVMTest &#123; private static int y; public static void main(String[] args) &#123; int z=3; System.out.println(y+z); &#125;&#125; 操作数栈操作数栈（Operand Stack）也常被称为操作栈，它是一个后入先出（Last In First Out，LIFO）栈。同局部变量表一样，操作数栈的最大深度也在编译的时候被写入到Code属性的max_stacks数据项之中。操作数栈的每一个元素都可以是包括long和double在内的任意Java数据类型。32位数据类型所占的栈容量为1，64位数据类型所占的栈容量为2。Javac编译器的数据流分析工作保证了在方法执行的任何时候，操作数栈的深度都不会超过在max_stacks数据项中设定的最大值。 eg:public class JVMTest &#123; public static void main(String[] args) &#123; long y=9223372036854775800L; int z=2; long x=y+z; &#125;&#125; 我们用javap -verbose JVMTest来查看他的class文件的字节码指令 在操作栈中的流程大致为： 动态链接每个栈帧都包含一个指向当前方法所在类型的运行时常量池的引用，持有这个引用是为了支持方法调用过程中的动态连接（Dynamic Linking）。在Class文件里，一个方法若要调用其他方法，或者访问成员变量，则需要通过符号引用(symolic reference)来表示，动态链接的作用就是将这些以符号引用所表示的方法转换为实际方法的直接引用。 什么是符号引用？ 通过查看字节码，上面的#7，#8，#9等等都是符号引用，他在class文件里只是个符号，就像你定义一个变量名称一样，变量名只是和字符符号，并不是真正的指向内存的地址指针。这些符号都指向运行时常量池的引用。 方法返回地址Java在调用方法时，只有两种返回方法，一种是正常返回，一种是异常返回。 正常返回正常返回指的就是在执行方法时，中间并没有异常抛出，或者已正确处理抛出的异常，这时就称当前方法正常调用完成，如果有返回值，就会给他调用者返回一个值，如果没有返回值(void)就正常返回。 这种场景下，当前栈帧承担着恢复调用者状态的责任，包括恢复调用者的局部变量表和操作数栈，以及正确递增程序计数器，以跳过刚才执行的调用方法指令等。调用者的代码在被调用方法的返回值压入调用者栈帧的操作数栈后，会正常执行。 异常返回在调用一些方法时，一些异常没有被正确捕获，就会导致方法终止，此时称方法异常调用完成，那一定不会有方法返回值返回给其调用者。 无论采用何种退出方式，在方法退出之后，都必须返回到最初方法被调用时的位置，程序才能继续执行，方法返回时可能需要在栈帧中保存一些信息，用来帮助恢复它的上层主调方法的执行状态。 怎么理解这个必须返回到最初方法被调用时的位置呢？ eg: 上面异常是在13行发生的，但是它并没有停在13行，而是回到了最初调用它第10行的位置。","categories":[{"name":"JVM","slug":"JVM","permalink":"https://greycode.top/categories/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://greycode.top/tags/JVM/"}]},{"title":"JVM类加载过程","slug":"java/jvm/java-class-load-2","date":"2020-09-16T15:04:22.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"java/jvm/java-class-load-2/","link":"","permalink":"https://greycode.top/java/jvm/java-class-load-2/","excerpt":"","text":"加载 通过一个类的全限定名(例如：java.lang.String)来获取定义此类的二进制字节流。 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。 在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口。 对于数组类而言，情况就有所不同，数组类本身不通过类加载器创建，它是由Java虚拟机直接在内存中动态构造出来的。 从ZIP压缩包中读取，这很常见，最终成为日后JAR、EAR、WAR格式的基础。 从网络中获取，这种场景最典型的应用就是Web Applet。 运行时计算生成，这种场景使用得最多的就是动态代理技术，在java.lang.reflect.Proxy中，就是用了ProxyGenerator.generateProxyClass()来为特定接口生成形式为“*$Proxy”的代理类的二进制字节流。 由其他文件生成，典型场景是JSP应用，由JSP文件生成对应的Class文件。 从数据库中读取，这种场景相对少见些，例如有些中间件服务器（如SAP Netweaver）可以选择把程序安装到数据库中来完成程序代码在集群间的分发。 可以从加密文件中获取，这是典型的防Class文件被反编译的保护措施，通过加载时解密Class文件来保障程序运行逻辑不被窥探。 验证 文件格式验证 是否以魔数0xCAFEBABE开头。 主、次版本号是否在当前Java虚拟机接受范围之内 常量池的常量中是否有不被支持的常量类型（检查常量tag标志）。 指向常量的各种索引值中是否有指向不存在的常量或不符合类型的常量。 CONSTANT_Utf8_info型的常量中是否有不符合UTF-8编码的数据。 ·Class文件中各个部分及文件本身是否有被删除的或附加的其他信息 …… 元数据验证 这个类是否有父类（除了java.lang.Object之外，所有的类都应当有父类）。 这个类的父类是否继承了不允许被继承的类（被final修饰的类）。 如果这个类不是抽象类，是否实现了其父类或接口之中要求实现的所有方法。 类中的字段、方法是否与父类产生矛盾（例如覆盖了父类的final字段，或者出现不符合规则的方法重载，例如方法参数都一致，但返回值类型却不同等）。 …… 字节码验证 保证任意时刻操作数栈的数据类型与指令代码序列都能配合工作，例如不会出现类似于“在操作栈放置了一个int类型的数据，使用时却按long类型来加载入本地变量表中”这样的情况。 保证任何跳转指令都不会跳转到方法体以外的字节码指令上。 保证方法体中的类型转换总是有效的，例如可以把一个子类对象赋值给父类数据类型，这是安全的，但是把父类对象赋值给子类数据类型，甚至把对象赋值给与它毫无继承关系、完全不相干的一个数据类型，则是危险和不合法的。 …… 符号引用验证 符号引用中通过字符串描述的全限定名是否能找到对应的类 在指定类中是否存在符合方法的字段描述符及简单名称所描述的方法和字段。 符号引用中的类、字段、方法的可访问性（private、protected、public、）是否可被当前类访问。 …… 准备准备阶段是正式为类中定义的变量（即静态变量，被static修饰的变量）分配内存并设置类变量初始值的阶段 例子： // 变量value在准备阶段过后的初始值为0而不是123// 因为这时尚未开始执行任何Java方法 value赋值为123的动作要到类的初始化阶段才会被执行public static int value = 123 解析解析阶段是Java虚拟机将常量池内的符号引用替换为直接引用的过程 符号引用（Symbolic References）：符号引用以一组符号来描述所引用的目标，符号可以是任何形式的字面量，只要使用时能无歧义地定位到目标即可。符号引用与虚拟机实现的内存布局无关，引用的目标并不一定是已经加载到虚拟机内存当中的内容。各种虚拟机实现的内存布局可以各不相同，但是它们能接受的符号引用必须都是一致的，因为符号引用的字面量形式明确定义在《Java虚拟机规范》的Class文件格式中。 下面红框中的都属于符号引用 直接引用（Direct References）：直接引用是可以直接指向目标的指针、相对偏移量或者是一个能间接定位到目标的句柄。直接引用是和虚拟机实现的内存布局直接相关的，同一个符号引用在不同虚拟机实例上翻译出来的直接引用一般不会相同。如果有了直接引用，那引用的目标必定已经在虚拟机的内存中存在。 初始化参考：jvm类初始化","categories":[{"name":"JVM","slug":"JVM","permalink":"https://greycode.top/categories/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://greycode.top/tags/JVM/"}]},{"title":"JVM中的双亲委派机制","slug":"java/jvm/java-class-load-1","date":"2020-09-16T15:02:34.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"java/jvm/java-class-load-1/","link":"","permalink":"https://greycode.top/java/jvm/java-class-load-1/","excerpt":"","text":"四种类加载器 启动类加载器(Bootstrap Class Loader )：加载$JAVA_HOME/jre/lib目录下的jar包 拓展类加载器(Extension Class Loader)：加载$JAVA_HOME/jre/lib/ext目录下的jar包 应用程序类加载器(Application Class Loader)：加载ClassPath目录下的jar包 自定义类加载器(User Class Loader)：加载自定义指定目录下的jar包 双亲委派机制 如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的类加载器都是如此，因此所有的加载请求最终都应该传送到最顶层的启动类加载器中，只有当父加载器反馈自己无法完成这个加载请求（它的搜索范围中没有找到所需的类）时，子加载器才会尝试自己去完成加载。 代码示例 当获取Bootstrap class loader的时候，输出了null，说明开发者无法通过引用操作启动类加载器 双亲委派机制的作用每个加载器都只需要固定的加载自己管理范围内的类，这样的好处就是保证了Java体系的稳定，不然的话你自己定义一个String类的话，这样系统中就会有两个String类，如果没有双亲委派机制的话，系统就不知道到底该加载哪一个，这样系统就变得一片混乱了。 破坏双亲委派机制双亲委派机制是Java设计者推荐给开发者们的类加载实现方式，并不是一个强制性约束的模型，所以也可以人为的破坏这个机制。 源码 源码在java.lang.ClassLoader有兴趣的可以去看下 可以看到，就这短短的几行代码，就实现了听起来很高大上的双亲委派机制，所以破坏双亲委派机制的话，就直接重写loadClass方法就可以了。","categories":[{"name":"JVM","slug":"JVM","permalink":"https://greycode.top/categories/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://greycode.top/tags/JVM/"}]},{"title":"Java类初始化","slug":"java/jvm/java-class-init","date":"2020-09-16T15:01:03.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"java/jvm/java-class-init/","link":"","permalink":"https://greycode.top/java/jvm/java-class-init/","excerpt":"","text":"代码结果？首先，我们来看看下面的代码的输出的结果，可以先试着想一下 //结果Code公众号 这时候有同学就会想，以前不是说类加载时，静态代码块都会加载的嘛！怎么Test1里的静态代码块没有加载呢？下面就来看看到底怎么回事 类的生命周期了解类加载前，首先熟悉一下类的生命周期 这里注意几个点： 解析阶段可以在初始化阶段之后，这是为了支持Java语言的运行时绑定特性（也称为动态绑定或晚期绑定） 这些阶段通常都是互相交叉地混合进行的，会在一个阶段执行的过程中调用、激活另一个阶段。 初始化和实例化我相信很多人跟我刚开始一样，搞不清他们两个的区别，搞不清new一个对象，到底是对这个对象进行了初始化还是实例化呢？ 初始化：是完成程序执行前的准备工作。在这个阶段，静态的（变量，方法，代码块）会被执行。同时在会开辟一块存储空间用来存放静态的数据。初始化只在类加载的时候执行一次。 实例化：是指创建一个对象的过程。这个过程中会在堆中开辟内存，将一些非静态的方法，变量存放在里面。在程序执行的过程中，可以创建多个对象，既多次实例化。每次实例化都会开辟一块新的内存。 类的初始化《Java虚拟机规范》中并没有对加载进行强制约束，这点可以交给虚拟机的具体实现来自由把握。但是对于初始化阶段，《Java虚拟机规范》则是严格规定了有且只有六种情况必须立即对类进行“初始化”（而加载、验证、准备自然需要在此之前开始）： 遇到new、getstatic、putstatic或invokestatic这四条字节码指令时，如果类型没有进行过初始化，则需要先触发其初始化阶段。那到底什么时候能够生成这些指令呢？其实看下字节码就都明白了 使用java.lang.reflect包的方法对类型进行反射调用的时候，如果类型没有进行过初始化，则需要先触发其初始化。 当初始化类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化。 当虚拟机启动时，用户需要指定一个要执行的主类（包含main()方法的那个类），虚拟机会先初始化这个主类。 当使用JDK 7新加入的动态语言支持时，如果一个java.lang.invoke.MethodHandle实例最后的解析结果为REF_getStatic、REF_putStatic、REF_invokeStatic、REF_newInvokeSpecial四种类型的方法句柄，并且这个方法句柄对应的类没有进行过初始化，则需要先触发其初始化。 当一个接口中定义了JDK 8新加入的默认方法（被default关键字修饰的接口方法）时，如果有这个接口的实现类发生了初始化，那该接口要在其之前被初始化。 java.lang.invoke.MethodHandle 是JDK7中新加入类似反射功能的一个类 被动引用对于以上这六种会触发类型进行初始化的场景，《Java虚拟机规范》中使用了一个非常强烈的限定语——“有且只有”，这六种场景中的行为称为对一个类型进行主动引用。除此之外，所有引用类型的方式都不会触发初始化，称为被动引用。 像文章一开始的代码，就属于被动引用，对于静态字段，只有直接定义这个字段的类才会被初始化，因此通过其子类来引用父类中定义的静态字段，只会触发父类的初始化而不会触发子类的初始化。 例子1–对象数组直接上图 以上代码执行后并不会输出灰色两个字，因为创建对象数组时并没有去初始化Test1这个类，而是用anewarray字节码指令去初始化了另外一个类，它是一个由虚拟机自动生成的、直接继承于java.lang.Object的子类。 拓展：数组越界检查没有封装在数组元素的访问类中，而是封装在数组访问的xaload,xastore字节码指令中 例子2–final修饰的静态字段 被final修饰的静态字段 此时运行该代码时，只会输出灰色Code字样，Test1并没有触发初始化阶段。这是因为在编译阶段通过常量传播优化，已经将此常量的值灰色Code直接存储在ClassLoadTest类的常量池中，所以当ClassLoadTest类调用Test1里的value时，都变成了对自身常量池的调用，和Test1类没有任何关系。 没有final修饰的静态字段 没有使用final修饰的静态变量，字节码出现了getstatic，所以触发Test1的初始化阶段，此时运行结果将会输出灰色和灰色Code","categories":[{"name":"JVM","slug":"JVM","permalink":"https://greycode.top/categories/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://greycode.top/tags/JVM/"}]},{"title":"创建线程的3种方式","slug":"java/thread/create-thread-3","date":"2020-06-22T16:29:38.000Z","updated":"2022-04-16T02:52:58.653Z","comments":true,"path":"java/thread/create-thread-3/","link":"","permalink":"https://greycode.top/java/thread/create-thread-3/","excerpt":"","text":"Java线程状态变迁图 构造一个线程在线程执行start()方法之前,首先需要初始化(NEW)一个线程,初始化的时候,可以设置线程名称,线程所属的线程组、线程优先级、是否是Daemon线程等信息。 Thread常见参数及设置方法: //线程是否是守护线程 默认false private boolean daemon = false; //设置方法 Thread thread=new Thread(); thread.setDaemon(true); &lt;figure class=\"highlight plaintext\">&lt;table>&lt;tr>&lt;td class=\"code\">&lt;pre>&lt;span class=\"line\">&lt;/span>&lt;br>&lt;span class=\"line\">- ```java&lt;/span>&lt;br>&lt;span class=\"line\"> //线程名字 默认\"Thread-\" + nextThreadNum()&lt;/span>&lt;br>&lt;span class=\"line\"> private volatile String name;&lt;/span>&lt;br>&lt;span class=\"line\"> //设置方法&lt;/span>&lt;br>&lt;span class=\"line\"> Thread thread=new Thread();&lt;/span>&lt;br>&lt;span class=\"line\"> thread.setName(\"myThread\"); //不能设置为null,会报异常&lt;/span>&lt;br>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>&lt;/figure> &#96;&#96;&#96;java&#x2F;&#x2F;线程优先级 是否起作用和操作系统及虚拟机版本相关private int priority; &#x2F;&#x2F;设置方法 范围:1-10 默认5myThread.setPriority(1); ### Thread源码构造方法在Thread源码中,一共提供了`9种`构造方法.![图片](https://cdn.jsdelivr.net/gh/greycodee/images@main/images/2021/10/08/20200602151437.png)从这些构造方法中,大致可以分为`有Runnable构造参数`的,和`无Runnable构造参数`两大类,无Runnable构造参数的就需要去继承`Thread`来重写`run()`方法&lt;font color=grey&gt;(注:`Thread`也实现了Runnable接口)&lt;/font&gt;,有Runnable构造参数的,就实现Runnable接口的run方法,然后通过构造参数,把实现Runnable接口的实例传入Thread.### 无返回值的线程可以看到,通过集成`Thread`类和实现`Runnable`接口的`run()`方法返回值都是`void`.这类是没有返回值的#### 方法一:继承Thread类创建一个线程```java//继承Thread类,重写run方法class MyThread extends Thread&#123; @Override public void run() &#123; System.out.println(&quot;继承Thread,重写run方法&quot;); &#125;&#125;public class ThreadTest&#123; public static void main(String[] args)&#123; MyThread myThread=new MyThread(); myThread.start(); &#125;&#125; 方法二:实现Runnable接口创建线程//实现Runnable接口的run方法,然后以构造参数的形式设置Thread的targetclass MyRun implements Runnable&#123; @Override public void run() &#123; System.out.println(&quot;实现Runnable方法&quot;); &#125;&#125;public class ThreadTest&#123; public static void main(String[] args)&#123; MyRun myRun=new MyRun(); Thread thread=new Thread(myRun); thread.start(); &#125;&#125; 有返回值的线程上面两个方法,都有一个共同缺点,就是没有返回值,当有一些特殊需求时,比如开启一个线程,用来计算一些东西,或者是处理另外一些需要返回数据的业务,这时就需要借助FutureTask来完成了 方法三:通过FutureTask创建一个线程//实现Callable接口的call方法 类似实现Runnable的run方法class MyCall implements Callable&lt;Integer&gt;&#123; @Override public Integer call() throws Exception &#123; //计算1+1 return 1+1; &#125;&#125;public class ThreadTest&#123; public static void main(String[] args)&#123; MyCall myCall=new MyCall(); //创建异步任务 FutureTask&lt;Integer&gt; futureTask=new FutureTask&lt;&gt;(myCall); Thread thread2=new Thread(futureTask); thread2.start(); //获取线程执行结果 Integer res=futureTask.get(); System.out.println(res); //输出2 &#125;&#125; 总结使用继承方式的好处是方便传参，你可以在子类里面添加成员变量，通过set方法设置参数或者通过构造函数进行传递，而如果使用Runnable方式，则只能使用主线程里面被声明为final的变量。不好的地方是Java不支持多继承，如果继承了Thread类，那么子类不能再继承其他类，而Runable则没有这个限制。前两种方式都没办法拿到任务的返回结果，但是Futuretask方式可以。","categories":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/categories/Java/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"https://greycode.top/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"吐血整理Git常用命令","slug":"tool/git-tool-command","date":"2020-06-22T16:27:25.000Z","updated":"2022-04-16T02:52:58.653Z","comments":true,"path":"tool/git-tool-command/","link":"","permalink":"https://greycode.top/tool/git-tool-command/","excerpt":"","text":"Git常用命令Git简介Git 是用于 Linux内核开发的版本控制工具。与常用的版本控制工具 CVS, Subversion 等不同，它采用了分布式版本库的方式，不必服务器端软件支持（wingeddevil注：这得分是用什么样的服务端，使用http协议或者git协议等不太一样。并且在push和pull的时候和服务器端还是有交互的。），使源代码的发布和交流极其方便。 Git 的速度很快，这对于诸如 Linux kernel 这样的大项目来说自然很重要。 Git 最为出色的是它的合并跟踪（merge tracing）能力。 git对于很多人来说,真的是又爱又恨,用的好可以提示开发效率;用不好,解决各种冲突就要累的你半死 git结构 网上有 我就不画了 workspace 相当于就是我们的本地电脑上的文件 Index 缓存区 Repository 本地仓库 Remote 远程仓库(github&#x2F;gitlab&#x2F;gitee) git命令git官方提供的命令多达几百个,可是我们日常却用不到这么多 所以我就整理了一下日常使用的命令 现在关注微信公招:灰色Code 回复关键字:git 就可以获取思维导图高清图片及导图源地址","categories":[{"name":"Tool","slug":"Tool","permalink":"https://greycode.top/categories/Tool/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://greycode.top/tags/Git/"}]},{"title":"创建一个自定义注解","slug":"spring/apring-aop-ann","date":"2020-06-22T16:23:56.000Z","updated":"2022-04-16T02:52:58.653Z","comments":true,"path":"spring/apring-aop-ann/","link":"","permalink":"https://greycode.top/spring/apring-aop-ann/","excerpt":"","text":"前言平时在用springBoot的使用，常常会用到@Service，@Compent等等注解，简化了我们的开发流程，提升了开发效率.那如何自己来写一个注解呢？下面就来介绍一下。 写一个注解创建一个注解主要分两部分，一部分是创建注解类，一部分是创建一个切面类。 创建注解类@Target(&#123;ElementType.METHOD&#125;)@Retention(RetentionPolicy.RUNTIME)public @interface MyAnn &#123; String value() default &quot;d&quot;;&#125; 创建注解类的关键字就是@interface，这个注解类设置了一个value变量，默认值为d； 在注解类上面还有@Target和@Retention注解，下面来说说创建注解类时需要用到的几个注解： @Target用来标记这个注解可以用于哪些地方，与ElementType枚举类搭配使用，那这个枚举类里面有什么内容呢？ public enum ElementType &#123; /** 类，接口（包括注释类型）或枚举声明*/ TYPE, /** 字段声明（包括枚举常量）*/ FIELD, /** 方法声明*/ METHOD, /** 形式参数（形参-调用方法时传入的参数）声明 */ PARAMETER, /** 构造函数声明 */ CONSTRUCTOR, /** 局部变量声明 */ LOCAL_VARIABLE, /** 注释类型声明 */ ANNOTATION_TYPE, /** 包声明 */ PACKAGE, /** * 类型参数声明 * java8新特性： * @since 1.8 */ TYPE_PARAMETER, /** * 任何类型声明 * java8新特性： * @since 1.8 */ TYPE_USE&#125; @Retention该注解表示自定义注解的生命周期 public enum RetentionPolicy &#123; /** * 注释将被编译器丢弃。 */ SOURCE, /** * 注释由编译器记录在类文件中 * 但不必在运行时由VM保留。 这是默认值 */ CLASS, /** *注释由编译器记录在类文件中，并且 *在运行时由VM保留，因此可以以反射方式读取它们。 */ RUNTIME&#125; 写一个切面类因为用到了切面，所以我们要先导入Spring AOP这个依赖包。 &lt;!--SpringBoot项目导入AOP--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt;&lt;/dependency&gt; 创建切面类@Aspect@Componentpublic class MyAnnAop &#123; private Logger logger= LoggerFactory.getLogger(MyAnnAop.class); @Pointcut(&quot;@annotation(com.example.demo.annotation.MyAnn)&quot;) public void ann()&#123; &#125; @Before(&quot;ann()&quot;) public void before(JoinPoint joinPoint)&#123; logger.info(&quot;打印：开始前&quot;); &#125; @AfterReturning(value = &quot;ann()&quot;,returning = &quot;res&quot;) public Object dochange(JoinPoint joinPoint,Object res)&#123; logger.info(&quot;AfterReturning通知开始-获取数据:&#123;&#125;&quot;,res); //获取数据 Map&lt;String,String&gt; map= (Map&lt;String, String&gt;) res; //添加新值 map.put(&quot;s1&quot;,&quot;我是在AOP中添加的新值&quot;); return map; &#125;&#125; Spring AOP说明 具体可以查阅Spring AOP相关资料 注解 说明 @Before 前置通知，在连接点方法前调用 @Around 环绕通知，它将覆盖原有方法，但是允许你通过反射调用原有方法 @After 后置通知，在连接点方法后调用 @AfterReturning 返回通知，在连接点方法执行并正常返回后调用，要求连接点方法在执行过程中没有发生异常 @AfterThrowing 异常通知，当连接点方法异常时调用 使用自定义的注解这里使用普通的SpringBoot来使用注解，创建一个Service,在里面使用注解，然后才控制层调用 //服务层@Servicepublic class TestService &#123; @MyAnn public Map test()&#123; Map&lt;String,String&gt; map=new HashMap&lt;&gt;(); map.put(&quot;t1&quot;,&quot;我是在Service设置的值&quot;); return map; &#125;&#125;//控制层@RestControllerpublic class Test2 &#123; private Logger logger= LoggerFactory.getLogger(Test2.class); @Autowired private TestService testService; @GetMapping(&quot;/test&quot;) public String test(String id)&#123; Map&lt;String,String&gt; s=testService.test(); logger.info(&quot;控制层输出：&#123;&#125;&quot;,s.get(&quot;s1&quot;)); return &quot;sccess&quot;; &#125;&#125; 输出com.example.demo.aop.MyAnnAop : AfterReturning通知开始-获取数据:&#123;t1=我是在Service设置的值&#125;com.example.demo.web.Test2 : 控制层输出：我是在AOP中添加的新值 注意事项上面那样使用注解是没问题的，但是如果是下面这样使用，AOP就会失效 @RestControllerpublic class Test2 &#123; private Logger logger= LoggerFactory.getLogger(Test2.class); @Autowired private TestService testService; @GetMapping(&quot;/test&quot;) public String test(String id)&#123; Map&lt;String,String&gt; s=this.test2(); logger.info(&quot;控制层输出：&#123;&#125;&quot;,s.get(&quot;s1&quot;)); return &quot;sccess&quot;; &#125; @MyAnn public Map test2()&#123; Map&lt;String,String&gt; map=new HashMap&lt;&gt;(); map.put(&quot;t1&quot;,&quot;我是在控制层设置的值&quot;); return map; &#125;&#125; 输出com.example.demo.web.Test2 : 控制层输出：null 这是应为内部方法调用，调用的是具体方法，并没有调用使用AOP后生成的代理方法 具体参考资料： https://blog.csdn.net/Daybreak1209/article/details/82982674 https://blog.csdn.net/u013151053/article/details/106124048?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase https://zhewuzhou.github.io/2018/09/01/Spring_AOP_Trap/","categories":[{"name":"Spring","slug":"Spring","permalink":"https://greycode.top/categories/Spring/"}],"tags":[{"name":"Spring AOP","slug":"Spring-AOP","permalink":"https://greycode.top/tags/Spring-AOP/"},{"name":"注解","slug":"注解","permalink":"https://greycode.top/tags/%E6%B3%A8%E8%A7%A3/"}]},{"title":"JVM4种垃圾收集算法","slug":"java/jvm/jvm-gc-alg","date":"2020-05-29T10:31:30.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"java/jvm/jvm-gc-alg/","link":"","permalink":"https://greycode.top/java/jvm/jvm-gc-alg/","excerpt":"","text":"简介垃圾收集算法可以划分为“引用计数式垃圾收集”（Reference Counting GC）和“追踪式垃圾收集”（Tracing GC）两大类，这两类也常被称作“直接垃圾收集”和“间接垃圾收集”。 标记-清除算法 标记过程就是对象是否属于垃圾的判定过程(采用可达分析算法GC Roots) 算法分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后，统一回收掉所有被标记的对象，也可以反过来，标记存活的对象，统一回收所有未被标记的对象。 缺点 执行效率不稳定，如果Java堆中包含大量对象，而且其中大部分是需要被回收的，这时必须进行大量标记和清除的动作，导致标记和清除两个过程的执行效率都随对象数量增长而降低； 第二个是内存空间的碎片化问题，标记、清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致当以后在程序运行过程中需要分配较大对象时无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。 标记-复制算法 标记过程就是对象是否属于垃圾的判定过程(采用可达分析算法GC Roots) 它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。 当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。 缺点 如果内存中多数对象都是存活的，这种算法将会产生大量的内存间复制的开销 代价是将可用内存缩小为了原来的一半,空间浪费未免太多了一点. 标记-整理算法 标记过程就是对象是否属于垃圾的判定过程(采用可达分析算法GC Roots) 在标记-清除的算法基础上改进,后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向内存空间一端移动，然后直接清理掉边界以外的内存， 缺点 在有大量存活对象的老年代区域,移动存活对象并更新所有引用这些对象的地方将会是一种极为负重的操作,而且这种对象移动操作必须全程暂停用户应用程序才能进行,比标记-清除算法停顿时间长. 分代收集算法现代商用虚拟机基于以上算法的优缺点,根据分代收集理论,在不同的区域采用了不同的收集算法. 老年代:新生代&#x3D;2:1 新生代 堆大小默认比例:Eden:S0:S1&#x3D;8:1:1 采用标记-复制算法 新生代分为Eden区和Survior区,而Survior区又分为From Survior区(S0)和To Survior区(S1).此区域采用标记-复制算法.每次Minor GC&#x2F;Young GC时,会把Eden区存活的对象复制到S0区,然后清空Eden区,当S0区满时,Eden区和S0区存活的对象会复制到S1区,然后S0和S0进行交换,永远保持S1为空状态,当新生代的对象经过一定次数的Minor GC还未被回收时,就会把这个对象移到老年代. 老年代 采用标记-整理法或标记-清理法 当老年代Old区域满时,会触发Full GC,同时回收新生代和老生代的所有区域.回收后诺内存还是不足时,会引发OOM异常;","categories":[{"name":"JVM","slug":"JVM","permalink":"https://greycode.top/categories/JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://greycode.top/tags/JVM/"}]},{"title":"Java四种引用方法使用和对比","slug":"java/jvm/jvm-object-four-quote","date":"2020-05-29T10:22:07.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"java/jvm/jvm-object-four-quote/","link":"","permalink":"https://greycode.top/java/jvm/jvm-object-four-quote/","excerpt":"","text":"强引用（Strongly Reference） 无论任何情况下，只要强引用关系还存在，垃圾收集器就永远不会回收掉被引用的对象。 回收时机:强引用关系不存在时 Object obj=new Object(); 软引用（Soft Reference） 软引用是用来描述一些还有用，但非必须的对象。只被软引用关联着的对象，在系统将要发生内存溢出异常前，会把这些对象列进回收范围之中进行第二次回收，如果这次回收还没有足够的内存，才会抛出内存溢出异常。 回收时机:发送内存溢出异常前 //软引用SoftReference&lt;Object&gt; srf = new SoftReference&lt;Object&gt;(new Object());//orObject obj=new Object();SoftReference&lt;Object&gt; srf = new SoftReference&lt;Object&gt;(obj);obj=null; //这种方法一定要设置obj为null,否则这个对象除了软引用可达外,还有原来强引用也可达 弱引用（Weak Reference） 弱引用也是用来描述那些非必须对象，但是它的强度比软引用更弱一些，被弱引用关联的对象只能生存到下一次垃圾收集发生为止。当垃圾收集器开始工作，无论当前内存是否足够，都会回收掉只被弱引用关联的对象。 回收时机:下一次垃圾回收时 //弱引用WeakReference&lt;Object&gt; wrf = new WeakReference&lt;Object&gt;(new Object());//orObject obj=new Object();WeakReference&lt;Object&gt; wrf = new WeakReference&lt;Object&gt;(new Object());obj=null; 虚引用（Phantom Reference） 虚引用也称为“幽灵引用”或者“幻影引用”，它是最弱的一种引用关系。一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。 回收时机:随时 //虚引用PhantomReference&lt;Object&gt; prf = new PhantomReference&lt;Object&gt;(new Object(), new ReferenceQueue&lt;&gt;());//orObject obj=new Object();PhantomReference&lt;Object&gt; prf = new PhantomReference&lt;Object&gt;(obj, new ReferenceQueue&lt;&gt;());obj=null;","categories":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/tags/Java/"},{"name":"Jvm","slug":"Jvm","permalink":"https://greycode.top/tags/Jvm/"}]},{"title":"JVM判断对象是否还活着的两种方法","slug":"java/jvm/jvm-object-is-alive","date":"2020-05-29T10:18:30.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"java/jvm/jvm-object-is-alive/","link":"","permalink":"https://greycode.top/java/jvm/jvm-object-is-alive/","excerpt":"","text":"引用计数法 Java虚拟机并不是通过引用计数算法来判断对象是否存活的。 在对象中添加一个引用计数器，每当有一个地方引用它时，计数器值就加一；当引用失效时，计数器值就减一；任何时刻计数器为零的对象就是不可能再被使用的。 优点 原理简单,判定效率高 缺点 不能用于复杂的环境中,比如对象的互相引用问题 可达性分析算法 Java虚拟机使用此算法来判断对象是否存活 这个算法的基本思路就是通过一系列称为“GC Roots”的根对象作为起始节点集，从这些节点开始，根据引用关系向下搜索，搜索过程所走过的路径称为“引用链”（Reference Chain），如果某个对象到GCRoots间没有任何引用链相连，或者用图论的话来说就是从GC Roots到这个对象不可达时，则证明此对象是不可能再被使用的。 Java中作为GC Roots的对象: 在虚拟机栈（栈帧中的本地变量表）中引用的对象，譬如各个线程被调用的方法堆栈中使用到的参数、局部变量、临时变量等。 在方法区中类静态属性引用的对象，譬如Java类的引用类型静态变量。 在方法区中常量引用的对象，譬如字符串常量池（String Table）里的引用。 在本地方法栈中JNI（即通常所说的Native方法）引用的对象。 Java虚拟机内部的引用，如基本数据类型对应的Class对象，一些常驻的异常对象（比如NullPointExcepiton、OutOfMemoryError）等，还有系统类加载器。 所有被同步锁（synchronized关键字）持有的对象。 反映Java虚拟机内部情况的JMXBean、JVMTI中注册的回调、本地代码缓存等。 其他对象临时性地加入,共同构成GC Roots","categories":[{"name":"JVM","slug":"JVM","permalink":"https://greycode.top/categories/JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://greycode.top/tags/JVM/"}]},{"title":"JVM运行时数据区域","slug":"java/jvm/jvm-running-data-area","date":"2020-05-26T16:35:47.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"java/jvm/jvm-running-data-area/","link":"","permalink":"https://greycode.top/java/jvm/jvm-running-data-area/","excerpt":"","text":"JVM运行时数据区域 程序计数器 线程私有 唯一一个没有规定 OutOfMemoryError 异常 的区域 它可以看作是当前线程所执行的字节码的行号指示器 如果线程正在执行的是一个Java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；如果正在执行的是本地（Native）方法，这个计数器值则应为空（Undefined） (摘自网上)我们想象下，CPU是怎么知道记住之前A线程，执行到哪一处的？ 答案是，CPU根本就不会记住之前执行到哪里了，它只是埋头苦干；那是什么保证了切换线程的程序可以正常执行的；答案是 ： 程序计数器 ；程序计数器里面保存的是 当前线程执行的字节码的行号（看着像行号，其实是指令地址）； 那么，我们需要几个程序计数器呢？如果，我们只有一个的话，切换B线程以后，程序计数器里面保存的就是B线程所执行的字节码的行号了，再切换回A线程，就蒙圈了，不知道执行到哪里了，因为，程序计数器里面保存的是B线程当前执行的字节码地址 ；因此，我们可以想象出，要为每个线程都分配一个程序计数器，因此，程序计数器的内存空间是线程私有的 ；这样即使线程 A 被挂起，但是线程 A 里面的程序计数器，记住了A线程当前执行到的字节码的指令地址了 ，等再次切回到A线程的时候，看一下程序计数器，就知道之前执行到哪里了！ 那么程序计数器，什么时候分配内存呢？我们试想下，一个线程在执行的任何期间，都会失去CPU执行权，因此，我们要从一个线程被创建开始执行，就要无时无刻的记录着该线程当前执行到哪里了！因此，线程计数器，必须是线程被创建开始执行的时候，就要一同被创建； 程序计数器，保存的是当前执行的字节码的偏移地址（也就是之前说的行号，其实那不是行号，是指令的偏移地址，只是为了好理解，才说是行号的，），当执行到下一条指令的时候，改变的只是程序计数器中保存的地址，并不需要申请新的内存来保存新的指令地址；因此，永远都不可能内存溢出的；因此，jvm虚拟机规范，也就没有规定，也是唯一一个没有规定 OutOfMemoryError 异常 的区域; 当线程执行的是本地方法的时候，程序计数器中保存的值是空（undefined）；原因很简单：本地方法是C++&#x2F;C 写的，由系统调用，根本不会产生字节码文件，因此，程序计数器也就不会做任何记录 Java虚拟机栈 线程私有 如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError异常； 如果Java虚拟机栈容量可以动态扩展，当栈扩展时无法申请到足够的内存会抛出OutOfMemoryError异常；(HotSpot虚拟机的栈容量是不可以动态扩展的，以前的Classic虚拟机倒是可以。所以在HotSpot虚拟机上是不会由于虚拟机栈无法扩展而导致OutOfMemoryError异常——只要线程申请栈空间成功了就不会有OOM，但是如果申请时就失败，仍然是会出现OOM异常的) -Xss5m: 设置5m的栈容量 每个方法执行都会创建一个栈帧，栈帧包含局部变量表、操作数栈、动态连接、方法出口等 本地方法栈 线程私有 与Java虚拟机栈相似 与Java虚拟机栈区别: Java虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则是为虚拟机使用到的本地（Native）方法服务。 Hot-Spot虚拟机直接就把本地方法栈和虚拟机栈合二为一 与虚拟机栈一样，本地方法栈也会在栈深度溢出或者栈扩展失败时分别抛出StackOverflowError和OutOfMemoryError异常 Java堆 线程共享 所有的Java对象实例不一定都在Java堆上分配内存 Java堆既可以被实现成固定大小的，也可以是可扩展的，不过当前主流的Java虚拟机都是按照可扩展来实现的（通过参数-Xmx和-Xms设定）。 如果在Java堆中没有内存完成实例分配，并且堆也无法再扩展时，Java虚拟机将会抛出OutOfMemoryError异常。 Java堆是垃圾收集器(Garbage Collected)管理的内存区域 方法区 线程共享 用于存储已被虚拟机加载的类型信息、常量、静态变量、即时编译器编译后的代码缓存等数据。 虽然《Java虚拟机规范》中把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫作“非堆”（Non-Heap），目的是与Java堆区分开来。 在JDK1.6及之前,使用永久代来实现方法区. -XX:MaxPermSize 设置永久代内存上限 -XX:PermSize 设置永久代内存 JDK1.7把字符串常量池、类的静态变量(class statics)转移到了java heap,但是永久代还是存在,主要放一些类信息(运算时常量池)等. JDK1.8彻底移除永久代,方法区采用本地内存中实现的元空间（Meta-space）来代替,将JDK1.7中永久代的信息移到了元空间,像字符串常量池和静态变量还是存在Java Heap中 如果方法区无法满足新的内存分配需求时，将抛出OutOfMemoryError异常。","categories":[{"name":"JVM","slug":"JVM","permalink":"https://greycode.top/categories/JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://greycode.top/tags/JVM/"}]},{"title":"JVM逃逸分析技术","slug":"java/jvm/jvm-javastack-EscapeAnalysis","date":"2020-05-26T16:02:00.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"java/jvm/jvm-javastack-EscapeAnalysis/","link":"","permalink":"https://greycode.top/java/jvm/jvm-javastack-EscapeAnalysis/","excerpt":"","text":"逃逸分析技术的日渐成熟,促使所有的Java对象实例不一定都在Java堆上分配内存 简单来讲就是，Java Hotspot 虚拟机可以分析新创建对象的使用范围，并决定是否在 Java 堆上分配内存的一项技术。 使用 开启逃逸分析：-XX:+DoEscapeAnalysis 关闭逃逸分析：-XX:-DoEscapeAnalysis 显示分析结果：-XX:+PrintEscapeAnalysis 逃逸分析技术在 Java SE 6u23+ 开始支持,并默认设置为启用状态 逃逸程度逸分析的基本行为就是分析对象动态作用域,从不逃逸、方法逃逸到线程逃逸，称为对象由低到高的不同逃逸程度。 方法逃逸当一个对象在方法中被定义后，它可能被外部方法所引用，例如作为调用参数传递到其他地方中，称为方法逃逸。 /*StringBuffer sb是一个方法内部变量，上述代码中直接将sb返回，这样这个StringBuffer有可能被其他方法所*改变，这样它的作用域就不只是在方法内部，虽然它是一个局部变量，称其逃逸到了方法外部。甚至还有可能被外部线*程访问到，譬如赋值给类变量或可以在其他线程中访问的实例变量，称为线程逃逸。*/ public static StringBuffer craeteStringBuffer(String s1, String s2) &#123; StringBuffer sb = new StringBuffer(); sb.append(s1); sb.append(s2); return sb; &#125; //上述代码如果想要StringBuffer sb不逃出方法，可以这样写： public static String createStringBuffer(String s1, String s2) &#123; StringBuffer sb = new StringBuffer(); sb.append(s1); sb.append(s2); return sb.toString(); &#125; 线程逃逸 当一个对象在方法中被定义后，它可能被外部线程访问到，譬如赋值给可以在其他线程中访问的实例变量，这种称为线程逃逸。 逃逸分析优化如果能证明一个对象不会逃逸到方法或线程之外（换句话说是别的方法或线程无法通过任何途径访问到这个对象），或者逃逸程度比较低（只逃逸出方法而不会逃逸出线程），则可能为这个对象实例采取不同程度的优化 栈上分配（Stack Allocations） 如果确定一个对象不会逃逸出线程之外，那让这个对象在栈上分配内存将会是一个很不错的主意，对象所占用的内存空间就可以随栈帧出栈而销毁。 由于复杂度等原因，HotSpot中目前暂时还没有做这项优化，但一些其他的虚拟机（如Excelsior JET）使用了这项优化。 栈上分配可以支持方法逃逸，但不能支持线程逃逸。 标量替换（Scalar Replacement） 若一个数据已经无法再分解成更小的数据来表示了，Java虚拟机中的原始数据类型（int、long等数值类型及reference类型等）都不能再进一步分解了，那么这些数据就可以被称为标量。相对的，如果一个数据可以继续分解，那它就被称为聚合量（Aggregate），Java中的对象就是典型的聚合量。 -XX:+EliminateAllocations 开启标量替换(jdk8默认开启) -XX:+PrintEliminateAllocations 查看标量的替换情况 如果把一个Java对象拆散，根据程序访问的情况，将其用到的成员变量恢复为原始类型来访问，这个过程就称为标量替换 假如逃逸分析能够证明一个对象不会被方法外部访问，并且这个对象可以被拆散，那么程序真正执行的时候将可能不去创建这个对象，而改为直接创建它的若干个被这个方法使用的成员变量来代替。 标量替换可以视作栈上分配的一种特例，实现更简单（不用考虑整个对象完整结构的分配），但对逃逸程度的要求更高，它不允许对象逃逸出方法范围内。 同步消除（Synchronization Elimination） 也叫锁消除 +XX:+EliminateLocks 开启同步消除(jdk8默认开启) 线程同步本身是一个相对耗时的过程，如果逃逸分析能够确定一个变量不会逃逸出线程，无法被其他线程访问，那么这个变量的读写肯定就不会有竞争，对这个变量实施的同步措施也就可以安全地消除掉。 比如常用的线程安全类:StringBuffer,HashTable,Vector等.","categories":[{"name":"JVM","slug":"JVM","permalink":"https://greycode.top/categories/JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://greycode.top/tags/JVM/"}]},{"title":"基于SpringCloud搭建Spring-security-oauth认证服务器","slug":"archive/web-security/spring-security-oauth-server-demo","date":"2020-05-19T20:25:06.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"archive/web-security/spring-security-oauth-server-demo/","link":"","permalink":"https://greycode.top/archive/web-security/spring-security-oauth-server-demo/","excerpt":"","text":"准备阶段这里搭建一个用OAuth2.0密码模式认证的服务器，token存入redis，client存入Mysql； 所以事先要准备好： Redis Mysql 并且Mysql执行Spring-security-oauth初始化Sql这个SQL，初始化Spring-security-oauth所需要的表。然后执行 -- 插入client_id和client_secret都为sunline的客户端insert into oauth_client_details (client_id, client_secret, authorized_grant_types , autoapprove)values (&quot;sunline&quot;,&quot; &#123;bcrypt&#125;$2a$10$G1CFd535SiyOtvi6ckbZWexQy.hW5x/I/fLBPiW/E4UmctCfKYbgG&quot;,&quot;password&quot;,&quot;true&quot;); client_secret为new BCryptPasswordEncoder().encode(&quot;sunline&quot;)方法加密后，然后在加上&#123;bcrypt&#125; 开始搭建导入pom依赖&lt;!--security-oauth--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-oauth2&lt;/artifactId&gt;&lt;/dependency&gt; &lt;!--redis--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; &lt;!--mysql--&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;8.0.17&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt;&lt;/dependency&gt; 配置application.properties#datasourcespring.datasource.url=jdbc:mysql://localhost:3307/grey_code?useUnicode=true&amp;characterEncoding=UTF-8&amp;autoReconnect=true&amp;serverTimezone=Asia/Shanghaispring.datasource.username=zmhspring.datasource.password=zmh#redisspring.redis.host=127.0.0.1spring.redis.port=6379server.port=9991server.servlet.context-path=/oauthServer 创建用户详情服务类 创建权限控制类 创建认证授权类 获取令牌访问:/oauth/token就可以获取到令牌 &#123; &quot;accessToken&quot;: &quot;e28f9a99-e60d-4693-b6c3-73e06a1d14f5ZMH10086&quot;, &quot;expiration&quot;: &quot;2020-05-19T21:11:39.883+0000&quot;, &quot;scope&quot;: [ &quot;all&quot; ], &quot;tokenType&quot;: &quot;bearer&quot;&#125; 访问资源带上获取到的令牌","categories":[{"name":"WebSecurity","slug":"WebSecurity","permalink":"https://greycode.top/categories/WebSecurity/"}],"tags":[{"name":"OAuth","slug":"OAuth","permalink":"https://greycode.top/tags/OAuth/"},{"name":"spring-security","slug":"spring-security","permalink":"https://greycode.top/tags/spring-security/"}]},{"title":"SSO单点登录和CAS框架","slug":"archive/web-security/sso-and-cas","date":"2020-05-14T19:27:14.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"archive/web-security/sso-and-cas/","link":"","permalink":"https://greycode.top/archive/web-security/sso-and-cas/","excerpt":"","text":"SSO单点登录单点登录（英语：Single sign-on，缩写为 SSO），又译为单一签入，一种对于许多相互关连，但是又是各自独立的软件系统，提供访问控制的属性。当拥有这项属性时，当用户登录时，就可以获取所有系统的访问权限，不用对每个单一系统都逐一登录。这项功能通常是以轻型目录访问协议（LDAP）来实现，在服务器上会将用户信息存储到LDAP数据库中。相同的，单一退出（single sign-off）就是指，只需要单一的退出动作，就可以结束对于多个系统的访问权限。 优点使用单点登录的好处包括： 降低访问第三方网站的风险（不存储用户密码，或在外部管理）。 减少因不同的用户名和密码组合而带来的密码疲劳。 减少为相同的身份重新输入密码所花费的时间。 因减少与密码相关的调用IT服务台的次数而降低IT成本。[1] SSO为所有其它应用程序和系统，以集中的验证服务器提供身份验证，并结合技术以确保用户不必频繁输入密码。 CAS框架CAS 协议基于在客户端Web浏览器、Web应用和CAS服务器之间的票据验证。当客户端访问访问应用程序，请求身份验证时，应用程序重定向到CAS。CAS验证客户端是否被授权，通常通过在数据库对用户名和密码进行检查。如果身份验证成功，CAS一次性在客户端以Cookie形式发放TGT票据，在其有效期CAS将一直信任用户，同时将客户端自动返回到应用程序，并向应用传递身份验证票（Service ticket）。然后，应用程序通过安全连接连接CAS，并提供自己的服务标识和验证票。之后CAS给出了关于特定用户是否已成功通过身份验证的应用程序授信信息。 历史 CAS是由耶鲁大学[1]的Shawn Bayern创始的，后来由耶鲁大学的Drew Mazurek维护。CAS1.0实现了单点登录。 CAS2.0引入了多级代理认证（Multi-tier proxy authentication）。CAS其他几个版本已经有了新的功能。 2004年12月，CAS成为Jasig[2]的一个项目，2008年该组织负责CAS的维护和发展。CAS原名“耶鲁大学CAS”，此后被称为“Jasig CAS”。 2005年5月，CAS协议版本2发布，引入代理和服务验证。 2006年12月，安德鲁·W·梅隆基金会授予耶鲁大学第一届梅隆技术协作奖，颁发50000美元的奖金对耶鲁大学开发CAS进行奖励。[3]颁奖之时，CAS在“数以百计的大学校园”中使用。 2012年12月，JASIG与Sakai基金合并，CAS改名为Apereo CAS。 2016年11月，基于Spring Boot的CAS软件版本5发布。","categories":[{"name":"WebSecurity","slug":"WebSecurity","permalink":"https://greycode.top/categories/WebSecurity/"}],"tags":[{"name":"SSO","slug":"SSO","permalink":"https://greycode.top/tags/SSO/"},{"name":"CAS框架","slug":"CAS框架","permalink":"https://greycode.top/tags/CAS%E6%A1%86%E6%9E%B6/"}]},{"title":"OAuth2.0与JWT","slug":"archive/web-security/oauth-and-jwt","date":"2020-05-12T14:59:43.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"archive/web-security/oauth-and-jwt/","link":"","permalink":"https://greycode.top/archive/web-security/oauth-and-jwt/","excerpt":"","text":"OAuth2.0OAuth2.0是一个授权协议，它允许软件应用代表资源拥有者去访问资源拥有者的资源。应用向资源拥有者请求令牌，并用这个令牌来访问资源拥有者的资源。 角色 客户端：相当于访问受保护资源的软件 授权服务器：授予客户端令牌的服务 资源拥有者：受保护的资源拥有者，有权决定将不将令牌授权给客户端 受保护的资源：除资源拥有者外，要访问此资源必须要有授权服务器颁发的有效的令牌 授权类型授权码许可类型 隐式许可类型 客户端凭证许可类型 资源拥有者凭证许可类型(账号密码模式) 断言许可类型JWTJWT全称：JSON Web Token，是一种令牌格式。其格式类似为xxxxx.yyyyy.zzzzz,分为三部分，每个部分都用Base64进行编码，之间用.分隔。 第一部分：为Header部分，标头通常由两部分组成：令牌的类型（即JWT）和所使用的签名算法，例如HMAC SHA256或RSA。 &#123; &quot;alg&quot;: &quot;HS256&quot;, &quot;typ&quot;: &quot;JWT&quot;&#125; 第二部分：令牌的第二部分是有效负载，其中包含声明。 声明是有关实体（通常是用户）和其他数据的声明。 共有三种类型的声明：注册的，公共的和私有的三种声明。当然里面可以存放任何有效的字段信息（私有声明）。但是为了避免不同实现之间不兼容，可以准守JWT官方提供的声明字段。 注册声明：JWT官方提供的声明，参考资料:https://tools.ietf.org/html/rfc7519#section-4.1 公共声明：用户发邮件给JWT官方进行注册的声明字段，参考资料：https://tools.ietf.org/html/rfc7519#section-4.2 私有声明：完全用户自定义，参考资料https://tools.ietf.org/html/rfc7519#section-4.3 第三部分：为令牌签名部分，使用这个字段后，资源服务器只会接受签名正确的令牌。","categories":[{"name":"WebSecurity","slug":"WebSecurity","permalink":"https://greycode.top/categories/WebSecurity/"}],"tags":[{"name":"OAuth2.0","slug":"OAuth2-0","permalink":"https://greycode.top/tags/OAuth2-0/"},{"name":"JWT","slug":"JWT","permalink":"https://greycode.top/tags/JWT/"}]},{"title":"fastDFS安装使用教程","slug":"linux/linux-fastdfs-install","date":"2020-05-07T13:34:10.000Z","updated":"2022-04-16T02:52:58.653Z","comments":true,"path":"linux/linux-fastdfs-install/","link":"","permalink":"https://greycode.top/linux/linux-fastdfs-install/","excerpt":"","text":"FastDFS简介FastDFS 是一个开源的高性能分布式文件系统（DFS）。 它的主要功能包括：文件存储，文件同步和文件访问，以及高容量和负载平衡。主要解决了海量数据存储问题，特别适合以中小文件（建议范围：4KB &lt; file_size &lt;500MB）为载体的在线服务。 FastDFS 系统有三个角色：跟踪服务器(Tracker Server)、存储服务器(Storage Server)和客户端(Client)。 Tracker Server：跟踪服务器，主要做调度工作，起到均衡的作用；负责管理所有的 storage server和 group，每个 storage 在启动后会连接 Tracker，告知自己所属 group 等信息，并保持周期性心跳。 Storage Server：存储服务器，主要提供容量和备份服务；以 group 为单位，每个 group 内可以有多台 storage server，数据互为备份。 Client：客户端，上传下载数据的服务器，也就是我们自己的项目所部署在的服务器。 结构图 上传文件流程 安装环境 系统及软件版本 Git开源地址 Centos 7 # libfastcommon V1.0.43 https://github.com/happyfish100/fastdfs fastdfs V6.06 https://github.com/happyfish100/libfastcommon 我虚拟机装的Centos7的ip地址是172.16.54.137 安装前工作关闭防火墙 为了方便，先关闭防火墙。线上环境安装可安装后开放对应端口。 service firewalld stop 下载所需安装包 libfastcommon wget https://github.com/happyfish100/libfastcommon/archive/V1.0.43.tar.gz -O libfastcommon.tar.gz fastDFS wget https://github.com/happyfish100/fastdfs/archive/V6.06.tar.gz -O fastdfs.tar.gz 安装fastDFS环境 解压安装libfastcommon tar -zxvf libfastcommon.tar.gz &amp;&amp; cd libfastcommon-1.0.43/ &amp;&amp; ./make.sh &amp;&amp; ./make.sh install 安装fastDFS解压安装tar -zxvf fastdfs.tar.gz &amp;&amp; cd fastdfs-6.06/ &amp;&amp; ./make.sh &amp;&amp; ./make.sh install 安装好fastDFS后，在/etc/fdfs/目录下会生成4个示例的配置文件 client.conf.sample fastDFS客户端配置文件 storage.conf.sample storage_ids.conf.sample 当storage超过1个时，可以用这个配置文件来配置管理 tracker.conf.sample 配置并启动Tracker进入/etc/fdfs/复制一份Tracker配置文件， cd /etc/fdfs/ &amp;&amp; cp tracker.conf.sample tracker.conf 修改tracker.conf配置文件里的base_path目录 base_path=/data/fastdfs/tracker 创建对应的文件夹 mkdir -p /data/fastdfs/tracker 服务命令 #启动Trackerservice fdfs_trackerd start#关闭Trackerservice fdfs_trackerd stop#开机自启systemctl enable fdfs_trackerd 配置并启动Storage进入/etc/fdfs/复制一份Storage配置文件， cd /etc/fdfs &amp;&amp; cp storage.conf.sample storage.conf 修改storage.conf配置文件 base_path=/data/fastdfs/storage#存放文件地址store_path0=/data/fastdfs/file#更改为你的tracker地址tracker_server=172.16.54.137:22122 创建对应的文件夹 mkdir -p /data/fastdfs/storage &amp;&amp; mkdir -p /data/fastdfs/file 服务命令 #启动Storageservice fdfs_storaged start#关闭Storageservice fdfs_storaged stop#开机自启systemctl enable fdfs_storaged 上传文件测试 上传文件可以用他自带的客户端进行测试，使用客户端前，要复制一份client.conf并修改一下里面的内容 #复制一份客户端配置文件cd /etc/fdfs &amp;&amp; cp client.conf.sample client.conf 修改client.config配置文件 base_path=/data/fastdfs/client#更改为你的tracker地址tracker_server=172.16.54.137:22122 创建对应文件夹 mkdir -p /data/fastdfs/client 使用方法 /usr/bin/fdfs_upload_file /etc/fdfs/client.conf [filename]#上传成功后返回group1/M00/00/00/rBA2iV6yvU2AEXUfAAACGTXt3Kw94.yaml 安装Nginx 为了方便，这里直接使用nginx的docker镜像来进行安装。docker安装请自行查找资料 首先创建一个文件夹，存放nginx的配置文件 #创建文件夹mkdir -p /data/nginx#进入文件夹并下载nginx配置文件cd /data/nginx &amp;&amp; wget http://xhh.dengzii.com/file/nginx.conf 配置文件已经修改过了，直接下载即可使用 然后运行docker命令（第一次运行会自动下载nginx镜像） docker run -d -p 81:80 -v /data/nginx/nginx.conf:/etc/nginx/nginx.conf -v /data/:/data/ --name fastDFS-nginx nginx 然后就可以通过http://ip:port/[filePth]访问上传到fastDFS的文件了 #例如刚才上传的文件 可以通过如下地址访问http://172.16.54.137:81/group1/M00/00/00/rBA2iV6yvU2AEXUfAAACGTXt3Kw94.yaml 拓展这里只是示例了单机的fastDFS安装，一般fastDFS都是分布式安装的。具体可以通过下载这个结构图去进行安装。此时如果配置了多个group，则需要安装fastdfs-nginx-module这个nginx的模块。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://greycode.top/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://greycode.top/tags/Linux/"},{"name":"fastDFS","slug":"fastDFS","permalink":"https://greycode.top/tags/fastDFS/"}]},{"title":"插入emoji到mysql时提示了一个表里不存在的字段的错误","slug":"mysql/mysql-utf8mb4-error","date":"2020-04-29T17:16:27.000Z","updated":"2022-04-16T02:52:58.653Z","comments":true,"path":"mysql/mysql-utf8mb4-error/","link":"","permalink":"https://greycode.top/mysql/mysql-utf8mb4-error/","excerpt":"","text":"1.问题描述由于公司前端有需求，需要在tiny_user_info表的nickname这个字段里存入emoji表情，于是我熟练地将这个字段修改为utf8mb4，改好后测试插入一条带emoji数据。于是报了这个错误： [2020-04-29 15:57:25] [HY000][1366] Incorrect string value: &#x27;\\xF0\\x9F\\x98\\x98&#x27; for column &#x27;user_name&#x27; at row 14 当时我就傻了，我这个表里也没有user_name这个字段啊，怎么会报这个字段错误,我明明修改的是nickname这个字段啊。于是google和百度搜了一圈，无解。 ２.解决方案试了好几种方法，删字段，重新建。删表，重新建。都不行。。。。。静下心来，于是打算从mysql服务器入手。进入到mysql对应库的文件夹，发现tiny_user_info这个表有三个文件 和常见的多了一个TRG文件。这是一个触发器文件，打开一看，发现了user_name字段。。。。。。 原来是同事在这个表里加了个触发器，当tiny_user_info里新增数据时，会触发新增到另一张表里，nickname的值同时会插入到另一张表的user_name字段，而他那张表的字段没有设置utf8mb4编码,所以导致插入失败。于是叫同事把他那张表设置一下utf8mb4编码后，就可以正常插入了。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://greycode.top/categories/MySQL/"}],"tags":[{"name":"Pit","slug":"Pit","permalink":"https://greycode.top/tags/Pit/"},{"name":"MySQL","slug":"MySQL","permalink":"https://greycode.top/tags/MySQL/"}]},{"title":"【数据结构】手写平衡二叉树（AVL）","slug":"algorithm/algorithm-avltree-01","date":"2020-02-01T15:56:00.000Z","updated":"2022-04-16T02:52:58.645Z","comments":true,"path":"algorithm/algorithm-avltree-01/","link":"","permalink":"https://greycode.top/algorithm/algorithm-avltree-01/","excerpt":"","text":"【数据结构】手写平衡二叉树（AVL） 积千里跬步，汇万里江河。每天进步一点点，终有一天将成大佬 本文源代码：手写AVL树 什么是平衡二叉树？平衡二叉树，又称为AVL树，当树不是空树时，它的左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。AVL树查找的时间复杂度为O(logN)。 平衡二叉树基本特点 左右子树深度差不能大于1 左边子树永远比根节点小 右边子树永远比根节点大 平衡二叉树基本结构及操作 左左结构——右旋 右右结构——左旋 左右结构——左子先左旋，然后整体右旋 右左结构——右子先右旋，然后整体左旋 代码实现先创建一个内部类Node，来表示树的每个节点 public class AVLTree &#123; private Node rootNode; //二叉树节点 private class Node&#123; public Node parent; //父 public Node left; //左子树 public Node right; //右子树 @NotNull public int data; //存放的数据 private int depth; //深度 private int balance; //平衡因子 //有参构造方法 public Node(int data)&#123; this.data=data; this.depth=1; this.balance=0; &#125; &#125;&#125; 插入数据暴露一个方法给外部调用 /**添加数据方法*/public void add(int data)&#123; if (this.rootNode==null)&#123; this.rootNode=new Node(data); &#125;else &#123; this.insert(rootNode,data); //判断根节点是否有父 有的话说明有旋转操作，更新根节点 if (this.rootNode.parent!=null)&#123; this.rootNode=this.rootNode.parent; &#125; &#125;&#125; 实际内部是调用另一个insert方法： private void insert(Node root,int data)&#123; //插入的数据比根小 if (data&lt;root.data)&#123; if (root.left==null)&#123; root.left=new Node(data); root.left.parent=root; &#125;else &#123; this.insert(root.left,data); &#125; &#125; //插入的数据比根大 if (data&gt;root.data)&#123; if (root.right==null) &#123; root.right=new Node(data); root.right.parent=root; &#125;else&#123; this.insert(root.right,data); &#125; &#125; root.balance=this.getBalance(root); if (root.balance&gt;1)&#123; //判断左子的平衡因子 if (root.left.balance&lt;0)&#123; this.leftTurn(root.left); &#125; this.rightTurn(root); &#125; if (root.balance&lt;-1)&#123; //判断右子的平衡因子 if (root.right.balance&gt;0)&#123; this.rightTurn(root.right); &#125; this.leftTurn(root); &#125; root.depth=this.getDepth(root); root.balance=this.getBalance(root);&#125; 右旋 右旋的操作如下 我父变成左子的父 左子变成我的父 我变成左子的右子 左子的右子变成我的左子 (当左子的右子存在时)我变成左子的右子的父 计算左右节点的深度 计算深度差 private void rightTurn(@NotNull Node node)&#123; Node parent=node.parent; Node leftSon=node.left; Node leftSon_rightSon=leftSon.right; //如果父不为空，判断我是在父的左节点还是右节点 if (parent!=null)&#123; if (node==parent.left)&#123; //我在父的左节点上，把我的左子变成父的左子 parent.left=leftSon; &#125; if (node==parent.right)&#123; //我在父的右节点上，把我的左子变成父的右子 parent.right=leftSon; &#125; &#125; leftSon.parent=parent; node.parent=leftSon; leftSon.right=node; node.left=leftSon_rightSon; //如果左子的右子确实存在的 if (leftSon_rightSon!=null)&#123; //我变成左子的右子的父 leftSon_rightSon.parent=node; &#125; //重新计算深度和平衡因子 node.depth=this.getDepth(node); node.balance=this.getBalance(node); leftSon.depth=this.getDepth(leftSon); leftSon.balance=this.getBalance(leftSon);&#125; 左旋 左旋的操作如下 我的父变右子的父 右子变成我的父 我变成右子的左子 右子的左子变成我的右子 (当右子的左子存在时)我变成右子的左子的父 计算左右节点的深度 计算深度差 private void leftTurn(@NotNull Node node)&#123; Node parent=node.parent; Node rightSon=node.right; Node rightSon_leftSon=rightSon.left; if (parent!=null)&#123; if (node==parent.left)&#123; parent.left=rightSon; &#125; if (node==parent.right)&#123; parent.right=rightSon; &#125; &#125; rightSon.parent=parent; node.parent=rightSon; rightSon.left=node; node.right=rightSon_leftSon; if (rightSon_leftSon!=null)&#123; rightSon_leftSon.parent=node; &#125; node.depth=this.getDepth(node); node.balance=this.getBalance(node); rightSon.depth=this.getDepth(rightSon); rightSon.balance=this.getBalance(rightSon);&#125; 计算深度/**计算深度*/private int getDepth(Node node)&#123; int depth = 0; if(node.left==null &amp;&amp; node.right!=null) &#123; depth=node.right.depth; &#125; if(node.right==null &amp;&amp; node.left!=null) &#123; depth=node.left.depth; &#125; if (node.right!=null &amp;&amp; node.left!=null) &#123; depth=Math.max(node.left.depth,node.right.depth); &#125; depth++; return depth;&#125; 计算平衡因子/**计算左右深度差*/private int getBalance(Node node)&#123; int leftDepth = 0; int rightDepth = 0; if(node.left!=null)&#123; leftDepth=node.left.depth; &#125; if(node.right!=null)&#123; rightDepth=node.right.depth; &#125; /** * 左减右 * 为负数：右边子树高 * 为正数: 左边子树高 * */ return leftDepth-rightDepth;&#125; 附言如果代码和静态图看不太明白的话，这边推荐几个动画演示的网站(可能需要科学上网)： visualgo在线 数据结构可视化","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"https://greycode.top/categories/Algorithm/"}],"tags":[{"name":"AVL","slug":"AVL","permalink":"https://greycode.top/tags/AVL/"},{"name":"数据结构","slug":"数据结构","permalink":"https://greycode.top/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"平衡二叉树","slug":"平衡二叉树","permalink":"https://greycode.top/tags/%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"name":"二叉树","slug":"二叉树","permalink":"https://greycode.top/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/"}]},{"title":"【转】免费可商用，最值得收藏的10个插画素材网站","slug":"recommend/recommend-tool-1","date":"2020-01-16T09:24:52.000Z","updated":"2022-04-16T02:52:58.653Z","comments":true,"path":"recommend/recommend-tool-1/","link":"","permalink":"https://greycode.top/recommend/recommend-tool-1/","excerpt":"","text":"转自凯凯刘 现在插画风格的界面越来越多，网上提供的免费插图也越来越丰富。这些插图优点是表达的内容更丰富，包括：人物、商业、运动、自然、工作、幽默等等。也更适合产品类的宣传网站或者落地页。另外，矢量图的不失真在不同尺寸的显示效果上更胜一筹。花时间整理了当前全网那些优秀的10个免费插图网站，给做产品的人们节省点查找的时间，建议收藏以备后用。这些站点的素材都是免费下载可用的，而且可以免费商用。 IRA Design网站：https://iradesign.io/介绍：可以将元素进行组合形成自己喜欢的图片，有png和svg格式 Absurd Design网站：https://absurd.design/介绍：有些荒诞风格的矢量图，适用网站的落地页、APP等 Ouch!网站：https://icons8.com/ouch介绍：很多的免费图，各种分类 unDraw网站：https://undraw.co/内容：开源的矢量图库，各种你能想到的基本都有 Pngtree网站：https://pngtree.com/介绍：上百万的素材资源可下载 Drawkit网站：https://www.drawkit.io/介绍：有免费的下载资源集合 Humaaans网站：https://www.humaaans.com内容：关于人物的插画图片站 Manypixels网站：https://www.manypixels.co/gallery/介绍：建筑、人物、科技、天气、运动，商业等类型的插画 Lukaszadam网站：https://lukaszadam.com/illustrations介绍：一些有趣的小图标的插画 Pixabay网站：https://pixabay.com/illustrations/search/介绍：收集了很多免费的插图素材，根据关键字可任意搜索","categories":[{"name":"Recommend","slug":"Recommend","permalink":"https://greycode.top/categories/Recommend/"}],"tags":[{"name":"UI","slug":"UI","permalink":"https://greycode.top/tags/UI/"},{"name":"推荐","slug":"推荐","permalink":"https://greycode.top/tags/%E6%8E%A8%E8%8D%90/"}]},{"title":"【源码解析】你真的了解ArrayDeque嘛？","slug":"java/java-arraydeque-source-1","date":"2020-01-08T14:00:51.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"java/java-arraydeque-source-1/","link":"","permalink":"https://greycode.top/java/java-arraydeque-source-1/","excerpt":"","text":"积千里跬步，汇万里江河；每天进步一点点，终有一天将成大佬 前言 上篇文章说LinkedList也可以实现队列和栈的功能，但是我们一般要用队列功能的话推荐使用ArrayDeque,因为他层是数组，而队列和栈都是只要操作头部或尾部，所以这样的话数组的性能就比链表快一点。 LinkedList和ArrayDeque都是通过实现了Deque这个接口来获得队列和栈的功能。而Deque这个接口通过继承Queue这个接口来取得队列功能，然后在这个基础进行扩展，实现了双端队列，由此可以获得栈的功能。为了空间能得到充分利用，ArrayDeque使用了循环队列；还有LinkedList可以插入null值，而ArrayDeque是不能插入null的。 什么是双端队列？ 简单来说，就是两端都可以操作的队列（🌚说了和没说一样…）。哈哈，还是看图吧 一般队列是这样的： 双端队列是这样的 总的来说，普通队列只可在头部删除元素和尾部添加元素，而双端队列头部和尾部都可以添加和删除元素 什么是循环队列？ 不如说你定了个5容量大小的数组，你第一次插入的位置是下标为2，当你添加第4个元素的时候，他不会进行扩容，而是通过头尾指针进行对比，然后把数据插入到下标为0的位置上。当头尾指针相等时，表示这个队列数组已经满了，这时才会扩容。 这里的数组从上向下的顺序，有人会问为什么头尾指针都指向第三个方格呢？因为这边演示的是第一个元素插入到下标为2的位置嘛。。当然，ArrayDeque是从0开始的，所以初始化时头尾指针都是指向下标为0的位置上。 Deque有什么？ 话不多说，看图： ArrayDeque具体实现的方法主要在蓝色的方框里，其他两个颜色的方框都是通过调用蓝色方框里的这些方法来实现相关功能的，可以再看一张我画的脑图： 这边队列的每种功能都有两个方法，其中add()，remove()，element()如果操作失败会报异常，offer()，poll()，peek()操作失败会返回null或者false 其实真正用到的就深红色方框里写的这些方法，所以本文我就说这四个方法，addLast()，pollFirst，getFirst()，addFirst()，peekFirst； 内部变量 ArrayDeque内部就只有4个变量，对象数组element[]，头指针head，尾指针tail，MIN_INITIAL_CAPACITY表示最小初始化容量为8 构造方法 构造方法和其他集合一样，有有参构造和无参构造 无参构造 很简单，直接初始化一个容量为16的对象数组 public&nbsp;ArrayDeque()&nbsp;&#123;&nbsp;&nbsp;&nbsp;&nbsp;elements&nbsp;=&nbsp;new&nbsp;Object[16];&#125; 有参构造 传入参数为int数 public&nbsp;ArrayDeque(int&nbsp;numElements)&nbsp;&#123;&nbsp;&nbsp;&nbsp;&nbsp;allocateElements(numElements);&#125; allocateElements(int numElements)分配空数组以容纳给定数量的元素。 private&nbsp;void&nbsp;allocateElements(int&nbsp;numElements)&nbsp;&#123;&nbsp;&nbsp;&nbsp;&nbsp;elements&nbsp;=&nbsp;new&nbsp;Object[calculateSize(numElements)];&#125; calculateSize(int numElements)调整传入的值大小 上面的算法中用到了位运算，如果不了解位运算的话，可以看位运算这篇文章。这里把数值设置成2的n次方(是整数次)，是为了满足下面要说的循环队列这个算法 传入的参数为集合对象 public&nbsp;ArrayDeque(Collection&lt;?&nbsp;extends&nbsp;E&gt;&nbsp;c)&nbsp;&#123;&nbsp;&nbsp;&nbsp;&nbsp;allocateElements(c.size());&nbsp;&nbsp;&nbsp;&nbsp;addAll(c);&#125; 第一步调用了和上面一样的方法，这里多了个addAll()方法 addAll(Collection c) 这边复制时并没有用和ArrayList一样的System.arraycopy()方法，而是采用for循环来调用add()方法进行一个一个添加的；为什么这么做呢？因为ArrayDeque和其他集合不一样，它里面是不能有null值的，而其他集合里面有的是可以传null的，所以这边采用add()一个一个的加，add()方法如果传入的值为空的话，就会报异常；（add()实际调用的是addLast()，下面再讲） addLast() 源码解析 这个方法的意思是添加数据到尾部，下面图片方框中的位与算法是实现循环队列这个功能的核心算法 还记得上面初始化时候，不管传入的是什么数值，最后出来的都是2n(整数次)方。这个算法就是当&amp;右边为2n−1时，&amp;左边的数为正整数时，不管有多大，最后的结果永远&lt;=2n；当&amp;左边的数为0时，结果为0；当&amp;左边的数为负数时，-1=2n−1 举一些例子：当2n=8，2n−1=7 4&amp;7=4 9&amp;7=1 22&amp;7=6 0&amp;7=0 -1&amp;7=7 -2&amp;7=6 -8&amp;7=0 doubleCapacity()扩容为原来的2倍 流程图 方便理解，我画下上扩容的流程图，比如head在中间： pollFirst() 移除头部数据 源码解析 删除的时候并没有像ArrayList一样移动数据，而只是移动了head指向的位置 流程图 getFirst()和peekFirst() 这两个方法都是一样的，都是直接返回head指向的数据，区别就是一个会抛异常，一个不会 源码分析 getFirst() public&nbsp;E&nbsp;getFirst()&nbsp;&#123;&nbsp;&nbsp;&nbsp;&nbsp;@SuppressWarnings(\"unchecked\")&nbsp;&nbsp;&nbsp;&nbsp;E&nbsp;result&nbsp;=&nbsp;(E)&nbsp;elements[head];&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(result&nbsp;==&nbsp;null)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;throw&nbsp;new&nbsp;NoSuchElementException();&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;result;&#125; peekFirst() public&nbsp;E&nbsp;peekFirst()&nbsp;&#123;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;elements[head]&nbsp;is&nbsp;null&nbsp;if&nbsp;deque&nbsp;empty&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;(E)&nbsp;elements[head];&#125; addFirst() 源码解析 这里还是用了上面讲了位与算法，算出head的值，然后插入数据 流程图 clear() 源码解析 清空这个操作是从head指向的元素开始删除，直到head=tail，清空完成； size() 这个获取队列的大小也是用了上面讲的位与算法，用尾部减去了头部，然后位与数组的长度-1。为什么要这么弄呢？直接向ArrayList和LinkedList一样定义个size不好嘛？你不觉得这样更方便吗？少了一个变量，就少维护了一个变量，就少了一个安全隐患啊 public&nbsp;int&nbsp;size()&nbsp;&#123;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;(tail&nbsp;-&nbsp;head)&nbsp;&amp;&nbsp;(elements.length&nbsp;-&nbsp;1);&#125; 总结 上面的方法基本上有位与这个算法的身影，可见这个是核心了；如果不了解位运算的话，可以看位运算这篇文章； 核心算法： 当&amp;右边为2n−1时，&amp;左边的数为正整数时，不管有多大，最后的结果永远&lt;=2n；当&amp;左边的数为0时，结果为0；当&amp;左边的数为负数时，-1=2n−1 ArrayDeque无参构造方法是直接初始化一个容量为16的空数组，而上篇ArrayList文章里，它无参构造方法是初始化了一个空数组，在第一次添加数据的时候才进行扩容到10； ArrayDeque每次扩容为原来数组长度的2倍 ArrayDeque不能插入null值","categories":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/tags/Java/"},{"name":"源码解析","slug":"源码解析","permalink":"https://greycode.top/tags/%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/"},{"name":"ArrayDeque","slug":"ArrayDeque","permalink":"https://greycode.top/tags/ArrayDeque/"}]},{"title":"【源码解析】想了解LinkedList？看这篇文章就对了","slug":"java/java-linkedlist-source-1","date":"2020-01-05T00:21:43.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"java/java-linkedlist-source-1/","link":"","permalink":"https://greycode.top/java/java-linkedlist-source-1/","excerpt":"","text":"积千里跬步，汇万里江河；每天进步一点点，终有一天将成大佬。 本文基于JDK1.8 前言 LinkedList由于实现了Deque这个接口，所以可以当栈和队列使用。不过一般要用栈或队列的时候推荐使用ArrayDeque,所以这里就不讲LinkedList的栈和队列功能了🌚。还是和上篇ArrayList一样，讲些常用的方法。 LinkedList内部是由双链表组成的，里面存放着一个个Node，每个Node又包含三个元素(prev,item,next): prev:指向前一个Node item:存放存入的数据 next:指向下一个Node 链表的第一个Node的prev为null，最后个Node的next为null 我简单的画了一张图，可以看下 这个prev和next并不是指向null，因为内存中没有为null分配空间，这边是表示是prev和next为null； 本文内容 内部变量 相比于Arraylist，LinkedList内部变量就少得多，就只有三个，size存这当前元素的个数，first指向链表的第一个，last指向列表的最后一个 构造方法 无参构造方法 代码实现 List&lt;String&gt;&nbsp;list=new&nbsp;LinkedList&lt;&gt;(); 源码分析 无参构造只是初始化了数据，并未做任何操作(初始化 size=0 first=null last=null) 有参构造方法 代码实现 List&lt;String&gt;&nbsp;oldList=new&nbsp;LinkedList&lt;&gt;();List&lt;String&gt;&nbsp;newList=new&nbsp;LinkedList&lt;&gt;(oldList); 源码分析 由于篇幅有限，addAll()方法这边就不讲了，后面另写文章再讲，里面的操作就相当于把集合里的元素复制到新集合里面。 get方法 get(int index) 这里先讲get()方法，然后再讲add()方法，原因是插入方法里用到的调用的方法个get()方法里是一样的 代码实现 List&lt;String&gt;&nbsp;list=new&nbsp;LinkedList&lt;&gt;();list.add(\"hui\");list.add(\"灰\");list.add(\"灰2\");list.add(\"灰3\");list.get(2); 源码分析 checkElementIndex(int index)检查越界 node(int index)查找Node add方法 add(E e) 代码实现 List&lt;String&gt;&nbsp;list=new&nbsp;LinkedList&lt;&gt;();list.add(\"hui\"); 源码分析 linkLast(E e)连接最后一个元素 Node&lt;E&gt;内部类 就像开头说的，每个Node里有三个，prev:指向前一个Node，item:存放存入的数据，next:指向下一个Node private&nbsp;static&nbsp;class&nbsp;Node&lt;E&gt;&nbsp;&#123;&nbsp;&nbsp;&nbsp;&nbsp;E&nbsp;item;&nbsp;&nbsp;&nbsp;&nbsp;Node&lt;E&gt;&nbsp;next;&nbsp;&nbsp;&nbsp;&nbsp;Node&lt;E&gt;&nbsp;prev;&nbsp;&nbsp;&nbsp;&nbsp;Node(Node&lt;E&gt;&nbsp;prev,&nbsp;E&nbsp;element,&nbsp;Node&lt;E&gt;&nbsp;next)&nbsp;&#123;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;this.item&nbsp;=&nbsp;element;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;this.next&nbsp;=&nbsp;next;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;this.prev&nbsp;=&nbsp;prev;&nbsp;&nbsp;&nbsp;&nbsp;&#125;&#125; 流程图 第一次添加时的流程示意图 第一次添加时的流程示意图 不是第一次添加 不是第一次添加 add(int index, E element) 代码实现 List&lt;String&gt;&nbsp;list=new&nbsp;LinkedList&lt;&gt;();list.add(\"hui\");list.add(\"灰\");list.add(1,\"hk\"); 源码分析 这边插入元素时，先判断插入的位置是不是尾部，如果不尾部的话，先调用和get()那个一样的方法，来查找要插入位置的当前元素，然后进行插入操作 checkPositionIndex(int index)检查是否越界 这个检查越界的方法个get()检查越界的方法有点不同，它是可以等于size的，因为linkedList的索引设计也是从0开始的，所以size永远比索引大1 linkBefore(E e, Node&lt;E&gt; succ)插入元素操作 流程图 上面说的可能有点绕，看看流程图就明白了，哈哈 添加的位置为第一个 添加的位置为第一个 添加的位置为中间 添加的位置为中间 set方法 set(int index, E element) 代码实现 List&lt;String&gt;&nbsp;list=new&nbsp;LinkedList&lt;&gt;();list.add(\"hui\");list.set(0,\"灰\"); 源码解析 这里大多调用的是和get()里一样的方法 remove方法 remove(int index) 按索引删除，先找到被删除的Node，然后解除相关链接，设置Node里三大元素为null，删除后返回被删除Node里的item 代码实现 List&lt;String&gt;&nbsp;list=new&nbsp;LinkedList&lt;&gt;();list.add(\"hui\");list.add(\"灰\");list.remove(1); 源码解析 unlink(Node&lt;E&gt; x)解除Node的连接，然后返回被解除链接的item 流程图 删除的是链表里的第一个元素 删除的是链表里的第一个元素 删除的是链表里的中间元素 删除的是链表里的最后一个元素 remove(Object o) 这个删除就比较慢了，它是从头开始一一对比，时间复杂度为O(n)，这个删除也是只删除最早添加的数据 代码实现 List&lt;String&gt;&nbsp;list=new&nbsp;LinkedList&lt;&gt;();list.add(\"hui\");list.remove(\"hui\"); 源码解析 unlink()方法就是上面讲的那个 clear方法 clear() 代码实现 List&lt;String&gt;&nbsp;list=new&nbsp;LinkedList&lt;&gt;();list.add(\"hui\");list.clear(); 源码解析 总结 LinkedList里删除，添加操作一般就两个步骤，变换前后Node指向的地址，删除操作把对应Node里的三个变量都设置为null，方便GC回收。 如果要删除元素时，最好选择传入索引删除，他比直接传入要删除的对象的方法要快很多","categories":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/tags/Java/"},{"name":"源码分析","slug":"源码分析","permalink":"https://greycode.top/tags/%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"name":"LinkedList","slug":"LinkedList","permalink":"https://greycode.top/tags/LinkedList/"}]},{"title":"【源码解析】扒开ArrayList的外衣","slug":"java/java-arraylist-source-1","date":"2020-01-03T19:13:31.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"java/java-arraylist-source-1/","link":"","permalink":"https://greycode.top/java/java-arraylist-source-1/","excerpt":"","text":"积千里跬步，汇万里江河；每天进步一点点，终有一天将成大佬。 本文内容当然ArrayList里的方法不止这些，本文主要讲一些常用的方法 方法变量Arraylist里的方法变量主要有以下几个 构造方法有参构造传入数组的大小代码实现List&lt;String&gt; list=new ArrayList&lt;&gt;(5); 源码解析 传入一个list对象其实这个就相当于把传入的list对象里的数据复制到新的ArrayList对象 代码实现List&lt;String&gt; list=new ArrayList&lt;&gt;(Arrays.asList(&quot;z&quot;,&quot;m&quot;,&quot;h&quot;)); 这里用来Arrays工具类里的asList方法，它的源码里是直接返回一个List，有兴趣的可以去看看，这里就不介绍了 源码解析 无参构造这个比较简单，直接赋值一个空数组 代码实现List&lt;String&gt; list=new ArrayList&lt;&gt;(); 源码解析 add方法add一般常用的有两个方法，一个就是add(E e)在尾部添加数据，一个就是add(int index,E element)在指定位置插入元素 add(E e)这个是Arrayist的主要方法，平时用的也是最多的方法之一，所以源码比较复杂，比较长 代码实现List&lt;String&gt; list=new ArrayList&lt;&gt;();list.add(&quot;灰灰HK&quot;); 源码解析 ensureCapacityInternal(int minCapacity)确保数组容量充足 calculateCapacity(Object[] elementData, int minCapacity) 再回到ensureExplicitCapacity(int minCapacity)这个方法，这个方法先修改次数加1，然后判断size+1是不是比当前的数组容量大，如果比当前的数组容量大，则进行扩容操作，扩大容量为原数组的1.5倍 比如第二次调用add方法，此时size+1=2, elementData.length=10,为什么等于10呢？因为第一次默认把数组容量从0扩大到了10,这时size+1比elementData.length小，就不会进行扩容操作 grow(int minCapacity)扩容 这里调用Arrays.copyOf()方法进行复制操作，当进一步深入这个方法时，发现是由System.arraycopy()这个方法实现复制功能的，这个方法由native关键字修饰，表示不是由Java语言实现的，一般是c&#x2F;cpp实现 小结到这里，add的方法流程就走完了，其核心步骤： 每次添加元素时判断数组容量是否充足 第一次添加元素，把数组容量扩容到10 扩容时，除第一次，以后的每次扩容为原大小的1.5倍 扩容后调用System.arraycopy()方法把原数组的元素复制到扩容后的新数组 add(int index, E element)该方法为在指定位置插入元素，该位置及后面所有元素后移 代码实现List&lt;String&gt; list=new ArrayList&lt;&gt;();list.add(&quot;hk&quot;);list.add(0,&quot;灰灰&quot;); 源码解析 可以看到，这边又用到了System.arraycopy()这个方法 rangeCheckForAdd(int index)判断是否越界 这里他是和size对比，而不是和数组的length对比，我个人认为这样第一节省了空间，第二方便后面移动的操作 System.arraycopy()拷贝数组 public static native void arraycopy(Object src, int srcPos, Object dest, int destPos, int length) src 原数组对象 srcPos 原数组起始位置 dest 目标数组 destPos 目标数组起始位置 length 复制多少个数据 小结插入方法其主要步骤如下: 检查插入的位置是否越界 检查数组容量是否充足，不充足进行扩容相关操作 调用System.arraycopy()进行index及后面的元素后移 get方法get(int index)代码实现List&lt;String&gt; list=new ArrayList&lt;&gt;();list.add(&quot;hk&quot;);list.get(0); 源码解析 rangeCheck(int index)判断是否越界 get个add方法判断越界的方法是不一样的，这边是index&gt;=size,多了个等于，为什么要多个等于呢？因为数组是从0开始的，而size相当于是开始的从1开始的 private void rangeCheck(int index) &#123; if (index &gt;= size) throw new IndexOutOfBoundsException(outOfBoundsMsg(index));&#125; elementData(int index)直接返回对应下标的数组元素 E elementData(int index) &#123; return (E) elementData[index];&#125; 小结get方法比较简单，主要步骤为： 检查是否越界 返回对应元素 set方法set(int index, E element)代码实现List&lt;String&gt; list=new ArrayList&lt;&gt;();list.add(&quot;hk&quot;);list.set(0,&quot;灰灰&quot;); 源码解析 remove方法remove(int index)代码实现List&lt;String&gt; list=new ArrayList&lt;&gt;();list.add(&quot;hk&quot;);list.remove(0); 源码解析 当删除的元素为最后一个元素时，numMoved就小于0了，就不会进行移动元素的操作 remove(Object o) 这个方法在实际中用的比较少，因为AraryList是可以保存重复的元素，所以删除是删除最早添加的元素 代码实现List&lt;String&gt; list=new ArrayList&lt;&gt;();list.add(&quot;hk&quot;);list.remove(&quot;hk&quot;); 源码解析 fastRemove(int index)删除元素 这个方法和remove(int index)内部的操作类似，不过这边不保存被删除的元素 private void fastRemove(int index) &#123; modCount++; int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work&#125; clear方法clear()代码实现List&lt;String&gt; list=new ArrayList&lt;&gt;();list.add(&quot;hk&quot;);list.clear(); 源码分析 总结ArrayList底层扩容或者移动数组元素时都调用了System.arraycopy()来进行相关操作，平时进行我们进行数组复制或移动的时候也可以调用这个方法了，这个性能比循环复制性能高多了，特别是在大量数据的时候。 文章好几次出现了modCount++这个操作，这个modCount主要用户内部类的迭代器","categories":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/tags/Java/"},{"name":"ArrayList","slug":"ArrayList","permalink":"https://greycode.top/tags/ArrayList/"},{"name":"源码解析","slug":"源码解析","permalink":"https://greycode.top/tags/%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/"}]},{"title":"【图】用图片告诉你Java中的位运算","slug":"java/java-base-wei","date":"2019-12-30T22:17:30.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"java/java-base-wei/","link":"","permalink":"https://greycode.top/java/java-base-wei/","excerpt":"","text":"前言​ 虽然位运算在实际开发中并不常用,但是在各种算法中却常常见到它们的身影.因为是直接操作二进制的,所以机器执行起来就快很多,所以尽管实际业务中不常用,但如果你不想只做个码农,这个基础还是要掌握的; 讲位操作之前,就必须要知道原码、反码、补码 其中正数的原码&#x3D;反码&#x3D;补码 原码、反码、补码 在机器的内存中,一个负数的表示是这个负数的绝对值取原码,再取反码,再加一,最后出现的就是这个负数在内存中的表示的二进制数值 比如说-9在内存中的二进制码,这里用8位表示: 最后-9在内存中的二进制值为11110111 在二进制中,最高位为符号位,0代表正,1代表负 位运算左移和右移在Java中的int类型有4字节,一个字节有8位,所以这边用32位表示一个数 负数的左移和右移 这边负数表示是在内存中表示的二进制值 右移时:最高位补符号位1 左移时:末尾补0 正数的左移和右移 右移时:最高位补符号位0 左移时:末尾补0 无符号右移 无论是正数还是负数,右移最高位一律补0 &amp;(位与) 当相对应的位都为1时,等于1,否则等于0 为了方便表示,接下来全部都用8位表示一个数 |(位或) 当相对应的位有一个为1时,等于1,否则等于0 ^(异或) 当相对应的位不同时,等于1,相同时等于0 ~(取反) 1等于0,0等于1 总结 含义 运算符 说明 左移 &lt;&lt; 末尾补0 右移 &gt;&gt; 负数:最高位补符号位1 正数:最高位补符号位0 无符号右移 &gt;&gt;&gt; 无论是正数还是负数,右移最高位一律补0 &amp;(位与) &amp; 当相对应的位都为1时,等于1,否则等于0 |(位或) | 当相对应的位有一个为1时,等于1,否则等于0 ^(异或) ^ 当相对应的位 不同时,等于1 相同时,等于0 ~(取反) ~ 1等于0,0等于1 最后有个小技巧,向左位移几位就是乘以2的几次方,比如9向左移n位,就是 $$9向左移n位&#x3D;9*2^n$$ 向右移几位就是除以2的几次方然后向下取整,比如9向右移动n位,就是 $$9向右移n位&#x3D;⌊9&#x2F;2^n⌋$$ 注:⌊⌋是数学符号向下取整,例如:2.25向下取整是2; -2.25向下取整是-3; 具体的话可以看看这篇文章向上取整与向下取整函数;该技巧不适用无符号右移","categories":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/tags/Java/"}]},{"title":"设计模式之建造者模式【用好玩的故事讲清楚设计模式】","slug":"gof/gof-builder","date":"2019-12-27T06:50:31.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"gof/gof-builder/","link":"","permalink":"https://greycode.top/gof/gof-builder/","excerpt":"","text":"积千里跬步,汇万里江河;每天进步一点点,终有一天将成大佬 所有源代码都在这:https://github.com/z573419235/GofDemo 各位大佬记得点个星星哦 前言建造者模式用于实例化一个比较复杂的实体类,当你实例化一个类时,它的构造参数比较多时,就可以用建造者模式来简化实例化过程;前几篇工厂模式的文章我们说道买车,那只是简单的区工厂买车,我们不关系工厂是怎么造出来的.可是实际工厂造一辆车需要有方向盘、发动机、车架、轮胎等部件,而且不同品牌的车的部件都是不同的,部件虽然不同,但是造车的方式基本都是差不多的步骤,这时候就可以用建造者模式来造一辆车了; 建造者（Builder）模式由产品、抽象建造者、具体建造者、指挥者等 4 个要素构成 土豪朋友开车厂 土豪朋友上次买了车之后,发现造车卖还挺赚钱,于是决定涉足汽车领域,真是很有商业头脑啊,不愧是我的玉树临风,疯言疯语,语速惊人,人模狗样的土豪朋友啊. 一天,前去向他讨教汽车的知识,他给我讲了汽车的大致构成: /** * 汽车 产品类 定义汽车的构成 * */@Datapublic class Car &#123; /** * 方向盘 * */ private String steering; /** * 发动机 * */ private String engine; /** * 车架 * */ private String frame; /** * 轮胎 * */ private String tire; /** * 展示一下汽车配置 * */ public String show() &#123; return &quot;&#123;&quot; + &quot;steering=&#x27;&quot; + steering + &#x27;\\&#x27;&#x27; + &quot;, engine=&#x27;&quot; + engine + &#x27;\\&#x27;&#x27; + &quot;, frame=&#x27;&quot; + frame + &#x27;\\&#x27;&#x27; + &quot;, tire=&#x27;&quot; + tire + &#x27;\\&#x27;&#x27; + &#x27;&#125;&#x27;; &#125;&#125; 果真是大致啊,忽悠我不懂车是吧,就给我讲4个东西,这谁不知道啊,哼!土豪朋友忙解释到:这不是为了通俗易懂嘛!!哈哈哈—土豪朋友尴尬而不失礼貌的笑着! 算了算了,不和你计较了,你再和我讲下你们车厂的造车模式吧!!他说,一开始他造车自己累的半死,什么都要亲力亲为,后来招了两个专家,一个负责宝马的制造,一个负责奔驰的制造,我现在要什么车,只要指挥谁造车就好了.轻松的很; 他给我介绍了一下他的两个专家: /** * 宝马车建造者 * */public class BMWBuilder extends AbstractBuild &#123; @Override void buildEngine() &#123; car.setEngine(&quot;宝马的发动机&quot;); &#125; @Override void buildSteering() &#123; car.setSteering(&quot;宝马的方向盘&quot;); &#125; @Override void buildFrame() &#123; car.setFrame(&quot;宝马的车架&quot;); &#125; @Override void buildTire() &#123; car.setTire(&quot;宝马的轮胎&quot;); &#125;&#125; /** * 奔驰车建造者 * */public class BenzBuilder extends AbstractBuild &#123; @Override void buildEngine() &#123; car.setEngine(&quot;奔驰的发动机&quot;); &#125; @Override void buildSteering() &#123; car.setSteering(&quot;奔驰的方向盘&quot;); &#125; @Override void buildFrame() &#123; car.setFrame(&quot;奔驰的车架&quot;); &#125; @Override void buildTire() &#123; car.setTire(&quot;奔驰的轮胎&quot;); &#125;&#125; 他们两个都遵循下面这个AbstractBuild汽车的建造规则: /** * 抽象建造者 定义造车的方法 * */abstract class AbstractBuild &#123; /** * 造的产品是车 * */ protected Car car=new Car(); /** * 造发动机 * */ abstract void buildEngine(); /** * 造轮胎 * */ abstract void buildSteering(); /** * 造车架 * */ abstract void buildFrame(); /** * 造轮胎 * */ abstract void buildTire(); /** * 得到造好的车 * */ public Car getCar()&#123; return this.car; &#125;&#125; 土豪朋友还跟我讲了是怎么指挥他们造车的: /** * 所有的建造者要听这个包工头的话,叫你造什么就造什么 * */public class Boss &#123; public static Car builderCar(AbstractBuild build)&#123; build.buildEngine(); build.buildFrame(); build.buildSteering(); build.buildTire(); return build.getCar(); &#125;&#125; 经过他这一翻显摆之后,感觉虽然长的人摸狗样的,干起事来还真是一套一套的,哈哈哈哈!! 说完,还向我展示了汽车是怎样造成的……….. 总结其实建造者模式和工厂模式还是挺像的,建造者模式里的建造者就相当于工厂模式里的工厂,不过建造者的核心是可以控制顺序,比如上面的土豪老板可以控制建造工人的建造顺序,可以控制他们是先造轮胎还是先造发动机,这才是建造者模式意义; 建造者模式如果和模板方法模式搭配起来,建造工人那个类封装一个模板方法开放给老板,老板就可以直接控制这个类就可以了,那这就和工厂模式没什么两样了","categories":[{"name":"GOF","slug":"GOF","permalink":"https://greycode.top/categories/GOF/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://greycode.top/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"建造者模式","slug":"建造者模式","permalink":"https://greycode.top/tags/%E5%BB%BA%E9%80%A0%E8%80%85%E6%A8%A1%E5%BC%8F/"}]},{"title":"一个故事一个模式-原型模式","slug":"gof/gof-prototype","date":"2019-12-25T23:34:48.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"gof/gof-prototype/","link":"","permalink":"https://greycode.top/gof/gof-prototype/","excerpt":"","text":"积千里跬步,汇万里江河;每天进步一点点,终有一天将成大佬 所有源代码都在这:https://github.com/z573419235/GofDemo 各位大佬记得点个星星哦 前言 前几天生病了,每天头昏脑胀的,诶,生病的时候才知道身体健康的重要性,以后还是要加强锻炼,身体是革命的本钱; 隔了差不多有五六天没写日志了,罪过罪过;好了,今天要说的是原型模式,原型模式在`Java`中核心秘密就是`clone`这个方法,通过重新`Object`中的`clone`方法.来达到原型模式;而要重新`clone`方法就必须要实现`Cloneable`这个接口,不实现这个接口的话就会报`java.lang.CloneNotSupportedException`异常; 我是鸣人 鸣人最喜欢的就是吃拉面,就算是上课的时候也是心心念念的想着一乐大叔的拉面 先来看看鸣人的原型实体类: /** * @author zheng * * 我是鸣人实体类 */@Datapublic class Naruto implements Cloneable&#123; /** * 姓名 * */ private String name=&quot;鸣人&quot;; /** * 年龄 * */ private int age=13; /** * 任务 * */ private String task; /** *爱好 * */ private ArrayList&lt;String&gt; hobby=new ArrayList&lt;&gt;(); /** * 构造方法 * */ public Naruto()&#123; this.hobby.add(&quot;吃拉面&quot;); this.hobby.add(&quot;泡温泉&quot;); &#125; /** * 重写Object类的clone方法 * */ @Override public Naruto clone()&#123; Naruto naruto=null; try &#123; naruto=(Naruto)super.clone(); &#125; catch (CloneNotSupportedException e) &#123; e.printStackTrace(); &#125; return naruto; &#125; @Override public String toString() &#123; return &quot;Naruto&#123;&quot; + &quot;name=&#x27;&quot; + name + &#x27;\\&#x27;&#x27; + &quot;, age=&#x27;&quot; + age + &#x27;\\&#x27;&#x27; + &quot;, task=&#x27;&quot; + task + &#x27;\\&#x27;&#x27; + &quot;, hobby=&quot; + hobby + &#x27;&#125;&#x27;; &#125;&#125; 为了代码整洁,我安装了lombok插件,所以不用写get&#x2F;set方法,直接加个@Data注解就可以了; 一天,鸣人上着伊鲁卡老师的课,可是心里还是念念不忘一乐大叔的拉面,想着前几天刚学了影分身之术,想着用分身术逃出去吃拉面.于是他就有变了一个分身留着这上课,自己却跑去吃拉面了; /** * 原型模式 * @author zheng * */public class Main &#123; public static void main(String[] args) &#123; //我是鸣人本人 Naruto naruto=new Naruto(); //我是影分身 Naruto narutoYin=naruto.clone(); narutoYin.setTask(&quot;上课&quot;); naruto.setTask(&quot;吃拉面&quot;); System.out.println(&quot;鸣人本人:&quot;+naruto.toString()); System.out.println(&quot;影分身:&quot;+narutoYin.toString()); &#125;&#125;//控制台输出鸣人本人:Naruto&#123;name=&#x27;鸣人&#x27;, age=&#x27;13&#x27;, task=&#x27;吃拉面&#x27;, hobby=[吃拉面, 泡温泉]&#125;影分身:Naruto&#123;name=&#x27;鸣人&#x27;, age=&#x27;13&#x27;, task=&#x27;上课&#x27;, hobby=[吃拉面, 泡温泉]&#125; 可以看到,鸣人本人的任务是去吃拉面,他的影分身的任务是留着教室上课;当然鸣人可以通过他本人创建无数个影分身,同时执行多个任务;这就是原型模式; 浅拷贝和深拷贝原型模式就是通过一个原型clone出多个和原型一样的类,但是拷贝也分浅拷贝和深拷贝; 浅拷贝 浅拷贝有多浅,浅到就相当于没有给你拷贝,他就是让你和原型共用一个空间,没有给你分配新的内存; 比如上面的鸣人本人有爱好,但是隐分身一般是没有爱好的,所以创建隐分身要吧爱好给清除调: /** * 原型模式 * @author zheng * */public class Main &#123; public static void main(String[] args) &#123; //我是鸣人本人 Naruto naruto=new Naruto(); //我是影分身 Naruto narutoYin=naruto.clone(); narutoYin.setTask(&quot;上课&quot;); //影分身不配有爱好 narutoYin.getHobby().clear(); naruto.setTask(&quot;吃拉面&quot;); System.out.println(&quot;鸣人本人:&quot;+naruto.toString()); System.out.println(&quot;影分身:&quot;+narutoYin.toString()); &#125;&#125;//控制台输出鸣人本人:Naruto&#123;name=&#x27;鸣人&#x27;, age=&#x27;13&#x27;, task=&#x27;吃拉面&#x27;, hobby=[]&#125;影分身:Naruto&#123;name=&#x27;鸣人&#x27;, age=&#x27;13&#x27;, task=&#x27;上课&#x27;, hobby=[]&#125; WTF,竟然把本人的爱好也清除调了,那还去吃啥拉面啊,算了算了,安安心心上课吧,诶;叫你上影分身课是时候不认真,失败了吧!!! 深拷贝 深拷贝就是在clone方法里除了克隆类之外,还要克隆引用对象,这样才会重新给引用对象分配新的内存空间 进过上次的教训,鸣人苦练影分身之术,终于学得核心所在,看看他新的影分身技能吧: 在变一个看看: /** * 原型模式 * @author zheng * */public class Main &#123; public static void main(String[] args) &#123; //我是鸣人本人 Naruto naruto=new Naruto(); //我是影分身 Naruto narutoYin=naruto.clone(); narutoYin.setTask(&quot;上课&quot;); //影分身不配有爱好 narutoYin.getHobby().clear(); naruto.setTask(&quot;吃拉面&quot;); System.out.println(&quot;鸣人本人:&quot;+naruto.toString()); System.out.println(&quot;影分身:&quot;+narutoYin.toString()); &#125;&#125;//控制台输出鸣人本人:Naruto&#123;name=&#x27;鸣人&#x27;, age=&#x27;13&#x27;, task=&#x27;吃拉面&#x27;, hobby=[吃拉面, 泡温泉]&#125;影分身:Naruto&#123;name=&#x27;鸣人&#x27;, age=&#x27;13&#x27;, task=&#x27;上课&#x27;, hobby=[]&#125; 哈哈,成功了,这下可以安安心心的区吃拉面了吧; 总结 引用设计模式之禅的一句话:内部的数组和引用对象才不拷贝，其他的原始类型比如`int`、`long`、`char`等都会被拷贝，但是对于`String`类型，`Java`就希望你把它认为是基本类型，它是没有clone方法的，处理机制也比较特殊，通过字符串池（stringpool）在需要的时候才在内存中创建新的字符串，在使用的时候就把`String`当做基本类使用即可。注意:&lt;font color=orange&gt;使用clone方法，在类的成员变量上就不要增加final关键字,否则当你重新设置这个成员变量的值时是不能设置的,因为final的不可变的,只能引用原来的值&lt;/font&gt;","categories":[{"name":"GOF","slug":"GOF","permalink":"https://greycode.top/categories/GOF/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://greycode.top/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"原型模式","slug":"原型模式","permalink":"https://greycode.top/tags/%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F/"}]},{"title":"更新驱动到mysql-connector-java-8遇到的一些问题","slug":"mysql/mysql-update-driver-connector-8","date":"2019-12-25T17:07:12.000Z","updated":"2022-04-16T02:52:58.653Z","comments":true,"path":"mysql/mysql-update-driver-connector-8/","link":"","permalink":"https://greycode.top/mysql/mysql-update-driver-connector-8/","excerpt":"","text":"更新驱动到mysql-connector-java-8遇到的一些问题问题POM&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;8.0.16&lt;/version&gt;&lt;/dependency&gt; application.propertiesspring.datasource.driver-class-name=com.mysql.jdbc.Driver 项目是SpringBoot构建的,数据库版本是:MySQL5.7,用了mysql-connector-java-8来链接数据库,application.properties也配置成spring.datasource.driver-class-name=com.mysql.jdbc.Driver,中间遇到了几个问题; 问题一描述如上配置后,控制台报了一下错误: Loading class `com.mysql.jdbc.Driver&#x27;. This is deprecated. The new driver class is `com.mysql.cj.jdbc.Driver&#x27;. The driver is automatically registered via the SPI and manual loading of the driver class is generally unnecessary. 翻译过来后就是: 加载类 com.mysql.jdbc.Driver。 不推荐使用。 新的驱动程序类为 com.mysql.cj.jdbc.Driver。 通过SPI自动注册驱动程序，通常不需要手动加载驱动程序类。 解决根据提示,解决方法有两种: 更改application.properties文件 spring.datasource.driver-class-name=com.mysql.jdbc.Driver//改成下面这样spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver 去掉application.properties文件中的spring.datasource.driver-class-name,因为它说会通过SPI自动注册的; 问题二描述数据库的数据时间总是和实际时间差8个小时 解决在数据库url添加serverTimezone=GMT%2B8 spring.datasource.url=jdbc:mysql://10.25.0.01:3307/db?useUnicode=true&amp;autoReconnect=true&amp;characterEncoding=UTF-8&amp;serverTimezone=GMT%2B8 总结mysql-connector-java5.X的版本驱动名是:com.mysql.jdbc.Driver; 6.X及以上版本的驱动名是:com.mysql.cj.jdbc.Driver","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://greycode.top/categories/MySQL/"}],"tags":[{"name":"Pit","slug":"Pit","permalink":"https://greycode.top/tags/Pit/"},{"name":"MySQL","slug":"MySQL","permalink":"https://greycode.top/tags/MySQL/"}]},{"title":"Docker迁移根目录导致mysql权限问题","slug":"docker/docker-transfer-pit","date":"2019-12-20T15:04:16.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"docker/docker-transfer-pit/","link":"","permalink":"https://greycode.top/docker/docker-transfer-pit/","excerpt":"","text":"问题描述 最近由于公司服务器硬盘老是爆满，导致经常要清硬盘空间．最后发现&#x2F;var&#x2F;lib&#x2F;docker目录占了25G,以前分kvm分区的时候，他们分了两个区：根目录＂&#x2F;＂,和＂&#x2F;home＂目录，发现home目录使用几乎为零，于是准备迁移Docker的根目录： 迁移根目录我看的是这个文章：docker的存储目录迁移, 不过迁移的时候我没有使用rsync这个命令，而是使用cp -R; 文件复制过去后，按照教程，重新启动docker服务，可是其中mysql容器跑不起来了，报mysqld: Can’t create&#x2F;write to file ‘&#x2F;tmp&#x2F;ibTCv7Rw’ (Errcode: 13 - Permission denied) 期间按照网上的方法：说docker容器启动是添加–privileged&#x3D;true,设置&#x2F;tmp目录的权限，关闭selinux，这些方法都没用！！！！！！ 其中设置&#x2F;tmp文件权限这个方法，我把里面的&#x2F;tmp文件挂载出来后，设置了权限，报这个的问题是解决了，可是又出现了新的问题，又报Version: ‘5.7.27’ socket: ‘&#x2F;var&#x2F;run&#x2F;mysqld&#x2F;mysqld.sock’ 看来还是得从根源上解决问题啊！ 我的解决办法 我想，既然是权限问题，那肯定是复制文件的时候权限丢失了，于是查了下cp命令保持权限的命令（cp -p）: 于是我又重新关闭的docker服务，然后删除了所有复制到home文件的目录，重新用cp -p -R &#x2F;var&#x2F;lib&#x2F;docker &#x2F;home&#x2F;docker&#x2F;lib&#x2F;来重新复制了文件； 复制后，重启docker服务，启动docker容器，ok,一切正常；用docker info查看，看到已成功转移到&#x2F;home下．","categories":[{"name":"Docker","slug":"Docker","permalink":"https://greycode.top/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://greycode.top/tags/Docker/"},{"name":"Mysql","slug":"Mysql","permalink":"https://greycode.top/tags/Mysql/"},{"name":"Linux","slug":"Linux","permalink":"https://greycode.top/tags/Linux/"},{"name":"Pit","slug":"Pit","permalink":"https://greycode.top/tags/Pit/"}]},{"title":"设计模式系列-模板方法模式","slug":"gof/gof-taemplate-method","date":"2019-12-20T00:04:28.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"gof/gof-taemplate-method/","link":"","permalink":"https://greycode.top/gof/gof-taemplate-method/","excerpt":"","text":"积千里跬步，汇万里江河．每天进步一点点，终有一天将成大佬 文前常规发言 模板方法的设计符合迪米特法则，也就是最少知道原则，他通过对一些重复方法的封装，减少类之间的耦合，让调用者也更省心，原来要调两三个方法才能实现的功能，现在调一个就可以了；就像我们伟大的祖国，现在也在推行这种模式呢．以前区办一些证明什么的，要跑三四个地方，还要保证这三四个地方都正常帮你办理，如果其中一个地方没办理，那么整个流程就都作废了．现在好了，提倡最多跑一次，只要去一个地方办一次手续就可以了，你只要知道这个地方能办好就行，其他的就不用烦心了； 阿狗卖电脑 阿狗是一个三十五岁没了头发的年轻小伙，当问及为什么没了头发，阿狗摸摸头，眼里充满了悔恨的泪水；要不是小时候没听大人的话，长大了也不至于做程序员啊－－－阿狗唉声叹气的说道．听到这里，我仿佛已经知道了答案．当我问他为什么现在改行卖电脑了，他说外面的世界很大，想趁年轻，多闯闯（实则是被公司裁员，被迫来卖电脑了）； 看看他的电脑店里都有什么 /** * 阿狗电脑店 * */abstract class AGouShop &#123; /** *显卡 * */ abstract void xianKa(); /** *cpu * */ abstract void cpu(); /** *电源 * */ abstract void dianYuan(); /** *主板 * */ abstract void zhuBan(); /** *硬盘 * */ abstract void yingPan(); /** *内存条 * */ abstract void neiCun(); /** *机箱 * */ abstract void jiXiang();&#125; 还不错，该有的都有了．当我们正在店里逛着时，来了两个顾客，阿猫和大牛，他们都来到阿狗店电脑店，挑选的电脑配件，准备组装电脑． 看看阿猫： 在看看大牛的： 再看看他们怎么组装的吧： 有想法的阿狗 阿狗自从卖电脑后，发现头上的头发也慢慢的长了出来了，每天也更加自信了．一天，他发现客户有个痛点，就是买电脑要分别买好配件，然后再自己组装，有时候买的配件有问题，又要拿去换，导致费时费力．这时，阿狗头脑灵光一闪，想到了当年做程序员时的模板方法模式；何不把客户组装电脑的步骤自己承包，这样客户只要来买电脑时选下配件，我就帮他组装好给他．客户省心省力，到时候生意肯定好；于是他改造了他的电脑店： /** * 阿狗电脑店 * */abstract class AGouShop &#123; /** *显卡 * */ abstract void xianKa(); /** *cpu * */ abstract void cpu(); /** *电源 * */ abstract void dianYuan(); /** *主板 * */ abstract void zhuBan(); /** *硬盘 * */ abstract void yingPan(); /** *内存条 * */ abstract void neiCun(); /** *机箱 * */ abstract void jiXiang(); /** * 阿狗帮客户装电脑 * 模板方法 * */ public void zhuZHuang()&#123; System.out.println(&quot;阿狗开始组装电脑＝＝＝＝＝＝&quot;); this.cpu(); this.dianYuan(); this.neiCun(); this.xianKa(); this.yingPan(); this.zhuBan(); this.jiXiang(); System.out.println(&quot;阿狗电脑组装完成＝＝＝＝＝＝&quot;); &#125;&#125; 上次的阿猫又来买电脑了： 看看结果： 客户反馈 阿狗按照上面的模式运行后，缺少增加了不少客户，可是有的顾客却反应说，为什么一定要我选显卡啊，我又不玩游戏，而且我买的cpu有核显，可以不要我选显卡嘛？阿狗一听，这是个问题啊，遵照客户就是上帝的原则(有钱就赚原则)，于是他又改了他店铺的模式： /** * 阿狗电脑店 * */abstract class AGouShop &#123; /** * 显卡 * ＂具体方法＂ * */ protected void xianKa()&#123; System.out.println(&quot;客户选了显卡&quot;); &#125; /** * 是否要显卡 默认是要显卡的 * ＂钩子方法＂ * */ public boolean isTrue()&#123; return true; &#125; /** *cpu * */ abstract void cpu(); /** *电源 * */ abstract void dianYuan(); /** *主板 * */ abstract void zhuBan(); /** *硬盘 * */ abstract void yingPan(); /** *内存条 * */ abstract void neiCun(); /** *机箱 * */ abstract void jiXiang(); /** * 阿狗帮客户装电脑 * 模板方法 * */ public void zhuZHuang()&#123; System.out.println(&quot;阿狗开始组装电脑＝＝＝＝＝＝&quot;); this.cpu(); this.dianYuan(); this.neiCun(); //判断要不要显卡 if(this.isTrue()) &#123; this.xianKa(); &#125; this.yingPan(); this.zhuBan(); this.jiXiang(); System.out.println(&quot;阿狗电脑组装完成＝＝＝＝＝＝&quot;); &#125;&#125; 可以看到上加了具体方法和钩子方法 上上次的阿猫和大牛，又双来买电脑了－－－－－有钱真好： 阿猫默认要显卡： 大牛不要显卡： 看看他们的电脑吧： 总结一下下 上面对比了阿牛的三种买电脑模式 普通模式：自己只提供最基础的东西，所有的由客户自己去完成 自己帮客户完成组装电脑：这里就用到了模板方法模式，通过对自身方法的封装，使客户买电脑更轻松了 客户有选择显卡的权利：这里用到了模板方法模式中的钩子方法，通过客户暴露钩子方法，使其可以控制阿狗在装电脑是要不要装显卡这个步骤方法，钩子方法是模板方法模式的灵魂，有了它，这个模式才有更大的意义；","categories":[{"name":"GOF","slug":"GOF","permalink":"https://greycode.top/categories/GOF/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://greycode.top/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"模板方法模式","slug":"模板方法模式","permalink":"https://greycode.top/tags/%E6%A8%A1%E6%9D%BF%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F/"}]},{"title":"恍然大悟，数组和链表的区别","slug":"algorithm/array-vs-linked","date":"2019-12-18T13:50:52.000Z","updated":"2022-04-16T02:52:58.645Z","comments":true,"path":"algorithm/array-vs-linked/","link":"","permalink":"https://greycode.top/algorithm/array-vs-linked/","excerpt":"","text":"积千里跬步，汇万里江河．每天进步一点点，终有一天将成大佬 文前发言 在Java中，很多地方都使用了数组和链表，还有两种组合的叫数组链表结构，就是常说的哈希表，HashMap底层的数据结构就是哈希表．远了，远了，这里不讲HashMap,这里讲数组和链表； 数组 数组是我们平时用的最多的数据结构，它的特点是查询数据快，插入数据慢，查询的时间复杂度是O(1),插入的时间复杂度是O(n). 牛＊一族去学校读书，学校有四人寝和五人寝，大牛，二牛，三牛，四牛一同住进了四人寝里，每天都五缺一；有一天，他们在游戏里认识了小牛，得知小牛也是他们学校的，于是邀请小牛和他们一起住，可是他们们寝室只能住四个人，这个怎么办呢？于是他们向学校(系统)申请，要求学校给他们一个新的六人寝(新的内存空间)，于是学校就给了他们新的六人寝，于是他们全部都搬去了六人寝里，小牛也办了进去，之后每天五黑，好不快活； 之后有其他学生看到牛＊他们的做法，于是也通通向学校申请；最后学校发现了一个问题：就是学生们为了住进新寝室，花费了大量的时间在从旧寝室到新寝室的路上(插入数据慢) 有的人会说，那一开始就安排大牛，二牛，三牛，四牛住５人寝不就好了吗？这样他们就不用搬了(这就相当于我们初始化数组时，给数组指定了一个大小)；这样的想法是好的，但是如果他们没有没有认识小牛，小牛也不会搬进去，这样他们四个人就一直住着５人寝，就造成了空间资源浪费； 有一天，老师去找进入新寝室的小牛谈话，一看得知小牛在４号床，一下就找到了小牛（查询数据快），问他在这个寝室住的习不习惯，小牛心想，每天都五黑，你说我习不习惯！！ 链表 链表我们平时用的比较少，它的特点是:插入数据快，查询数据慢，查询的时间复杂度是：O(n)，插入的时间复杂度是：O(1)，它的特点是和数组相反的； 经过无数日夜的奋战，牛＊一寝人觉得是时候该出去玩玩了，自从小牛搬过来后，就一直没日没夜的五黑，都快不知道外面的世界长什么样子了；他们一行人准备去游乐园转转． 来到游乐园后，一群人像刚放出来的一样，对一切都充满了新鲜感，到处转悠．就在转悠的时候，细心的大牛发现了地上有一张纸条，打开一看，上面写着：＂少年，你渴望力量吗？想获得力量就来海盗船找我！＂，大牛赶紧找来其他小伙伴，一同前往；到了海盗船的地方，发现船上写着：＂力量源自摩天轮，请前往摩天轮＂，于是一群人就又前往摩天轮，在那里，终于过得了神秘力量－－－毒鸡汤：你的内心有多强大，你的力量就有多强大；小牛他们为了寻找这个力量，可谓费尽九牛二虎之力啊（查询数据慢）； 可以发现，每个元素存着下个元素的地址，所以如果要查找其中某个元素，就必须要从头开始，才能找到．这就比较慢了．但是，他们添加元素很快,元素可以随机出现在游乐园的某个地方，只要在新添加元素的前一个元素指明新元素的地址在哪里就可以了； 发个对比表格吧时间复杂度对比表 数组 链表 插入 O(n) 慢 O(1) 快 删除 O(n) 慢 O(1) 快 查询 O(1) 快 O(n) 慢","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"https://greycode.top/categories/Algorithm/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://greycode.top/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"设计模式系列-抽象工厂模式","slug":"gof/gof-abstract-factory","date":"2019-12-16T21:17:23.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"gof/gof-abstract-factory/","link":"","permalink":"https://greycode.top/gof/gof-abstract-factory/","excerpt":"","text":"积千里跬步，汇万里江河；每天进步一点点，终有一天将成大佬 突然开始的正文紧接着上一章的工厂方法模式，其实抽象工厂的概念和工厂方法的概念都是差不多的，抽象工厂模式是对工厂方法模式的更高级，比如上次我们说的那个汽车工厂总部类AllCarFactory，本来他只定义了生产汽车这个方法，下面的各个品牌的汽车厂也只能生产这个汽车，现在由于市场需求，需要生产摩托车，然后AllCarFactory定义了一个生产摩托车的接口，这样这个接口下面的汽车厂就可以生产摩托车了．就在这时他们的生产模式也从工厂方法模式升级到了抽象工厂模式； 话不多说，看两个模式的类图你就明白了： 原本的工厂方法模式类图： 升级后的抽象工厂模式： 可以看到，抽象工厂只是比工厂方法模式多生产了一个产品，当抽象工厂模式的产品减到只有一个的时候，他就又回到了工厂方法模式； 好色的朋友买车了上次我朋友看见我买车之后，得知是个小姐姐带我区买车的，于是他叫我联系了下那个小姐姐，说他也要买车，点名要叫小姐姐带他去，由于资金有限，他只卖了奔驰和五菱系列的产品，没有买莱斯莱斯的；看看他是怎么买的吧： 可以看到，由于要在一个工厂买两个东西，他是先找到了工厂，然后再一件一件的从工厂买．我们上次是一个工厂买一件东西，所以是直接去工厂买的； 措不及防的结束了 不是我不想讲，而是抽象工厂就是这样的东西．从上面可以看出，抽象工厂每当增加一个产品时，后面相关的的品牌工厂也全部要实现他这个产品，这就违背了开闭原则了．所以，在实际设计中，一个业务场景是稳定的,用抽象工厂是比较好的，因为一次设计,后面就不用改了,这样就不会违反开闭原则了．但是如果一个业务场景是稳定的是不稳定的，那么就不适合使用这个模式了，因为后期需要多次修改，这就违反了开闭原则，同时也及其难维护，应为你不知道修改了代码，到底会影响哪些功能；","categories":[{"name":"GOF","slug":"GOF","permalink":"https://greycode.top/categories/GOF/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://greycode.top/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"抽象工厂模式","slug":"抽象工厂模式","permalink":"https://greycode.top/tags/%E6%8A%BD%E8%B1%A1%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/"}]},{"title":"设计模式系列-工厂模式","slug":"gof/gof-factory-method","date":"2019-12-15T17:25:00.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"gof/gof-factory-method/","link":"","permalink":"https://greycode.top/gof/gof-factory-method/","excerpt":"","text":"积千里跬步，汇万里江河．每天进步一点点，终有一天将成大佬 前言工厂模式有一下三种 简单工厂模式 工厂方法模式 抽象工厂模式 其中简单工厂模式不在23中模式之中，更多的是一种编程习惯，而我们平常所说的工厂模式一般指的是工厂方法模式，抽象工厂在实际的业务开发中也用的比较少，因为它有时候违背了开闭原则．由于篇幅有限，抽象工厂本文就不讲了，以后单独讲； 简单工厂模式简单工厂到底有多简单呢？简单到只有一个工厂，这个工厂相当于是万能工厂，你想要什么，只要和它说一声，它就会想方设法的去抱你创建，然后给你；举个买车的简单的例子： 当我要买车的时候，我选了这两种车． /** * 创建一个汽车接口 * */public interface Car &#123; /** * 汽车能动 * */ void run();&#125; /** * 奔驰车 * */public class Benz implements Car &#123; @Override public void run() &#123; System.out.println(&quot;大奔开动了&quot;); &#125;&#125; /** * 五菱神车 * */public class Wuling implements Car &#123; @Override public void run() &#123; System.out.println(&quot;五菱神车开动了&quot;); &#125;&#125; 选是选好了，可是要怎么得到呢？是不是下意识的new一个出来？ //我要奔驰车Benz myCar=new Benz(); 如果是这样的话，就相当于自己亲手造了一辆奔驰车出来，因为是你自己new出来的嘛！！！！！ 这种事情当然是交给工厂去做嘛，叫工厂去new就可以了，我只要交钱给工厂就可以了．诶，有钱真好！ /** * 汽车工厂 * * 静态工厂 * * 简单工厂 * */public class CarFactory &#123; public static Car getCar(String type)&#123; if(&quot;我要五菱神车&quot;.equals(type))&#123; return new Wuling(); &#125; if (&quot;我要大奔驰&quot;.equals(type))&#123; return new Benz(); &#125; return null; &#125;&#125; 找到了这个工厂之后，我只要直接告诉它我要什么车就可以了，工厂就会帮我造好给我； /** * 买车 * */public class CostumerMain &#123; public static void main(String[] args) &#123; //跟车厂说一声我要五菱神车 Car wuling=CarFactory.getCar(&quot;我要五菱神车&quot;); //跟车厂说一声我要大奔驰 Car Benz=CarFactory.getCar(&quot;我要大奔驰&quot;); //开着五菱神车去兜兜风 wuling.run(); //开着大奔去兜兜风 Benz.run(); &#125;&#125;//五菱神车开动了//大奔开动了 这样子，买车就结束了，果然钱可以解决一切，哈哈，开个玩笑～ 工厂方法模式上次买了两辆车之后，白天开着大奔去街上撩妹，晚上开着五菱神车去秋名山飙车，从此走向了人生巅峰．可是好景不长，大奔开着开着就漏油了，五菱神车终于也翻车了． 找到了上次买车的工厂，准备换个低调点的劳斯莱斯．可是那家工厂竟然告诉我说他们那边还没有造过劳斯莱斯，需要改造一下工厂，然后才能生产劳斯莱斯，叫我等他们改造好之后再来买．听他们这麽说后，我心想，我这分分钟几百万上下的人，时间就是金钱．我可等不了． 于是几番寻找之后，发现英国有个劳斯莱斯车场，专门来生产劳斯莱斯．于是和接待我的中介小姐姐聊了一下，发现他们的生产模式是这样的： /** * 他们有个汽车工厂总部，用来定义车厂该干什么 * */public interface AllCarFactory &#123; /** * 生产汽车 */ Car getCar();&#125; /*** 有个汽车规则，用来定义汽车能干什么*/public interface Car &#123; /** * 汽车能跑 */ void run();&#125; /** * 劳斯莱斯汽车 * */public class RollsRoyce implements Car &#123; /** * 劳斯莱斯能跑起来 */ @Override public void run() &#123; System.out.println(&quot;劳斯莱斯开起来了！！&quot;); &#125;&#125; /** * 劳斯莱斯汽车工厂 * */public class RollsRoyceFactory implements AllCarFactory &#123; /** * 生产一辆劳斯莱斯 */ @Override public Car getCar() &#123; return new RollsRoyce(); &#125;&#125; 找到车厂后，我毫不犹豫和接待我的小姐姐说给我来一辆，小姐姐见我这么豪爽，准备再忽悠我买几辆车，不推荐我几辆车．．．．她知道我之前买了奔驰和五菱神车,和我说他们这边还有还有五菱车厂和奔驰车厂，都是专门用来造同一种车的．于是我就去参观了一下： /*** 五菱神车*/public class Wuling implements Car &#123; /** * 五菱神车能飙车 */ @Override public void run() &#123; System.out.println(&quot;五菱神车开动了&quot;); &#125;&#125; /** * 五菱神车工厂 * */public class WulingFactory implements AllCarFactory &#123; /** * 生产一辆五菱神车 */ @Override public Car getCar() &#123; return new Wuling(); &#125;&#125; 再区看看奔驰车厂： /*** 奔驰汽车*/public class Benz implements Car &#123; /** * 奔驰汽车能跑 */ @Override public void run() &#123; System.out.println(&quot;大奔开动了&quot;); &#125;&#125; /** * 奔驰汽车工厂 * */public class BenzFactory implements AllCarFactory &#123; /** * 生产一辆奔驰汽车 */ @Override public Car getCar() &#123; return new Benz(); &#125;&#125; 看完之后，感觉还可以，于是分别到三个工厂买了三辆车，然后高高兴兴的回家了： 看看我买车的过程： /** * 土豪买车记 * */public class CostumerMain &#123; public static void main(String[] args) &#123; //去五菱车厂买车 Car wuling=new WulingFactory().getCar(); //去奔驰车厂买车 Car benz=new BenzFactory().getCar(); //去劳斯莱斯车厂买车 Car rollsRoyce=new RollsRoyceFactory().getCar(); //开着三辆车去兜兜风 wuling.run(); benz.run(); rollsRoyce.run(); &#125;&#125;//五菱神车开动了//大奔开动了//劳斯莱斯开起来了！！ 总结买完车后，小姐姐还和我说他们这样的模式生产车的话有好多好处，比如一个车厂只要负责一种车的生产和售后，这样的话，生产效率就会比较高，赚的钱自然也多，同时每个车厂还可以举行不同活动，来吸引消费者，同时，你如果哪个品牌的车出现了问题了，直接去那辆车的工厂，基本上都能帮你解决问题，毕竟&lt;font color=orange&gt;术业有专攻&lt;/font&gt;，对比前一个工厂什么都造的万金油来说，深入一项技术比什么技术都懂好； 不过有时候，万金油工厂也挺好的，就是一站式服务，你要什么它都有，不用到处乱跑，省心省力．所以还是要根据什么行业来执行什么模式，这样才能利益最大化；","categories":[{"name":"GOF","slug":"GOF","permalink":"https://greycode.top/categories/GOF/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://greycode.top/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"工厂方法模式","slug":"工厂方法模式","permalink":"https://greycode.top/tags/%E5%B7%A5%E5%8E%82%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F/"}]},{"title":"OOP程序七大原则","slug":"gof/gof-oop-7-all","date":"2019-12-15T10:45:04.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"gof/gof-oop-7-all/","link":"","permalink":"https://greycode.top/gof/gof-oop-7-all/","excerpt":"","text":"开闭原则开闭原则相当于所有原则的祖先，主张对修改关闭，对拓展开放． 里氏替换原则当两个类有继承关系时，子类不能修改父类的方法和变量. 里氏替换中的替换指的是：当有父类出现的地方，这个父类可以替换成子类，而且对程序没有影响，这就遵循了里氏替换原则；当替换成子类时对程序有影响，说明子类修改了父类的方法，就没有遵循里氏替换原则了； 依赖倒置原则依赖倒置原则是对开闭原则的一个实现，也是主张对拓展开放，对修改关闭．它的核心思想是面对接口编程，不要面对具体实现编程． 这是一个遵守依赖倒置原则的UML图，原来的话当客户购买商品时,shopping这个方法要传入相应的网店进去，当要更改店铺时，就要修改Cusromer这个类里的shopping方法，而现在，只要定义一个Shop接口，所有的店铺都实现这个接口的方法，顾客类的shopping方法只要传入Shop这个接口类就可以了．然后具体实现的时候，要到哪里买，就传入哪一个网店就可以了，而不用修改Cusromer这个类的方法； //代码来之＇C语言中文网＇public class DIPtest&#123; public static void main(String[] args) &#123; Customer wang=new Customer(); System.out.println(&quot;顾客购买以下商品：&quot;); wang.shopping(new ShaoguanShop()); wang.shopping(new WuyuanShop()); &#125;&#125;//商店interface Shop&#123; public String sell(); //卖&#125;//韶关网店class ShaoguanShop implements Shop&#123; public String sell() &#123; return &quot;韶关土特产：香菇、木耳……&quot;; &#125; &#125;//婺源网店class WuyuanShop implements Shop&#123; public String sell() &#123; return &quot;婺源土特产：绿茶、酒糟鱼……&quot;; &#125;&#125; //顾客class Customer&#123; public void shopping(Shop shop) &#123; //购物 System.out.println(shop.sell()); &#125;&#125;//输出顾客购买以下商品：韶关土特产：香菇、木耳……婺源土特产：绿茶、酒糟鱼…… 单一职责单一职责要求一个类只负责一项职责. 这个听起来很简单，但是实际应用上却非常的难把握．因为这个职责在中国是非常抽象的概念，中国是一个文化底蕴非常丰富的国家，就像&lt;&lt;设计模式之禅&gt;&gt; 这本书里所说的例子：比如说中国的筷子，他既可以当刀来分割食物，也可以当叉子来叉取食物，而在国外，叉子就是叉子，用来取食物的，刀就是用来分割食物的；所以这个单一职责要求软件开发人员有非常丰富的实践经验．不然很难把握； 迪米特法则迪米特法则也称最小知道原则，一个类对外暴露的东西越少越好． 从依赖者的角度来说，只依赖应该依赖的对象。 从被依赖者的角度说，只暴露应该暴露的方法。 个人理解：当A类需要调用B类的三个方法才能实现的功能时,B类可以对这三个方法进行一个封装，然后只暴露封装的这个方法给A,这样A就只需要调用B的这个封装的方法就可以了，当B的三个方法中有修改的时候，只要修改B这个对外封装的方法就可以，而Ａ调用者却不用改变，因为Ａ只知道调用这个方法可以实现功能，而不用具体管Ｂ内部是怎么实现的，降低了程序的耦合度； 接口隔离原则这个和单一职责有点类似，不过还是不一样的． 单一职责原则注重的是职责，而接口隔离原则注重的是对接口依赖的隔离。 单一职责原则主要是约束类，它针对的是程序中的实现和细节；接口隔离原则主要约束接口，主要针对抽象和程序整体框架的构建。 官方定义：要求程序员尽量将臃肿庞大的接口拆分成更小的和更具体的接口，让接口中只包含客户感兴趣的方法，降低程序耦合度。 这个法则也要根据实际的业务场景来应用，如果粒度控制的太小，就会导致类的急剧增加，明明一个功能只要三四个类，如果粒度小的话，就会变成十几个，甚至几十个，虽然这样程序耦合度低，比较灵活，但是维护难啊．如果粒度大，耦合度就会高，程序不灵活．所以这个原则要求技术人员有足够的实践，经验和领悟； 合成复用原则它要求在软件复用时，要尽量先使用组合或者聚合等关联关系来实现，其次才考虑使用继承关系来实现。如果要使用继承关系，则必须严格遵循里氏替换原则。合成复用原则同里氏替换原则相辅相成的，两者都是开闭原则的具体实现规范。 如果不了解什么是组合和聚合的话可以看看这个篇文章&lt;&lt;组合、聚合与继承的爱恨情仇&gt;&gt;,讲的挺好的 总结在程序设计中，尽量遵循OOP七大原则．不过有句话说的好，规则是死的，人是活的．意思是这七大原则有时候也不是万能的，有时候有的业务场景如果遵循了这些原则，反而变得难维护，所以一切都要从实际出发，23种设计模式也是一样，不要按死规则来．","categories":[{"name":"GOF","slug":"GOF","permalink":"https://greycode.top/categories/GOF/"}],"tags":[{"name":"GOF","slug":"GOF","permalink":"https://greycode.top/tags/GOF/"},{"name":"OOP","slug":"OOP","permalink":"https://greycode.top/tags/OOP/"}]},{"title":"Jenkins教程-集成SonarQube","slug":"jenkins/build-jenkins-sonarqube","date":"2019-12-13T15:38:02.000Z","updated":"2022-04-16T02:52:58.653Z","comments":true,"path":"jenkins/build-jenkins-sonarqube/","link":"","permalink":"https://greycode.top/jenkins/build-jenkins-sonarqube/","excerpt":"","text":"什么是SonarQube?看看维基百科的说明： SonarQube与CI&#x2F;CD架构图 Docker运行SonarQube简单了解之后，开始安装SonarQube.这里用Docker安装 注：这里用mysql来存储SonarQube的数据，SonarQube7.9起已经不在支持mysql了，可以安装官方推荐的PostgreSQL SonarQube 6.7.7 Docker-CE 19.03.1 Mysql 5.7 安装直接运行这个docker命令来安装，网上其他的教程有什么挂载文件什么的，我试了都会安装失败，原因还是因为权限原因，因为SonarQube不是以root用户运行的，导致没权限读写挂载出来的文件夹． 注意：创建容器前一定要先保证你连的容器有对应的数据库 docker run -d --name sonarqube -p 9099:9000 -p 9092:9092 --link=dev_mysql:mysql -e SONARQUBE_JDBC_USERNAME=app -e SONARQUBE_JDBC_PASSWORD=app -e SONARQUBE_JDBC_URL=&quot;jdbc:mysql://mysql:3306/sonar?useUnicode=true&amp;characterEncoding=utf8&amp;rewriteBatchedStatements=true&amp;useConfigs=maxPerformance&amp;useSSL=false&quot; --restart=always sonarqube:6.7.7-community –link&#x3D;dev_mysql:mysql 这个命令我链接到了我的mysql容器，dev_mysql是容器的名字，mysql是在SonarQube容器里的别名，所以链接数据库时直接用mysql这个别名就可了． SONARQUBE_JDBC_USERNAME ：数据库的账户 SONARQUBE_JDBC_PASSWORD ：数据库密码 访问安装好后直接访问9099端口，登录的账户和密码默认都是admin．首页就是这个样子的． Jenkins集成SonarQubeJenkins和SonarQube都是运行在Docker容器里的 下载和安装插件直接下载最新版的，然后导入，导入的方法可以看插件导入方法 插件下载地址：https://updates.jenkins.io/download/plugins/sonar/ SonarQube生成Token进入SonarQube管理界面 Administration-&gt;Security-&gt;Users 然后随便输入一个名字，点击生成，记下Token 添加全局凭证类型选Secret text,然后Secret和ID输入框都填入刚才生成的Token 设置SonarQube servers进入 系统管理-&gt;系统设置-&gt;SonarQube servers 设置好后点保存 因为我SonarQube和Jenkins安装在同一台机器不同的Docker容器里的,所以这里URL直接填SonarQube的Docker容器的IP和端口 安装SonarQube Scanner下载压缩包 下载SonarQube Scanner压缩包：SonarQube Scanner 解压到Jenkins挂载出来的目录里只有解压到挂载出来的Jenkins的目录里，Docker容器安装的Jenkins才能读取到,我这里是宿主机的&#x2F;opt&#x2F;jenkins挂载到了Jenkins容器里的&#x2F;var&#x2F;jenkins_home目录上，所以我只要解压到宿主机的&#x2F;opt&#x2F;jenkins目录中就可以了 Jenkins配置全局工具进入 系统管理-&gt;全局工具配置-&gt;SonarQube Scanner 找到模块后点击新增SonarQube Scanner SONAR_RUNNER_HOME填你Jenkins这个Docker容器里的路径 构建一个Maven项目网上很多教程说要勾上这个选项： 其实这个是可选的，下面有一句话：These variables are useful when configuring a SonarQube analysis using standard build steps such as Maven, Gradle, Ant, and command line scripts.This feature is not needed if you’re using “SonarQube Scanner” or “SonarScanner for MSBuild” build steps. 翻译过来就是：因为我们这里用的就是SonarQube Scanner,所以这个我们是可以不用勾上的，但是勾上也没影响； 开始构建 具体怎么构建项目可以看：Jenkins教程-创建Maven项目,这里就不多介绍了 添加Execute SonarQube Scanner在原来构建的基础上加上Execute SonarQube Scanner，就可以了 在Analysis properties里填上构建的参数 唯一的项目标识符（必填）sonar.projectKey &#x3D;tiny-config1 项目元数据（以前是必需的，自SonarQube 6.1起是可选的）sonar.projectName &#x3D;tiny-config1sonar.projectVersion &#x3D; 1.0 源目录的路径（必需）sonar.sources &#x3D; srcDir1，srcDir2 测试源目录的路径（可选）sonar.tests &#x3D; testDir1，testDir2 Java项目编译类的路径（可选）sonar.java.binaries &#x3D; bin 逗号分隔的库路径列表（可选）sonar.java.libraries &#x3D; path &#x2F; to &#x2F; library.jar，path &#x2F; to &#x2F; classes &#x2F; dir 附加参数sonar.my.property &#x3D;value 保存后就可以正常构建了． 错误解决（没有错误可跳过这段）如果在构建项目的时候,Jenkins控制台如果报一下错误，这是因为SonarQube的Java版本太低造成的 升级SonarQube的Java版本进入SonarQube的管理台： Administration-&gt;Marketplace-&gt;SonarJava 如果你版本没升级，右边会有个update按钮，点击就可以升级了，升级完后重启SonarQube;这边因为我已经升级过了，所以没有这个按钮 构建完成后Jenkins控制台显示SUCCESS就表示构建成功了 这时候就可以点击构建项目的SonarQube直接跳转到SonarQube控制台了 这里就可以看到结果了 总结到这里就可以根据SonarQube的提示区改BUG了．这BUG有点多＝＿＝！. 在搭建过程中，最主要的就是那个SonarQube Scanner这个的安装了，因为Jenkins都是Docker化的，所以他可以选择自动安装，但是我这边选择自动安装却没用，所以就自己下载了SonarQube Scnner的包挂载到Jenkins容器里区，然后直接指定SonarQube Scnner的目录就可以了；","categories":[{"name":"Jenkins","slug":"Jenkins","permalink":"https://greycode.top/categories/Jenkins/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://greycode.top/tags/Docker/"},{"name":"Jenkins","slug":"Jenkins","permalink":"https://greycode.top/tags/Jenkins/"},{"name":"SonarQube","slug":"SonarQube","permalink":"https://greycode.top/tags/SonarQube/"}]},{"title":"Java8 Stream方法大全","slug":"java/java-8-stream-method","date":"2019-12-10T09:53:34.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"java/java-8-stream-method/","link":"","permalink":"https://greycode.top/java/java-8-stream-method/","excerpt":"","text":"","categories":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/tags/Java/"}]},{"title":"Java数组的几种初始化方式","slug":"java/java-array-init","date":"2019-12-09T10:22:12.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"java/java-array-init/","link":"","permalink":"https://greycode.top/java/java-array-init/","excerpt":"","text":"一维数组初始化容量/*** 定义容量为5,初始值为0的int一维数组*/int array[]=new int[5];int[] array2=new int[5]; 初始化值/*** 初始化一维容量为5的一维数组的值*/int[] array10=&#123;1,2,3,4,5&#125;;int aray12[]=&#123;1,2,3,4,5&#125;; 二维数组 二维数组初始化时必须要声明行数,列数可随意 初始化容量 声明了列数的 /*** 初始化一个5行5列的二维数组*/int[][] array3=new int[5][5];int []array4[]=new int[5][5];int array5[][]=new int[5][5]; 未声明列数的 此种方法初始化后如果要赋值的话要new一个数组,如果按照常规的方法赋值然后取值会报空指针异常 /*** 初始化一个5行空列的二维数组*/int[][] array6=new int[5][];int []arra7[]=new int[5][];int array8[][]=new int[5][]; /*** 赋值方法*/int[][] array6=new int[5][];array6[0]=new int[]&#123;1,2,3&#125;;System.out.println(array6[0][0]);//输出:1 初始化值/*** 初始化并赋值一个2行3列的二维数组*/int[][] array13=&#123;&#123;1,2,3&#125;,&#123;4,5,6&#125;&#125;;int []array14[]=&#123;&#123;1,2,3&#125;,&#123;4,5,6&#125;&#125;;int array15[][]=&#123;&#123;1,2,3&#125;,&#123;4,5,6&#125;&#125;; 总结​ 其他像什么三维数组,多维数组初始化的方式都差不多,可以自己在IDE工具中试一下;","categories":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/tags/Java/"}]},{"title":"RestTemplate简单使用","slug":"spring/spring-boot-resttemplate-example","date":"2019-11-20T17:32:18.000Z","updated":"2022-04-16T02:52:58.653Z","comments":true,"path":"spring/spring-boot-resttemplate-example/","link":"","permalink":"https://greycode.top/spring/spring-boot-resttemplate-example/","excerpt":"","text":"前言本文只讲常用的**GET** 和**POST**请求,其他类型的请求(如**PUT**，**PATCH**)请求方式都差不多，有兴趣的可以查看RestTemplate源码。 GET GET官方给了getForEntity和getForObject两种种方法，每个方法又有三个重载方法 官方源码接口@Nullable&lt;T&gt; T getForObject(String url, Class&lt;T&gt; responseType, Object... uriVariables) throws RestClientException;@Nullable&lt;T&gt; T getForObject(String url, Class&lt;T&gt; responseType, Map&lt;String, ?&gt; uriVariables) throws RestClientException;@Nullable&lt;T&gt; T getForObject(URI url, Class&lt;T&gt; responseType) throws RestClientException;&lt;T&gt; ResponseEntity&lt;T&gt; getForEntity(String url, Class&lt;T&gt; responseType, Object... uriVariables) throws RestClientException;&lt;T&gt; ResponseEntity&lt;T&gt; getForEntity(String url, Class&lt;T&gt; responseType, Map&lt;String, ?&gt; uriVariables) throws RestClientException;&lt;T&gt; ResponseEntity&lt;T&gt; getForEntity(URI url, Class&lt;T&gt; responseType) throws RestClientException; 使用API接口 首先我写了两个接口供RestTemplate调用 @RestControllerpublic class Test &#123; @GetMapping(&quot;/test&quot;) public JSONObject test()&#123; JSONObject jsonObject=new JSONObject(); jsonObject.put(&quot;name:&quot;,&quot;Mr.Zheng&quot;); jsonObject.put(&quot;tag:&quot;,&quot;Good&quot;); return jsonObject; &#125; @GetMapping(&quot;/test/&#123;name&#125;&quot;) public JSONObject test2(@PathVariable String name)&#123; JSONObject jsonObject=new JSONObject(); jsonObject.put(&quot;name:&quot;,name); jsonObject.put(&quot;tag:&quot;,&quot;Good&quot;); return jsonObject; &#125; &#125; getForObject代码@Test public void restTemplate()&#123; RestTemplate template=new RestTemplate(); //使用URI请求 URI uri=URI.create(&quot;http://localhost:8090/test&quot;); String response=template.getForObject(uri, String.class); System.out.println(response); //url带参数请求 String response2=template.getForObject(&quot;http://localhost:8090/test/&#123;name&#125;&quot;,String.class,&quot;hui1&quot;); System.out.println(response2); //当url参数过多可以用map Map&lt;String,String&gt; param=new HashMap&lt;&gt;(); param.put(&quot;name&quot;,&quot;hui2&quot;); String reponse3=template.getForObject(&quot;http://localhost:8090/test/&#123;name&#125;&quot;,String.class,param); System.out.println(reponse3); &#125; 结果:&#123;&quot;name:&quot;:&quot;Mr.Zheng&quot;,&quot;tag:&quot;:&quot;Good&quot;&#125;&#123;&quot;name:&quot;:&quot;hui1&quot;,&quot;tag:&quot;:&quot;Good&quot;&#125;&#123;&quot;name:&quot;:&quot;hui2&quot;,&quot;tag:&quot;:&quot;Good&quot;&#125; getForEntity代码@Testpublic void restTemplate()&#123; RestTemplate template=new RestTemplate(); //使用URI请求 URI uri=URI.create(&quot;http://localhost:8090/test&quot;); ResponseEntity&lt;String&gt; response=template.getForEntity(uri, String.class); System.out.println(response.getBody()); //url带参数请求 ResponseEntity&lt;String&gt; response2=template.getForEntity(&quot;http://localhost:8090/test/&#123;name&#125;&quot;,String.class,&quot;hui1&quot;); System.out.println(response2.getBody()); //当url参数过多可以用map Map&lt;String,String&gt; param=new HashMap&lt;&gt;(); param.put(&quot;name&quot;,&quot;hui2&quot;); ResponseEntity&lt;String&gt; reponse3=template.getForEntity(&quot;http://localhost:8090/test/&#123;name&#125;&quot;,String.class,param); System.out.println(reponse3.getBody());&#125; 结果&#123;&quot;name:&quot;:&quot;Mr.Zheng&quot;,&quot;tag:&quot;:&quot;Good&quot;&#125;&#123;&quot;name:&quot;:&quot;hui1&quot;,&quot;tag:&quot;:&quot;Good&quot;&#125;&#123;&quot;name:&quot;:&quot;hui2&quot;,&quot;tag:&quot;:&quot;Good&quot;&#125; 小结可以看到getForEntity和getForObject的使用方法差不多，他们的区别就是 getForObject只返回结果，getForEntity包装了返回的信息，可以从中获取更多关于http请求的信息，比如请求头，请求状态等 POST POST官方给了postForLocation,postForObject,postForEntity三种方法，每种又有三个重载方法 官方源码接口@NullableURI postForLocation(String url, @Nullable Object request, Object... uriVariables) throws RestClientException;@NullableURI postForLocation(String url, @Nullable Object request, Map&lt;String, ?&gt; uriVariables) throws RestClientException;@NullableURI postForLocation(URI url, @Nullable Object request) throws RestClientException;@Nullable&lt;T&gt; T postForObject(String url, @Nullable Object request, Class&lt;T&gt; responseType, Object... uriVariables) throws RestClientException;@Nullable&lt;T&gt; T postForObject(String url, @Nullable Object request, Class&lt;T&gt; responseType, Map&lt;String, ?&gt; uriVariables) throws RestClientException;@Nullable&lt;T&gt; T postForObject(URI url, @Nullable Object request, Class&lt;T&gt; responseType) throws RestClientException;&lt;T&gt; ResponseEntity&lt;T&gt; postForEntity(String url, @Nullable Object request, Class&lt;T&gt; responseType, Object... uriVariables) throws RestClientException;&lt;T&gt; ResponseEntity&lt;T&gt; postForEntity(String url, @Nullable Object request, Class&lt;T&gt; responseType, Map&lt;String, ?&gt; uriVariables) throws RestClientException;&lt;T&gt; ResponseEntity&lt;T&gt; postForEntity(URI url, @Nullable Object request, Class&lt;T&gt; responseType) throws RestClientException; API接口@RestControllerpublic class Test &#123; private static final Logger LOG= LoggerFactory.getLogger(Test.class); @PostMapping(&quot;/test&quot;) public JSONObject test(@RequestBody JSONObject param)&#123; LOG.info(&quot;param:&#123;&#125;&quot;,param.toJSONString()); return param; &#125; @PostMapping(&quot;/test/&#123;urlParam&#125;&quot;) public JSONObject test(@RequestBody JSONObject param,@PathVariable String urlParam)&#123; LOG.info(&quot;param:&#123;&#125;&quot;,param); param.put(&quot;urlParam&quot;,urlParam); return param; &#125; &#125; postForObject代码@Testpublic void restTemplate()&#123; RestTemplate template=new RestTemplate(); String baseURL=&quot;http://localhost:8090&quot;; JSONObject param=new JSONObject(); param.put(&quot;tag&quot;,&quot;this is post request!!&quot;); //使用URI请求 URI uri=URI.create(baseURL+&quot;/test&quot;); String response=template.postForObject(uri,param,String.class); System.out.println(response); //url带参数请求 String response2=template.postForObject(baseURL+&quot;/test/&#123;urlParam&#125;&quot;,param,String.class,&quot;this is urlParam&quot;); System.out.println(response2); //当url参数过多可以用map Map&lt;String,String&gt; mapParam=new HashMap&lt;&gt;(); mapParam.put(&quot;urlParam&quot;,&quot;this is map param!!&quot;); String reponse3=template.postForObject(baseURL+&quot;/test/&#123;urlParam&#125;&quot;,param,String.class,mapParam); System.out.println(reponse3);&#125; 结果&#123;&quot;tag&quot;:&quot;this is post request!!&quot;&#125;&#123;&quot;tag&quot;:&quot;this is post request!!&quot;,&quot;urlParam&quot;:&quot;this is urlParam&quot;&#125;&#123;&quot;tag&quot;:&quot;this is post request!!&quot;,&quot;urlParam&quot;:&quot;this is map param!!&quot;&#125; postForEntity postForEntity和postForObject用法类似，具体这里就写了。 postForLocation 这个请求和其他请求不一样，可以看到他返回的是URI，这里具体讲一下 新写个API接口@RestControllerpublic class UriTest &#123; private static final Logger LOG= LoggerFactory.getLogger(UriTest.class); @PostMapping(&quot;/uri&quot;) public void uriTest(@RequestBody JSONObject param, HttpServletResponse response) throws IOException &#123; try &#123; //打印上传的参数 LOG.info(&quot;requestParam:&#123;&#125;&quot;,param); //跳转百度 response.sendRedirect(&quot;https://www.baidu.com&quot;); &#125;catch (Exception e)&#123; LOG.info(e.getMessage(),e); &#125; &#125;&#125; 代码@Testpublic void restTemplate()&#123; RestTemplate template=new RestTemplate(); String baseURL=&quot;http://localhost:8090&quot;; JSONObject param=new JSONObject(); param.put(&quot;info&quot;,&quot;this is postForLocation test!!&quot;); URI response2=template.postForLocation(baseURL+&quot;/uri&quot;,param); System.out.println(response2);&#125; 结果 服务端日志 小结postForObject和postForEntity两个方法和GET请求的用法差不多，只是POST请求比GET请求多了个request请求体。而postForLocation方法一般用的比较少,一般只有后端发生301或302等跳转时用来获取跳转后的URL，方法的形参中不用定义返回的数据类型，默认是URI；","categories":[{"name":"Spring","slug":"Spring","permalink":"https://greycode.top/categories/Spring/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://greycode.top/tags/SpringBoot/"}]},{"title":"Nacos报[NACOS HTTP-POST]","slug":"java/nacos-post-error","date":"2019-11-14T23:50:58.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"java/nacos-post-error/","link":"","permalink":"https://greycode.top/java/nacos-post-error/","excerpt":"","text":"问题 由于项目使用阿里的Nacos来管理项目的配置文件，今天所有使用Nacos的项目的日志都报[NACOS HTTP-POST] The maximum number of tolerable server reconnection errors has been reached这个错误。 解决方法 查阅资料后说是连接超过了最大重试次数。Nacos有个maxRetry这个配置参数，默认是3;可是和SpringCloud整合后在application文件中找不到这个参数，只好另寻方法； 由于项目都是Docker容器化的，先前出现过连接不到Nacos的问题,于是就查看了各个Docker容器的IP。 修正Nacos的地址 查阅后发现，是因为同事吧服务器重启了一遍，导致Docker服务也重启了，然后Docker容器里的IP全部都变了。因为同一台服务器上我们各个容器间的访问是通过Docker容器内部IP的，也就是172.16.x.x这个IP段。所以导致访问不到报错。 spring.cloud.nacos.config.server-addr=172.16.X.X //更改到最新nacos的地址","categories":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/categories/Java/"}],"tags":[{"name":"Nacos","slug":"Nacos","permalink":"https://greycode.top/tags/Nacos/"}]},{"title":"Jenkins插件版本太旧的更新方法","slug":"jenkins/problem-jenkins-01","date":"2019-11-12T17:27:27.000Z","updated":"2022-04-16T02:52:58.653Z","comments":true,"path":"jenkins/problem-jenkins-01/","link":"","permalink":"https://greycode.top/jenkins/problem-jenkins-01/","excerpt":"","text":"前言Jenkins的插件好多都是互相依赖的，如果有的插件版本太低，而另一个插件就会导致用不了，就会出现下面的情况： Durable Task Plugin version 1.29 is older than required. To fix, install version 1.33 or later. 查看本地已安装版本可以看到，本地安装的版本和刚才提示的一样，是1.29版本的，刚才提示说太旧了，要更新到1.33版本。 搜索插件当你理所应当的去这个界面准备搜索这个插件并更新时。。。。你傻了，，怎么搜不到？？？WTF 不要慌，天无绝人之路，这里找不到，可以去另外的地方找。浏览器打开这个网站 Jenkins插件下载 进入后在输入框里输入你刚才要下载的插件: 选择对应的插件 然后点击右上角 下载刚才提示的1.33版本 下载完成后是一个hpi文件 导入插件 到插件管理界面，找到Upload Plugin 然后选择刚才下载的插件，点击导入 可以看到插件正在导入 导入完成后，重启Jenkins就OK了","categories":[{"name":"Jenkins","slug":"Jenkins","permalink":"https://greycode.top/categories/Jenkins/"}],"tags":[{"name":"Jenkins","slug":"Jenkins","permalink":"https://greycode.top/tags/Jenkins/"}]},{"title":"Jenkins教程-Docker+GitLab持续部署持续集成","slug":"jenkins/build-jenkins-ci-cd","date":"2019-11-12T17:27:02.000Z","updated":"2022-04-16T02:52:58.653Z","comments":true,"path":"jenkins/build-jenkins-ci-cd/","link":"","permalink":"https://greycode.top/jenkins/build-jenkins-ci-cd/","excerpt":"","text":"目录 Jenkins教程-搭建(Docker版) Jenkins教程-创建Maven项目 Jenkins教程-Docker+GitLab持续部署持续集成 环境 地址 系统 安装的软件 主机１ 10.25.0.72 Centos 7 Docker , Jenkins(Docker版) 主机２ 10.25.0.50 Cnetos 7 Docker Jenkins所需添加插件 Git Parameter GitLab SSH 创建ssh登录凭据 这边选择Username with password,用账户密码来设置；然后在Username和Password输入框中分别输入10.25.0.50服务器的账号和密码。点击OK保存； 添加SSH配置 找到SSH remote hosts 设置你远程机器的ip和端口，然后选择刚配置好的凭证，点击save保存 配置Job 进入上篇文章创建好的Job,在此基础上进行改造 配置Git Parameter,来获取gitlab的Tag数据 配置触发器 点击最下面的Generate,生成秘钥。然后记下URL:http://172.16.54.131:8080/project/JenkinsTest 和生成的秘钥：60327d68d10f1f7621696edd42719d1c 添加构建完成后的动作 添加Execute shell 和Execute shell script on remote host using ssh Execute shell ： 执行Jenkins所在服务器的脚本 Execute shell script on remote host using ssh：登录远程服务器执行脚本 编写你要执行的脚本 由于是自定义的，内容我就不粘贴出来了.编写好后点击保存 开始构建手动构建 选择你要构建的tag标签，点击Build开始构建并自动部署 自动构建 自动构建是当你push或打tag上传代码的时候，Jenkins就会自动构建部署 自动构建流程 配置GitLab代码仓库 点击你你项目右边Settings的Integrations,然后在URL和Secret Tonken中填写刚保存的URL和秘钥，选择Tag push events,然后点击保存 Git打Tag标签git tag -a 1.0 -m &#x27;1.0&#x27; //打一个1.0的taggit push origin 1.0 //上传1.0标签到远程仓库 上传完tag后此时Jenkins已经开始自动构建并部署项目了； 注意弄自动部署时，Jenkins和GitLab要都能互相访问的到，不然就会出错；","categories":[{"name":"Jenkins","slug":"Jenkins","permalink":"https://greycode.top/categories/Jenkins/"}],"tags":[{"name":"Jenkins","slug":"Jenkins","permalink":"https://greycode.top/tags/Jenkins/"}]},{"title":"Jenkins教程-创建Maven项目","slug":"jenkins/build-jenkins-mavne","date":"2019-11-12T17:26:19.000Z","updated":"2022-04-16T02:52:58.653Z","comments":true,"path":"jenkins/build-jenkins-mavne/","link":"","permalink":"https://greycode.top/jenkins/build-jenkins-mavne/","excerpt":"","text":"目录 Jenkins教程-搭建(Docker版) Jenkins教程-创建Maven项目 Jenkins教程-Docker+GitLab持续部署持续集成 前期准备本教程是和gitlab集成,所以要有gitlab仓库。注意：如果后期要弄自动部署的话,你Jenkins的地址gitlab必须能访问到。不然gitlab监听到事件就通知不了Jenkins了； 环境 Centos 7 Jenkins(Docker版) 所需插件 除了搭建Jenkins时安装的插件,还需安装的插件 Maven Integration 安装Maven点击侧边栏的Manage Jenkins,然后点击Global Tool Configuration,进入全局工具设置 然后找到Maven,点击Add Maven,可以选择你要的Maven版本，然后设置一个名字。点击保存 创建Git登录凭证点击侧边栏的凭证，然后按图点击 这边Kind有很多选项，这边选择Username with password,用账户密码来设置；然后在Username和Password输入框中分别输入gitlab的账号和密码。点击OK保存； 保存后就会出现你保存好的凭证； 创建JOB 创建Maven项目 输入你的gitlab项目地址，然后选择刚才配置的凭证 输入Maven打包命令，然后点击保存 开始构建 查看构建项目日志 第一次构建会比慢，因为他要下载maven相关构建的包 查看构建好的jar包 到此，构建maven项目已结束，可以下载这个jar包进行部署。后面会有自动构建部署的教程","categories":[{"name":"Jenkins","slug":"Jenkins","permalink":"https://greycode.top/categories/Jenkins/"}],"tags":[{"name":"Jenkins","slug":"Jenkins","permalink":"https://greycode.top/tags/Jenkins/"}]},{"title":"Jenkins初始化界面插件安装失败解决方法","slug":"jenkins/problem-jenkins-02","date":"2019-11-07T17:19:52.000Z","updated":"2022-04-16T02:52:58.653Z","comments":true,"path":"jenkins/problem-jenkins-02/","link":"","permalink":"https://greycode.top/jenkins/problem-jenkins-02/","excerpt":"","text":"前言在初始化安装界面可能由于网络问题会出现插件下载失败，就像下面这个界面 别着急，直接点击继续，先完成初始化步骤。 设置源 插件下载失败，一般都是网络的原因，只要更换到国内的软件源就可以了，点击Manage Jenkins 点击Correct 点击Advanced 下拉找到Update Site 然后把输入框的内容换成 https://mirrors.tuna.tsinghua.edu.cn/jenkins/updates/2.89/update-center.json 重新下载插件 然后重新下载刚才那些下载失败的插件,这里随机选一个 在刚才设置源的那个界面点击 Available，搜索插件，选择，点击install 插件正在安装 安装完全部插件后然后重启Jenkins，插件界面的报错信息才会消失;如果遇到插件下载不下来或搜不到，可以看这篇文章：Jenkins插件版本太旧的更新方法","categories":[{"name":"Jenkins","slug":"Jenkins","permalink":"https://greycode.top/categories/Jenkins/"}],"tags":[{"name":"Jenkins","slug":"Jenkins","permalink":"https://greycode.top/tags/Jenkins/"}]},{"title":"Jenkins教程-搭建(Docker版)","slug":"jenkins/build-jenkins-docker","date":"2019-11-07T17:19:34.000Z","updated":"2022-04-16T02:52:58.653Z","comments":true,"path":"jenkins/build-jenkins-docker/","link":"","permalink":"https://greycode.top/jenkins/build-jenkins-docker/","excerpt":"","text":"目录 Jenkins教程-搭建(Docker版) Jenkins教程-创建Maven项目 Jenkins教程-Docker+GitLab持续部署持续集成 环境 主机：172.16.54.131 系统：Cnetos 7 安装Docker-CE检查Docker首先检查本机是否安装Docker，如果安装了直接跳过安装Docker步骤 docker -v 如果出现Docker version 19.03.4, build 9013bf583a类似的信息，则说明已安装Docker 安装 本教程以centos7安装方式说明，其他系统安装方式会有不同 执行以下命令，安装Docker yum install -y yum-utils device-mapper-persistent-data lvm2yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo yum install docker-ceservice docker startsystemctl enable docker 第一条命令：为添加源做准备 使其支持存储 第二条命令：添加docker-ce软件源 第三条命令：安装docker-ce 第四条命令：启动docker服务 第五条命令：设置开启自启 安装Jenkins的Docker容器创建文件夹在创建容器前先在宿主机创建一个Jenkins的工作文件夹，用于持久化 mkdir /opt/jenkins //创建文件夹chmod 7777 /opt/jenkins //授予权限 该文件夹一定要给权限，不然docker容器访问不了，容器会创建失败。 拉取官方镜像docker pull jenkins/jenkins:lts 启动容器docker run -d -p 8080:8080 -p 50000:50000 -u root -v /var/run/docker.sock:/var/run/docker.sock -v $(which docker):/usr/bin/docker -v /opt/jenkins:/var/jenkins_home -v /etc/localtime:/etc/localtime -e JAVA_OPTS=-Duser.timezone=Asia/Shanghai --restart=always --name jenkins jenkins/jenkins:lts 启动容器一定要用root用户进入docker容器，不然访问不了宿主机的docker服务。还有要挂载&#x2F;var&#x2F;run&#x2F;docker.sock和$(which docker)这两个文件夹到容器，这样docker版的jenkins才可以用使用docker相关服务。 查看容器日志docker logs jenkins 记下43455b344f904cf69a4af9e231f7d48d这个密码，等下要用到 初始化Jenkins解锁在浏览器访问172.16.54.131:8080这个地址，进入Jenkins的web界面。（如果访问不了，请开启防火墙的8080端口） 在输入框中填入刚才保存的密码 自定义推荐直接选 安装推荐的插件 安装插件到这个界面等他安装完成，时间会长一点 如这个界面插件下载失败，直接点继续，进行下一步，具体解决办法可以看这个篇文章 Jenkins初始化界面插件安装失败解决方法 创建用户设置你的登录账号和密码，然后点保存完成 实例配置默认直接点保存完成 开始使用点击开始使用Jenkins Jenkins主界面进入Jenkins主界面，到此教程结束","categories":[{"name":"Jenkins","slug":"Jenkins","permalink":"https://greycode.top/categories/Jenkins/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://greycode.top/tags/Docker/"},{"name":"Linux","slug":"Linux","permalink":"https://greycode.top/tags/Linux/"},{"name":"Jenkins","slug":"Jenkins","permalink":"https://greycode.top/tags/Jenkins/"}]},{"title":"设计模式系例-单例模式","slug":"gof/gof-singleton","date":"2019-10-22T21:16:37.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"gof/gof-singleton/","link":"","permalink":"https://greycode.top/gof/gof-singleton/","excerpt":"","text":"积千里跬步，汇万里江河．每天进步一点点，终有一天将成大佬 前言网上说单例模式是所有模式中最简单的一种模式，巧的是我也这么认为。不过越简单的东西，往往坑就隐藏的越深，这边文章我会把我知道的几个坑所出来。 一.什么是单例模式​ 就如同他的名字一样，’单例’-就是只有一个实例。也就是说一个类在全局中最多只有一个实例存在，不能在多了，在多就不叫单例模式了。 1.白话小故事​ 程序员小H单身已久，每天不是对着电脑，就是抱着手机这样来维持生活。某日，坐在电脑前，突然感觉一切都索然无味。谋生想找一个对象来一起度过人生美好的每一天。 ​ 于是精心打扮出门找对象，由于小H很帅，很快就找到了心仪的另一半–小K。小H的心中永远只有小K一个人，而且发誓永远不会在找新对象。 小H和小K的关系就是单例模式，在小H的全局中只有一个小K对象，且无第二个，如果有第二个的话，他们之间的关系就出问题了。哈哈 2.用在哪里​ 单例模式一般用在对实例数量有严格要求的地方，比如数据池，线程池，缓存，session回话等等。 3.在Java中构成的条件 静态变量 静态方法 私有构造器 二.单例模式的两种形态1.懒汉模式 线程不安全 public class Singleton &#123; private static Singleton unsingleton; private Singleton()&#123;&#125; public static Singleton getInstance()&#123; if(unsingleton==null)&#123; unsingleton=new Singleton(); &#125; return unsingleton; &#125;&#125; 2.饿汉模式 线程安全 public class Singleton &#123; private static Singleton unsingleton=new Singleton(); private Singleton()&#123;&#125; public static Singleton getInstance()&#123; return unsingleton; &#125;&#125; 调用public class Test &#123; public static void main(String[] args) &#123; Singleton singleton1=Singleton.getInstance(); &#125;&#125; 三.懒汉模式优化成线程安全 懒汉模式要变成线程安全的除了用饿汉模式之外，还有两种方法。 1.加synchronized关键字 此方法是最简单又有效的方法，不过对性能上会有所损失。比如两个线程同时调用这个实例，其中一个线程要等另一个线程调用完才可以继续调用。而线程不安全往往发生在这个实例在第一次调用的时候发生，当实例被调用一次后，线程是安全的，所以加synchronized就显得有些浪费性能。 public class Singleton &#123; private static Singleton unsingleton; private Singleton()&#123;&#125; public static synchronized Singleton getInstance()&#123; if(unsingleton==null)&#123; unsingleton=new Singleton(); &#125; return unsingleton; &#125;&#125; 2.用”双重检查加锁” 上个方法说到，线程不安全往往发生在这个实例在第一次调用的时候发生，当实例被调用一次后，线程是安全的。那有没有方法只有在第一次调用的时候才用synchronized关键字，而第一次后就不用synchronized关键字呢？答案是当然有的，就是用volatile来修饰静态变量，保持其可见性。 public class Singleton &#123; private static volatile Singleton unsingleton; private Singleton()&#123;&#125; public static Singleton getInstance()&#123; if(unsingleton==null)&#123; //只有当第一次访问的时候才会使用synchronized关键字 synchronized (Singleton.class)&#123; unsingleton=new Singleton(); &#125; &#125; return unsingleton; &#125;&#125; 三种线程安全的单例模式比较 饿汉模式：性能好，写法简单，个人比较推荐用这个 加synchronized关键字：性能差，不过对懒汉模式的盖章比较直接有效。 volatile-双重验证加锁：性能好，对Java版本有要求，要求Java5以上版本","categories":[{"name":"GOF","slug":"GOF","permalink":"https://greycode.top/categories/GOF/"}],"tags":[{"name":"GOF","slug":"GOF","permalink":"https://greycode.top/tags/GOF/"},{"name":"Singleton","slug":"Singleton","permalink":"https://greycode.top/tags/Singleton/"}]},{"title":"RocketMQ集群搭建","slug":"rocketmq/rocketmq-cluster-build","date":"2019-10-09T20:55:36.000Z","updated":"2022-04-16T02:52:58.653Z","comments":true,"path":"rocketmq/rocketmq-cluster-build/","link":"","permalink":"https://greycode.top/rocketmq/rocketmq-cluster-build/","excerpt":"","text":"本文只讲RocketMQ集群的搭建(异步复制)，具体理论知识后续会在写新文章详细介绍; 环境 JDK1.8 Centos7 主机-两台 centos7_1 :172.16.54.130 centos7_2 :172.16.54.128 软件资源 JDK1.8 :https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html RocketMQ4.5.2 :http://mirrors.tuna.tsinghua.edu.cn/apache/rocketmq/4.5.2/rocketmq-all-4.5.2-bin-release.zip 安装JDK 首先分别在两台主机上安装JDK1.8，具体安装方法这里就不说了，网上随便搜一搜都有； 配置RocketMQ 把下载的RocketMQ包分别上传到两台服务器上，然后用命令解压: # unzip rocketmq-all-4.5.2-bin-release.zip 编写配置文件 这一步很重要，集群的搭建关键在于配置文件的编写，首先看看RocketMQ配置文件的解析: #所属集群名字 brokerClusterName=rocketmq-cluster#broker名字，每队master和slave保持一致brokerName=broker-a#0 表示 Master，&gt;0 表示 SlavebrokerId=0 #指定主机ipbrokerIP1 = 主机IP#nameServer地址，分号分割namesrvAddr=主机IP:9876;主机IP:9876#在发送消息时，自动创建服务器不存在的topic，默认创建的队列数 defaultTopicQueueNums=4#是否允许 Broker 自动创建Topic，建议线下开启，线上关闭 autoCreateTopicEnable=true#是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭 autoCreateSubscriptionGroup=true#Broker 对外服务的监听端口 listenPort=10911#删除文件时间点，默认凌晨 4点 deleteWhen=04#文件保留时间，默认 48 小时 fileReservedTime=120#commitLog每个文件的大小默认1G mapedFileSizeCommitLog=1073741824#ConsumeQueue每个文件默认存30W条，根据业务情况调整mapedFileSizeConsumeQueue=300000#检测物理文件磁盘空间diskMaxUsedSpaceRatio=88#存储路径storePathRootDir=/usr/local/rocketmq/store#commitLog 存储路径 storePathCommitLog=/usr/local/rocketmq/store/commitlog#消费队列存储路径存储路径storePathConsumeQueue=/usr/local/rocketmq/store/consumequeue#消息索引存储路径storePathIndex=/usr/local/rocketmq/store/index#checkpoint 文件存储路径storeCheckpoint=/usr/local/rocketmq/store/checkpoint#Broker 的角色#- ASYNC_MASTER 异步复制Master#- SYNC_MASTER 同步双写Master#- SLAVE brokerRole=ASYNC_MASTER#刷盘方式#- ASYNC_FLUSH 异步刷盘#- SYNC_FLUSH 同步刷盘 flushDiskType=ASYNC_FLUSH#checkTransactionMessageEnable=false#abort 文件存储路径abortFile=/usr/javawork/apache-rocketmq/store/abort#限制的消息大小 maxMessageSize=65536 以上配置可根据个人需求加入到自己的配置文件中；RocketMQ官方已经为我们创建好了简单的集群配置文件，进去解压后的文件夹，在进入到conf文件夹，可以看到里面有三个文件夹： 2m-2s-async :2个master，2个slave，async异步复制 2m-2s-sync :2个master，2个slave，sync同步双写 2m-noslave :2个master,没有slave 这里我们用async异步复制模式，进入文件夹，分别编辑： centos7_1主机编辑如下两个配置文件 注意，master和slave的文件存储路径不能用同一个路径，所以必须要区分开。 broker-a.propertiesbrokerClusterName=DefaultClusterbrokerName=broker-abrokerId=0deleteWhen=04fileReservedTime=48brokerRole=ASYNC_MASTERflushDiskType=ASYNC_FLUSHnamesrvAddr=172.16.54.128:9876;172.16.54.130:9876listenPort=10911#存储路径storePathRootDir=/usr/local/rocketmq/master/store#commitLog 存储路径 storePathCommitLog=/usr/local/rocketmq/master/store/commitlog#消费队列存储路径存储路径storePathConsumeQueue=/usr/local/rocketmq/master/store/consumequeue#消息索引存储路径storePathIndex=/usr/local/rocketmq/master/store/index#checkpoint 文件存储路径storeCheckpoint=/usr/local/rocketmq/master/store/checkpoint 这个监听端口设置设置成10911后还会自动监听10909,10912这两个端口，所以要配置文件要避免设置到相应的端口。 broker-a-s.propertiesbrokerClusterName=DefaultClusterbrokerName=broker-abrokerId=1deleteWhen=04fileReservedTime=48brokerRole=SLAVEflushDiskType=ASYNC_FLUSHnamesrvAddr=172.16.54.128:9876;172.16.54.130:9876listenPort=20911#存储路径storePathRootDir=/usr/local/rocketmq/slave/store#commitLog 存储路径 storePathCommitLog=/usr/local/rocketmq/slave/store/commitlog#消费队列存储路径存储路径storePathConsumeQueue=/usr/local/rocketmq/slave/store/consumequeue#消息索引存储路径storePathIndex=/usr/local/rocketmq/slave/store/index#checkpoint 文件存储路径storeCheckpoint=/usr/local/rocketmq/slave/store/checkpoint 这个监听端口设置设置成20911后还会自动监听20909,20912这两个端口，所以要配置文件要避免设置到相应的端口。 centos7_2主机编辑如下两个配置文件和centos7_1主机配置一样，这边就不写了，不过brokerName要设置成不同的，我这边设置成broker-b。设置RocketMQ运行的JVM内存(非必须) 此项设置非必须，如果你主机内存很大的话可以不设置，RocketMQ默认要8G。 进入rocketmq-all-4.5.2-bin-release&#x2F;bin目录，两台主机分别设置runbroker.sh和runserver.sh这两个文件。 runbroker.sh：找到如下一行配置 JAVA_OPT=&quot;$&#123;JAVA_OPT&#125; -server -Xms8g -Xmx8g -Xmn4g&quot;改成：JAVA_OPT=&quot;$&#123;JAVA_OPT&#125; -server -Xms512m -Xmx512m -Xmn256m&quot; runserver.sh: 找到如下一行配置 JAVA_OPT=&quot;$&#123;JAVA_OPT&#125; -server -Xms4g -Xmx4g -Xmn2g -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m&quot;改成：JAVA_OPT=&quot;$&#123;JAVA_OPT&#125; -server -Xms512m -Xmx512m -Xmn256m -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m&quot; 启动RocketMQ 启动RocketMQ前为了方便访问，先关闭两台主机的防火墙。执行如下命令： # service firewalld stop 进入rocketmq-all-4.5.2-bin-release&#x2F;bin这个目录，两台主机分别执行以下命令： 启动namesrv # nohup sh mqnamesrv &amp; 启动broker-master # nohup sh mqbroker -c ../conf/2m-2s-async/broker-a.properties &amp; 启动broker-slave # nohup sh mqbroker -c ../conf/2m-2s-async/broker-a-s.properties &amp; 注意两台主机启动broker时后面的-c记得加载你配置好的配置文件路径，别加载错了 搭建Console可视化控制台 任意一台机器或者本地下载Console源码，地址：https://github.com/apache/rocketmq-externals，或者有git的话直接用命令拉取： # git clone https://github.com/apache/rocketmq-externals.git 进去目录： # cd rocketmq-externals-master/rocketmq-console 修改配置文件： # vim src/main/resources/application.properties 添加两个namesvr的主机ip rocketmq.config.namesrvAddr=172.16.54.128:9876;172.16.54.130:9876 然后进项目跟目录，运行项目 # mvn sprint-boot:run 浏览器访问：","categories":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://greycode.top/categories/RocketMQ/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://greycode.top/tags/Linux/"},{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://greycode.top/tags/RocketMQ/"}]},{"title":"Vue Cli3-11创建项目慢的问题","slug":"vue/vue-cli3-11-problem","date":"2019-09-05T16:33:23.000Z","updated":"2022-04-16T02:52:58.653Z","comments":true,"path":"vue/vue-cli3-11-problem/","link":"","permalink":"https://greycode.top/vue/vue-cli3-11-problem/","excerpt":"","text":"前言 这几天刚学习vue，于是下载了最新的vue cli3.11来搭建项目，可是搭建的时候一直卡在下载插件见面，就是下面这张图。 网上查了说不能用国内的镜像，WTF，不是说国内的更快吗？好吧，我换！！！ 下载nrm 看清楚哦，是nrm部署npm！！！nrm 是一个 npm 源管理器，允许你快速地在 npm 源间切换。执行以下命令安装。 sudo npm install -g nrm 测试nrm是否安装成功nrm -V 如果输出版本号，则说明安装成功。 切换npm源 nrm ls 此命令会列出npm的所有源 可以看到我现在使用的是淘宝的源，现在把他切换到npm的源。 nrm use npm 再次创建vue项目vue create rrr2 项目成功创建！！！","categories":[{"name":"Vue","slug":"Vue","permalink":"https://greycode.top/categories/Vue/"}],"tags":[{"name":"Pit","slug":"Pit","permalink":"https://greycode.top/tags/Pit/"},{"name":"Vue","slug":"Vue","permalink":"https://greycode.top/tags/Vue/"}]},{"title":"Docker下安装mysql并设置用户权限","slug":"docker/docker-mysql","date":"2019-09-03T15:58:46.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"docker/docker-mysql/","link":"","permalink":"https://greycode.top/docker/docker-mysql/","excerpt":"","text":"环境 Ubuntu18.04 Docker19.03.1 Mysql5.7 Docker拉取镜像 Docker拉取镜像默认是从DockerHub上面拉取，上面有各厂商提供的优质官方镜像，可以直接拉取使用。或者也可以用DockerFile自定义构建你自己的镜像。 sudo docker pull mysql:5.7 //拉取镜像到本地 注：上面mysql:5.7指的是拉取5.7版本的mysql，如果不加直接写mysql的话默认是拉取mysql的最新版本。 如果显示上面这样，说明已经拉取好了。 查看镜像sudo docker images //查看本地镜像 创建容器创建sudo docker run -d -p 3306:3306 --name mysql5.7 -e MYSQL_ROOT_PASSWORD=root mysql:5.7 -d 指定容器运行于后台 -p 端口映射 主机端口:容器端口 –name 自定义容器名字，方便记忆，不设置的话会随机生产 -e 容器环境变量 创建好的话会显示一串随机生产的id 查看创建好的容器sudo docker ps -a -a 显示所有创建好的容器，如果不加只显示正在运行的容器 Mysql进入容器sudo docker exec -it mysql5.7 bash -i 打开STDIN，用于控制台交互 -t 分配tty设备，该可以支持终端登录 登录mysqlmysql -uroot -p 注：然后输入刚才创建容器时的密码，就是MYSQL_ROOT_PASSWORD这个参数 创建测试数据库create database test; 创建mysql用户create user &#x27;zmh&#x27;@&#x27;%&#x27; identified by &#x27;zmh&#x27;; 注：”%”表示可以任意ip访问 切换mysql用户alter user &#x27;zmh&#x27; identified by &#x27;zmh&#x27;; 授权授权test库的所有表的所有权限给zmh用户 grant all privileges on test.* to &#x27;zmh&#x27;@&#x27;%&#x27;; 刷新权限flush privileges; 退出mysql命令行 exit 客户端连接测试 成功！ 附加如果要重启mysql的话，不用进容器里面，直接重启容器就可以 sudo docker start mysql5.7 启动mysql5.7容器 sudo docker stop mysql5.7 停止mysql5.7容器 sudo docker restart mysql5.7 重启mysql5.7容器","categories":[{"name":"Docker","slug":"Docker","permalink":"https://greycode.top/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://greycode.top/tags/Docker/"},{"name":"Mysql","slug":"Mysql","permalink":"https://greycode.top/tags/Mysql/"},{"name":"Linux","slug":"Linux","permalink":"https://greycode.top/tags/Linux/"}]},{"title":"树莓派安装docker","slug":"linux/build-docker-pi","date":"2019-08-30T18:33:03.000Z","updated":"2022-04-16T02:52:58.653Z","comments":true,"path":"linux/build-docker-pi/","link":"","permalink":"https://greycode.top/linux/build-docker-pi/","excerpt":"","text":"前言 和平常x86_64架构的电脑安装docker不同，树莓派是ARM架构的，所以安装步骤比较繁琐一点。 使用APT源安装docker 更新apt软件源及安装必备组件。为了确认所下载软件包的合法性，还需要添加软件源的 GPG 密钥。 $sudo apt-get update$sudo apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg2 \\ lsb-release \\ software-properties-common$curl -fsSL https://mirrors.ustc.edu.cn/docker-ce/linux/raspbian/gpg | sudo apt-key add - 添加docker ce 软件源 首先执行以下一行命令，然后记一下输出的结果 $ echo $(lsb_release -cs)stretch 在&#x2F;etc&#x2F;apt&#x2F;sources.list.d目录下新建文件docker.list $ sudo vi /etc/apt/sources.list.d/docker.list 在文件里添加下面这行 deb [arch=armhf] https://download.docker.com/linux/raspbian $(lsb_release -cs) stable 把$(lsb_release -cs)改为刚才第一行输出的结果，比如我的输出的是stretch，改完后如下 deb [arch=armhf] https://download.docker.com/linux/raspbian stretch stable 保存，退出 安装docker ce 依次执行以下两行命令，即可完成安装 $ sudo apt-get update$ sudo apt-get install docker-ce 启动$ service docker start 启动$ service docker stop 停止$ service docker status 状态$ service docker restart 重启","categories":[{"name":"Linux","slug":"Linux","permalink":"https://greycode.top/categories/Linux/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://greycode.top/tags/Docker/"},{"name":"Linux","slug":"Linux","permalink":"https://greycode.top/tags/Linux/"},{"name":"RaspberryPi","slug":"RaspberryPi","permalink":"https://greycode.top/tags/RaspberryPi/"}]},{"title":"JDK时区问题","slug":"linux/problem-jdk-timezone","date":"2019-08-27T15:26:30.000Z","updated":"2022-04-16T02:52:58.653Z","comments":true,"path":"linux/problem-jdk-timezone/","link":"","permalink":"https://greycode.top/linux/problem-jdk-timezone/","excerpt":"","text":"今天碰到一个大坑，弄了快一个小时才解决掉； 一个管理台后端服务，用docker隔离了三个容器，oracle,nginx,tomcat;后发现管理台查出来的时间和现实时间相差8个小时，一查是linux时区问题； 于是改之,三台容器都输入一下代码 cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 测试了一下，发现问题docker容器的时区是正确了，可是问题并未得到解决，数据库时间还是慢了8个小时。 于是又查资料，换另外一种设置时区的方法； vi /etc/sysconfig/clock 在里面输入如下内容 ZONE=&quot;Asia/Shanghai&quot;UTC=falseARC=false 保存，重启，测试。。。。。发现还是一样,快疯了 第三种方法，设置TZ环境变量 设置环境变量可以在设置系统级别的&#x2F;etc&#x2F;profile ,也可以设置用户级别的home目录的.bashrc。由于用的是docker，防止变量重启失效，只能在.bashrc里设置。在.bashrc加入如下内容： export TZ=&#x27;CST-8&#x27; 保存：然后执行 source .bashrc 使设置立即生效。 重启容器，测试，发现时间正常了。。。。哈哈哈哈 总结上面问题出在jdk的new Date()方法，所以只要设置jdk所在的那个docker容器的变量就可以，不用每个都设置。jdk的new Date()方法每次调用都会去取环境变量TZ的时区，TZ是TimeZone的缩写，容器内部操作系统并未指定时区（TimeZone）信息，系统默认使用世界标准时（UTC+0),所以导致new Date()出来的数据存库会比当前时间慢8个小时；","categories":[{"name":"Linux","slug":"Linux","permalink":"https://greycode.top/categories/Linux/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/tags/Java/"},{"name":"Linux","slug":"Linux","permalink":"https://greycode.top/tags/Linux/"}]},{"title":"Java的==和equals","slug":"java/java-equals","date":"2019-08-20T19:22:50.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"java/java-equals/","link":"","permalink":"https://greycode.top/java/java-equals/","excerpt":"","text":"在平常工作和学习中，我们一般用&#x3D;&#x3D;和equals来比较两个对象或数据是否相等。但是什么时候用equals，什么时候用&#x3D;&#x3D;一直都不怎么清楚，今天整理了下； 首先看看Java的栈空间和堆空间的地址引用 &#x3D;&#x3D;的说明 在Java中，&#x3D;&#x3D;对比的是两个对象在空间里的地址是否一致,比如上图的s2&#x3D;&#x3D;s3返回的是false，s5&#x3D;&#x3D;s6返回的是为true。话不多说，上代码。 public class demo2 &#123; public static void main(String[] args) &#123; String s1=new String(&quot;t1&quot;); String s2=new String(&quot;t2&quot;); String s3=new String(&quot;t2&quot;); String s4=new String(&quot;t3&quot;); String s5=&quot;t3&quot;; String s6=&quot;t3&quot;; System.out.println(&quot;s2==s3:&quot;+(s2==s3)); System.out.println(&quot;s5==s6:&quot;+(s5==s6)); &#125;&#125; 结果： 这是因为&#x3D;&#x3D;比的是在空间里的地址，s2和s3在堆里面是两个不同的对象，所以地址也不同，自然返回就是false。s5和s6是Java的基础数据类型，指向的是常量池里同一个引用，所以地址也相同，返回的就是true。 equals的说明 每个Object里的equals都不一样，我们看看String里的源码 public boolean equals(Object anObject) &#123; if (this == anObject) &#123; return true; &#125; if (anObject instanceof String) &#123; String anotherString = (String)anObject; int n = value.length; if (n == anotherString.value.length) &#123; char v1[] = value; char v2[] = anotherString.value; int i = 0; while (n-- != 0) &#123; if (v1[i] != v2[i]) return false; i++; &#125; return true; &#125; &#125; return false;&#125; 首先它会对比地址，如果地址相等，就直接返回true 如果地址不相等，就会对比里面的每一个字符，直到完全相等，然后返回true 总结 所以一般如果是对比两个对象是否相等的话，用&#x3D;&#x3D;就可以。但是如果你要对比两个值是否相等的话，就要用equals了，因为如果用&#x3D;&#x3D;就会出现上面明明值相等,返回却是false的情况。","categories":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/tags/Java/"}]},{"title":"Java中String判断为空的4大方法比较","slug":"java/java-isnull-four","date":"2019-08-20T18:59:15.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"java/java-isnull-four/","link":"","permalink":"https://greycode.top/java/java-isnull-four/","excerpt":"","text":"一.四大方法public class demo1 &#123; public static void main(String[] args) &#123; String a=&quot;&quot;; String a2=new String(); System.out.println(a==&quot;&quot;); System.out.println(a2==&quot;&quot;); System.out.println(&quot;------------------------------&quot;); System.out.println(a==null); System.out.println(a2==null); System.out.println(&quot;------------------------------&quot;); System.out.println(a.length()&lt;=0); System.out.println(a2.length()&lt;=0); System.out.println(&quot;------------------------------&quot;); System.out.println(a.isEmpty()); System.out.println(a2.isEmpty()); System.out.println(&quot;------------------------------&quot;); &#125;&#125; 二.输出结果 可以看到用”&#x3D;&#x3D;”判断的那组出现了不一致的情况","categories":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/tags/Java/"}]},{"title":"递归算法-获取json中指定key的所有值","slug":"algorithm/algorithm-recursive-01","date":"2019-08-17T12:38:52.000Z","updated":"2022-04-16T02:52:58.645Z","comments":true,"path":"algorithm/algorithm-recursive-01/","link":"","permalink":"https://greycode.top/algorithm/algorithm-recursive-01/","excerpt":"","text":"今天在工作中遇到要解析json并获取json里所有指定key的值，再把key的值插入对应的数据映射表。于是写了一个递归算法来取值。 1.首先导入alibaba的fastjson，用来解析json。当然也可以用其他的解析包&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.58&lt;/version&gt;&lt;/dependency&gt; 2.创建两个工具类方法，用来判断传入的是不是json对象或json数组public static boolean isJSONObj(Object json)&#123; return json instanceof JSONObject;&#125;public static boolean isJSONArray(Object json)&#123; return json instanceof JSONArray;&#125; java中的instanceof也称为类型比较运算符，因为它将实例与类型进行比较。它返回true或false。 3.建立核心重载方法public static void getJSONValue(JSONObject json,String k,List&lt;String&gt; list)&#123; for (Object j:json.keySet())&#123; if(isJSONObj(json.get(j)))&#123; //是对象 JSONObject j2= JSON.parseObject(json.get(j).toString()); getJSONValue(j2,k,list); &#125;else if(isJSONArray(json.get(j)))&#123; JSONArray j3=JSON.parseArray(json.get(j).toString()); //是数组 getJSONValue(j3,k,list); &#125;else if(j==k)&#123; //是字符串 list.add(json.get(j).toString()); &#125; &#125;&#125;public static void getJSONValue(JSONArray json,String k,List&lt;String&gt; list)&#123; for (Object j:json)&#123; if(isJSONObj(j))&#123; //是对象 JSONObject j2= JSON.parseObject(j.toString()); getJSONValue(j2,k,list); &#125;else if(isJSONArray(j))&#123; //是数组 JSONArray j3=JSON.parseArray(j.toString()); getJSONValue(j3,k,list); &#125; &#125;&#125; 4.接下来写一个比较复杂的json，里面有对象嵌套数组的，数组嵌套对象的，数组嵌套数组的示例json 5.调用方法try &#123; File file=new File(demo1.class.getResource(&quot;/2.json&quot;).getPath()); FileInputStream fileInputStream=new FileInputStream(file); InputStreamReader inputStreamReader=new InputStreamReader(fileInputStream); BufferedReader bufferedReader=new BufferedReader(inputStreamReader); String line=&quot;&quot;; StringBuffer json=new StringBuffer(); while ((line=bufferedReader.readLine())!=null)&#123; json.append(line); &#125; JSONObject j3=JSON.parseObject(json.toString()); List&lt;String&gt; mid=new ArrayList&lt;&gt;(); getJSONValue(j3,&quot;interfaceId&quot;,mid); System.out.println(mid.toString());&#125;catch (Exception e)&#123; System.out.println(e.getMessage());&#125; 6.成功获取 demo源码地址：https://github.com/z573419235/studyDemo","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"https://greycode.top/categories/Algorithm/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/tags/Java/"},{"name":"Recursive","slug":"Recursive","permalink":"https://greycode.top/tags/Recursive/"},{"name":"Algorithm","slug":"Algorithm","permalink":"https://greycode.top/tags/Algorithm/"},{"name":"Json","slug":"Json","permalink":"https://greycode.top/tags/Json/"}]},{"title":"Base64影响泰文字段取值问题","slug":"java/problem-java-base64","date":"2019-08-14T10:39:23.000Z","updated":"2022-04-16T02:52:58.649Z","comments":true,"path":"java/problem-java-base64/","link":"","permalink":"https://greycode.top/java/problem-java-base64/","excerpt":"","text":"今天在工作中，图片要用base64上传，上传数据中还有泰文，然后和前端app联调时发现他们传的泰文这边竟然没存到库里，怀疑是app没有传值过来，于是一番操作查看日志 what,日志里面竟然有他们传过来的泰文的值 对比ios和android的数据 发现日志里的数据都是一样的，但是android上传的数据全部传入了mysql数据库，ios的除了泰文，其他的也都传到了库里 确定问题 最后对比发现，android的泰文字段三放在base64字段前面的然后传上来的，ios是放在base64字段后面传上来的，怀疑问题在此处 修复bug 于是叫ios也和android一样，把上传字段的顺序调整了以下，把泰文的字段放在base64字段前面，然后上传。改了之后试了以下，，竟然解决了，2222333333 总结：暂时不知道具体什么原因，有可能是因为base64数据太长了，影响到泰文的字段存储了。","categories":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://greycode.top/tags/Java/"},{"name":"Pit","slug":"Pit","permalink":"https://greycode.top/tags/Pit/"},{"name":"Base64","slug":"Base64","permalink":"https://greycode.top/tags/Base64/"}]}],"categories":[{"name":"web3.0","slug":"web3-0","permalink":"https://greycode.top/categories/web3-0/"},{"name":"协议","slug":"协议","permalink":"https://greycode.top/categories/%E5%8D%8F%E8%AE%AE/"},{"name":"网络","slug":"网络","permalink":"https://greycode.top/categories/%E7%BD%91%E7%BB%9C/"},{"name":"Linux","slug":"Linux","permalink":"https://greycode.top/categories/Linux/"},{"name":"Tool","slug":"Tool","permalink":"https://greycode.top/categories/Tool/"},{"name":"Java","slug":"Java","permalink":"https://greycode.top/categories/Java/"},{"name":"ZooKeeper","slug":"ZooKeeper","permalink":"https://greycode.top/categories/ZooKeeper/"},{"name":"Vue","slug":"Vue","permalink":"https://greycode.top/categories/Vue/"},{"name":"UML","slug":"UML","permalink":"https://greycode.top/categories/UML/"},{"name":"Essay","slug":"Essay","permalink":"https://greycode.top/categories/Essay/"},{"name":"Quarkus","slug":"Quarkus","permalink":"https://greycode.top/categories/Quarkus/"},{"name":"Vert.x","slug":"Vert-x","permalink":"https://greycode.top/categories/Vert-x/"},{"name":"Protocol","slug":"Protocol","permalink":"https://greycode.top/categories/Protocol/"},{"name":"Spring","slug":"Spring","permalink":"https://greycode.top/categories/Spring/"},{"name":"Dubbo","slug":"Dubbo","permalink":"https://greycode.top/categories/Dubbo/"},{"name":"Go","slug":"Go","permalink":"https://greycode.top/categories/Go/"},{"name":"JVM","slug":"JVM","permalink":"https://greycode.top/categories/JVM/"},{"name":"WebSecurity","slug":"WebSecurity","permalink":"https://greycode.top/categories/WebSecurity/"},{"name":"MySQL","slug":"MySQL","permalink":"https://greycode.top/categories/MySQL/"},{"name":"Algorithm","slug":"Algorithm","permalink":"https://greycode.top/categories/Algorithm/"},{"name":"Recommend","slug":"Recommend","permalink":"https://greycode.top/categories/Recommend/"},{"name":"GOF","slug":"GOF","permalink":"https://greycode.top/categories/GOF/"},{"name":"Docker","slug":"Docker","permalink":"https://greycode.top/categories/Docker/"},{"name":"Jenkins","slug":"Jenkins","permalink":"https://greycode.top/categories/Jenkins/"},{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://greycode.top/categories/RocketMQ/"}],"tags":[{"name":"web3.0","slug":"web3-0","permalink":"https://greycode.top/tags/web3-0/"},{"name":"Redis","slug":"Redis","permalink":"https://greycode.top/tags/Redis/"},{"name":"协议","slug":"协议","permalink":"https://greycode.top/tags/%E5%8D%8F%E8%AE%AE/"},{"name":"MySQL","slug":"MySQL","permalink":"https://greycode.top/tags/MySQL/"},{"name":"P2P","slug":"P2P","permalink":"https://greycode.top/tags/P2P/"},{"name":"网络","slug":"网络","permalink":"https://greycode.top/tags/%E7%BD%91%E7%BB%9C/"},{"name":"Linux","slug":"Linux","permalink":"https://greycode.top/tags/Linux/"},{"name":"Centos","slug":"Centos","permalink":"https://greycode.top/tags/Centos/"},{"name":"Java","slug":"Java","permalink":"https://greycode.top/tags/Java/"},{"name":"Json-Schema","slug":"Json-Schema","permalink":"https://greycode.top/tags/Json-Schema/"},{"name":"参数验证","slug":"参数验证","permalink":"https://greycode.top/tags/%E5%8F%82%E6%95%B0%E9%AA%8C%E8%AF%81/"},{"name":"表达式引擎","slug":"表达式引擎","permalink":"https://greycode.top/tags/%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%BC%95%E6%93%8E/"},{"name":"Aviator","slug":"Aviator","permalink":"https://greycode.top/tags/Aviator/"},{"name":"集群","slug":"集群","permalink":"https://greycode.top/tags/%E9%9B%86%E7%BE%A4/"},{"name":"分布式","slug":"分布式","permalink":"https://greycode.top/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"ZooKeeper","slug":"ZooKeeper","permalink":"https://greycode.top/tags/ZooKeeper/"},{"name":"Vuex","slug":"Vuex","permalink":"https://greycode.top/tags/Vuex/"},{"name":"Vue","slug":"Vue","permalink":"https://greycode.top/tags/Vue/"},{"name":"TypeScript","slug":"TypeScript","permalink":"https://greycode.top/tags/TypeScript/"},{"name":"DDNS","slug":"DDNS","permalink":"https://greycode.top/tags/DDNS/"},{"name":"UML","slug":"UML","permalink":"https://greycode.top/tags/UML/"},{"name":"抒发情感","slug":"抒发情感","permalink":"https://greycode.top/tags/%E6%8A%92%E5%8F%91%E6%83%85%E6%84%9F/"},{"name":"Quarkus","slug":"Quarkus","permalink":"https://greycode.top/tags/Quarkus/"},{"name":"Graal VM","slug":"Graal-VM","permalink":"https://greycode.top/tags/Graal-VM/"},{"name":"Maven","slug":"Maven","permalink":"https://greycode.top/tags/Maven/"},{"name":"SaaS","slug":"SaaS","permalink":"https://greycode.top/tags/SaaS/"},{"name":"Vert.x","slug":"Vert-x","permalink":"https://greycode.top/tags/Vert-x/"},{"name":"闲谈","slug":"闲谈","permalink":"https://greycode.top/tags/%E9%97%B2%E8%B0%88/"},{"name":"SEO","slug":"SEO","permalink":"https://greycode.top/tags/SEO/"},{"name":"Time","slug":"Time","permalink":"https://greycode.top/tags/Time/"},{"name":"Darabonba","slug":"Darabonba","permalink":"https://greycode.top/tags/Darabonba/"},{"name":"HTTP协议","slug":"HTTP协议","permalink":"https://greycode.top/tags/HTTP%E5%8D%8F%E8%AE%AE/"},{"name":"Nacos","slug":"Nacos","permalink":"https://greycode.top/tags/Nacos/"},{"name":"Spring Cloud Gateway","slug":"Spring-Cloud-Gateway","permalink":"https://greycode.top/tags/Spring-Cloud-Gateway/"},{"name":"Dubbbo","slug":"Dubbbo","permalink":"https://greycode.top/tags/Dubbbo/"},{"name":"Spring","slug":"Spring","permalink":"https://greycode.top/tags/Spring/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://greycode.top/tags/SpringCloud/"},{"name":"Gateway","slug":"Gateway","permalink":"https://greycode.top/tags/Gateway/"},{"name":"smtp","slug":"smtp","permalink":"https://greycode.top/tags/smtp/"},{"name":"telnet","slug":"telnet","permalink":"https://greycode.top/tags/telnet/"},{"name":"Go","slug":"Go","permalink":"https://greycode.top/tags/Go/"},{"name":"钉钉机器人","slug":"钉钉机器人","permalink":"https://greycode.top/tags/%E9%92%89%E9%92%89%E6%9C%BA%E5%99%A8%E4%BA%BA/"},{"name":"gitalk","slug":"gitalk","permalink":"https://greycode.top/tags/gitalk/"},{"name":"Nio","slug":"Nio","permalink":"https://greycode.top/tags/Nio/"},{"name":"Disruptor","slug":"Disruptor","permalink":"https://greycode.top/tags/Disruptor/"},{"name":"Dubbo","slug":"Dubbo","permalink":"https://greycode.top/tags/Dubbo/"},{"name":"Shell","slug":"Shell","permalink":"https://greycode.top/tags/Shell/"},{"name":"Github Actions","slug":"Github-Actions","permalink":"https://greycode.top/tags/Github-Actions/"},{"name":"Git","slug":"Git","permalink":"https://greycode.top/tags/Git/"},{"name":"Fegin","slug":"Fegin","permalink":"https://greycode.top/tags/Fegin/"},{"name":"Resttemplate","slug":"Resttemplate","permalink":"https://greycode.top/tags/Resttemplate/"},{"name":"Logback","slug":"Logback","permalink":"https://greycode.top/tags/Logback/"},{"name":"MDC","slug":"MDC","permalink":"https://greycode.top/tags/MDC/"},{"name":"JVM","slug":"JVM","permalink":"https://greycode.top/tags/JVM/"},{"name":"多线程","slug":"多线程","permalink":"https://greycode.top/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"Spring AOP","slug":"Spring-AOP","permalink":"https://greycode.top/tags/Spring-AOP/"},{"name":"注解","slug":"注解","permalink":"https://greycode.top/tags/%E6%B3%A8%E8%A7%A3/"},{"name":"Jvm","slug":"Jvm","permalink":"https://greycode.top/tags/Jvm/"},{"name":"OAuth","slug":"OAuth","permalink":"https://greycode.top/tags/OAuth/"},{"name":"spring-security","slug":"spring-security","permalink":"https://greycode.top/tags/spring-security/"},{"name":"SSO","slug":"SSO","permalink":"https://greycode.top/tags/SSO/"},{"name":"CAS框架","slug":"CAS框架","permalink":"https://greycode.top/tags/CAS%E6%A1%86%E6%9E%B6/"},{"name":"OAuth2.0","slug":"OAuth2-0","permalink":"https://greycode.top/tags/OAuth2-0/"},{"name":"JWT","slug":"JWT","permalink":"https://greycode.top/tags/JWT/"},{"name":"fastDFS","slug":"fastDFS","permalink":"https://greycode.top/tags/fastDFS/"},{"name":"Pit","slug":"Pit","permalink":"https://greycode.top/tags/Pit/"},{"name":"AVL","slug":"AVL","permalink":"https://greycode.top/tags/AVL/"},{"name":"数据结构","slug":"数据结构","permalink":"https://greycode.top/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"平衡二叉树","slug":"平衡二叉树","permalink":"https://greycode.top/tags/%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"name":"二叉树","slug":"二叉树","permalink":"https://greycode.top/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"name":"UI","slug":"UI","permalink":"https://greycode.top/tags/UI/"},{"name":"推荐","slug":"推荐","permalink":"https://greycode.top/tags/%E6%8E%A8%E8%8D%90/"},{"name":"源码解析","slug":"源码解析","permalink":"https://greycode.top/tags/%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/"},{"name":"ArrayDeque","slug":"ArrayDeque","permalink":"https://greycode.top/tags/ArrayDeque/"},{"name":"源码分析","slug":"源码分析","permalink":"https://greycode.top/tags/%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"name":"LinkedList","slug":"LinkedList","permalink":"https://greycode.top/tags/LinkedList/"},{"name":"ArrayList","slug":"ArrayList","permalink":"https://greycode.top/tags/ArrayList/"},{"name":"设计模式","slug":"设计模式","permalink":"https://greycode.top/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"建造者模式","slug":"建造者模式","permalink":"https://greycode.top/tags/%E5%BB%BA%E9%80%A0%E8%80%85%E6%A8%A1%E5%BC%8F/"},{"name":"原型模式","slug":"原型模式","permalink":"https://greycode.top/tags/%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F/"},{"name":"Docker","slug":"Docker","permalink":"https://greycode.top/tags/Docker/"},{"name":"Mysql","slug":"Mysql","permalink":"https://greycode.top/tags/Mysql/"},{"name":"模板方法模式","slug":"模板方法模式","permalink":"https://greycode.top/tags/%E6%A8%A1%E6%9D%BF%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F/"},{"name":"抽象工厂模式","slug":"抽象工厂模式","permalink":"https://greycode.top/tags/%E6%8A%BD%E8%B1%A1%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/"},{"name":"工厂方法模式","slug":"工厂方法模式","permalink":"https://greycode.top/tags/%E5%B7%A5%E5%8E%82%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F/"},{"name":"GOF","slug":"GOF","permalink":"https://greycode.top/tags/GOF/"},{"name":"OOP","slug":"OOP","permalink":"https://greycode.top/tags/OOP/"},{"name":"Jenkins","slug":"Jenkins","permalink":"https://greycode.top/tags/Jenkins/"},{"name":"SonarQube","slug":"SonarQube","permalink":"https://greycode.top/tags/SonarQube/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://greycode.top/tags/SpringBoot/"},{"name":"Singleton","slug":"Singleton","permalink":"https://greycode.top/tags/Singleton/"},{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://greycode.top/tags/RocketMQ/"},{"name":"RaspberryPi","slug":"RaspberryPi","permalink":"https://greycode.top/tags/RaspberryPi/"},{"name":"Recursive","slug":"Recursive","permalink":"https://greycode.top/tags/Recursive/"},{"name":"Algorithm","slug":"Algorithm","permalink":"https://greycode.top/tags/Algorithm/"},{"name":"Json","slug":"Json","permalink":"https://greycode.top/tags/Json/"},{"name":"Base64","slug":"Base64","permalink":"https://greycode.top/tags/Base64/"}]}